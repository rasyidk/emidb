#	Conbined-HCIpapers
1	Unveiling the landscape of generative artificial intelligence in education: a comprehensive taxonomy of applications, challenges, and future prospects Generative AI; GenAI; Educational technology; ChatGPT; AI applications in education; Quality education The rapid advancement of Generative Artificial Intelligence (GenAI) models, particularly ChatGPT, has sparked widespread discussion among educators and researchers regarding their potential implications for education. This study presents a comprehensive taxonomy of GenAI in academia and education, encompassing a wide range of applications, challenges, ethical considerations, and future prospects. Drawing on a scoping review of 453 articles, including the 50 most cited works throughout 2023, the taxonomy provides a state-of-the-art analysis of the current landscape of GenAI in education. The taxonomy offers a theoretical framework that aligns with the current discourse in GenAI and education, providing a critical evaluation of the existing literature and proposing innovative perspectives and solutions. The practical implications of the taxonomy for educators, researchers, and policymakers are highlighted, emphasizing the need for ethical considerations and informed policies to maximize the benefits of GenAI while minimizing its risks and negative impacts.
2	The impact of Generative AI (GenAI) on practices, policies and research direction in education: a case of ChatGPT and Midjourney artificial intelligence; Generative AI in education; teacher education; learning; teaching; assessment; administration Generative artificial intelligence (GenAI) tools have become increasingly accessible and have impacted school education in numerous ways. However, most of the discussions occur in higher education. In schools, teachers' perspectives are crucial for making sense of innovative technologies. Accordingly, this qualitative study aims to investigate how GenAI changes our school education from the perspectives of teachers and leaders. It used four domains - learning, teaching, assessment, and administration - as the initial framework suggested in a systematic literature review study on AI in education. The participants were 88 school teachers and leaders of different backgrounds. They completed a survey and joined a focus group to share how ChatGPT and Midjounery had a GenAI effect on school education. Thematic analysis identified four main themes and 12 subthemes. The findings provide three suggestions for practices: know-it-all attitude, new prerequisite knowledge, interdisciplinary teaching, and three implications for policy: new assessment, AI education, and professional standards. They also further suggest six future research directions for GenAI in education.
3	Students' engagement with ChatGPT feedback: implications for student feedback literacy in the context of generative artificial intelligence Feedback engagement; generative AI; ChatGPT; feedback literacy Student feedback engagement is often reported as unsatisfactorily low, undermining the effectiveness of feedback in higher education. The emergence of Generative Artificial Intelligence (GenAI) has created new opportunities to enhance student feedback engagement through its unique affordances. However, assuming that GenAI is a panacea for feedback disengagement can be misleading, as it also presents substantial challenges. Therefore, it is essential to understand how students engage comprehensively with GenAI feedback. However, such understanding is lacking in literature. To close the research gaps, this study investigated how college students engaged with the feedback provided by ChatGPT on their International English Language Testing System writing tasks. Sixteen undergraduates voluntarily participated in unobtrusive observations and stimulated recall interviews. Their feedback engagement was classified into cognitive, metacognitive, affective and behavioural aspects. The findings reveal that participants employed more cognitive strategies than metacognitive ones, experienced minimal emotional resistance, and exhibited varying levels of trust in ChatGPT's feedback. Additionally, the participants' behavioural engagement appeared superficial when requesting feedback, interacting with ChatGPT and revising their writing tasks. Student feedback literacy, including prompt engineering, evaluative judgement, emotional reflexivity, ethical decision-making and meta-cognitive skills, should be cultivated to foster students' active engagement in a GenAI context.
4	Prompt engineering in higher education: a systematic review to help inform curricula Prompt engineering; Higher education; Generative artificial intelligence; ChatGPT This paper presents a systematic review of the role of prompt engineering during interactions with Generative Artificial Intelligence (GenAI) in Higher Education (HE) to discover potential methods of improving educational outcomes. Drawing on a comprehensive search of academic databases and relevant literature, key trends, including multiple framework designs, are presented and explored to review the role, relevance, and applicability of prompt engineering to purposefully improve GenAI-generated responses in higher education contexts. Multiple experiments using a variety of prompt engineering frameworks are compared, contrasted and discussed. Analysis reveals that well-designed prompts have the potential to transform interactions with GenAI in higher education teaching and learning. Further findings show it is important to develop and teach pragmatic skills in AI interaction, including meaningful prompt engineering, which is best managed through a well-designed framework for creating and evaluating GenAI applications that are aligned with pre-determined contextual educational goals. The paper outlines some of the key concepts and frameworks that educators should be aware of when incorporating GenAI and prompt engineering into their teaching practices, and when teaching students the necessary skills for successful GenAI interaction.
5	Exploring the impact of generative AI-based technologies on learning performance through self-efficacy, fairness & ethics, creativity, and trust in higher education Generative AI-based technologies; Higher education; LLM models; Learning performance; Self-efficacy; Fairness & ethics; Creativity; Trust Artificial Intelligence (AI) technologies have rapidly transformed the education sector and affect student learning performance, particularly in China, a burgeoning educational landscape. The development of generative artificial intelligence (AI) based technologies, such as chatbots and large language models (LLMs) like ChatGPT, has completely changed the educational environment by providing individualized and engaging programs. This study brings forward a model and hypothesis based on social cognitive theory and appropriate research. This investigation centers on how generative AI-based technologies influence students' learning performance in higher education (HE) institutions and the function of self-efficacy, fairness & ethics, creativity, and trust in promoting these connections. Data is collected from 362 students at Chinese universities using purposive sampling. The proposed structural model was evaluated using partial least squares-structural equation modeling (PLS-SEM). The findings reveal that generative AI technologies such as LLM models exemplified by ChatGPT and chatbots significantly influence students' learning performance through self-efficacy, fairness & ethics, and creativity. Furthermore, trust significantly moderates the relationship between fairness & ethics, creativity, and learning performance but negatively moderates the relationship between self-efficacy and learning performance. This study supports the new explanatory potential of social cognitive theory in technological practices. Additionally, this research suggests using generative AI technologies to enhance students' digital learning and boost academic achievement.
6	Mapping out a research agenda for generative artificial intelligence in tertiary education generative artificial intelligence; research; assessment Generative artificial intelligence (AI) has taken the world by storm. In this editorial, we outline some of the key areas of tertiary education impacted by large language models and associated applications that will require re-thinking and research to address in the short to medium term. Given how rapidly generative AI developments are currently occurring, this editorial is speculative. Although there is a long history of research on AI in education, the current situation is both unprecedented and seemingly not something that the AI in education community fully predicted. We also outline the editorial position of AJET in regards to generative AI to assist authors using tools such as ChatGPT as any part of the research or writing process. This is a rapidly evolving space. We have attempted to provide some clarity in this editorial while acknowledging that we may need to revisit some or all of what we offer here in the weeks and months ahead.
7	How should we change teaching and assessment in response to increasingly powerful generative Artificial Intelligence? Outcomes of the ChatGPT teacher survey Artificial Intelligence; Generative AI; ChatGPT; Teacher beliefs; Motivation There has been widespread media commentary about the potential impact of generative Artificial Intelligence (AI) such as ChatGPT on the Education field, but little examination at scale of how educators believe teaching and assessment should change as a result of generative AI. This mixed methods study examines the views of educators (n = 318) from a diverse range of teaching levels, experience levels, discipline areas, and regions about the impact of AI on teaching and assessment, the ways that they believe teaching and assessment should change, and the key motivations for changing their practices. The majority of teachers felt that generative AI would have a major or profound impact on teaching and assessment, though a sizeable minority felt it would have a little or no impact. Teaching level, experience, discipline area, region, and gender all significantly influenced perceived impact of generative AI on teaching and assessment. Higher levels of awareness of generative AI predicted higher perceived impact, pointing to the possibility of an 'ignorance effect'. Thematic analysis revealed the specific curriculum, pedagogy, and assessment changes that teachers feel are needed as a result of generative AI, which centre around learning with AI, higher-order thinking, ethical values, a focus on learning processes and face-to-face relational learning. Teachers were most motivated to change their teaching and assessment practices to increase the performance expectancy of their students and themselves. We conclude by discussing the implications of these findings in a world with increasingly prevalent AI.
8	Exploring students' perspectives on Generative AI-assisted academic writing AI-assisted writing; AI literacy; academic writing; AI in education; generative Artificial Intelligence; student-AI Interaction The rapid development of generative artificial intelligence (GenAI), including large language models (LLM), has merged to support students in their academic writing process. Keeping pace with the technical and educational landscape requires careful consideration of the opportunities and challenges that GenAI-assisted systems create within education. This serves as a useful and necessary starting point for fully leveraging its potential for learning and teaching. Hence, it is crucial to gather insights from diverse perspectives and use cases from actual users, particularly the unique voices and needs of student-users. Therefore, this study explored and examined students' perceptions and experiences about GenAI-assisted academic writing by conducting in-depth interviews with 20 Chinese students in higher education after completing academic writing tasks using a ChatGPT4-embedded writing system developed by the research team. The study found that students expected AI to serve multiple roles, including multi-tasking writing assistant, virtual tutor, and digital peer to support multifaceted writing processes and performance. Students perceived that GenAI-assisted writing could benefit them in three areas including the writing process, performance, and their affective domain. Meanwhile, they also identified AI-related, student-related, and task-related challenges that were experienced during the GenAI-assisted writing activity. These findings contribute to a more nuanced understanding of GenAI's impact on academic writing that is inclusive of student perspectives, offering implications for educational AI design and instructional design.
9	Social-Emotional Learning and Generative AI: A Critical Literature Review and Framework for Teacher Education generative artificial intelligence; Social-Emotional Learning (SEL); teacher education; artificial intelligence in education; AI and emotional intelligence; educational technology teaching; ethical AI in education; human-centered AI This article provides a critical thematic literature review that explores the intersection of generative artificial intelligence (GenAI) and social-emotional learning (SEL), analyzing its implications for teacher education. GenAI offers promising applications for enhancing SEL competencies such as self-awareness, empathy, and social skills through tools like real-time emotional feedback and personalized learning experiences. However, the integration of GenAI into SEL also presents significant challenges, including risks of depersonalization, algorithmic bias, and privacy concerns. This paper introduces a conceptual framework designed to prepare both pre-service and in-service teachers to navigate these complexities, emphasizing ethical considerations, human oversight, and cultural sensitivity. The framework highlights strategies to operationalize cultural sensitivity within AI systems, recognizing the limitations of current technologies in accounting for diverse social and emotional norms. By addressing both opportunities and risks, we aim to provide a balanced analysis of GenAI's potential in SEL as well as guidance for teacher education programs.
10	Not quite eye to AI: student and teacher perspectives on the use of generative artificial intelligence in the writing process Artificial intelligence; Large language model; GPT; Writing education; Academic integrity Generative artificial intelligence (GenAI) can be used to author academic texts at a similar level to what humans are capable of, causing concern about its misuse in education. Addressing the role of GenAI in teaching and learning has become an urgent task. This study reports the results of a survey comparing educators' (n = 68) and university students' (n = 158) perceptions on the appropriate use of GenAI in the writing process. The survey included representations of user prompts and output from ChatGPT, a GenAI chatbot, for each of six tasks of the writing process (brainstorming, outlining, writing, revising, feedback, and evaluating). Survey respondents were asked to differentiate between various uses of GenAI for these tasks, which were divided between student and teacher use. Results indicate minor disagreement between students and teachers on acceptable use of GenAI tools in the writing process, as well as classroom and institutional-level lack of preparedness for GenAI. These results imply the need for explicit guidelines and teacher professional development on the use of GenAI in educational contexts. This study can contribute to evidence-based guidelines on the integration of GenAI in teaching and learning.
11	Developing evaluative judgement for a time of generative artificial intelligence Generative artificial intelligence; evaluative judgement; assessment for learning; higher education Generative artificial intelligence (AI) has rapidly increased capacity for producing textual, visual and auditory outputs, yet there are ongoing concerns regarding the quality of those outputs. There is an urgent need to develop students' evaluative judgement - the capability to judge the quality of work of self and others - in recognition of this new reality. In this conceptual paper, we describe the intersection between evaluative judgement and generative AI with a view to articulating how assessment practices can help students learn to work productively with generative AI. We propose three foci: (1) developing evaluative judgement of generative AI outputs; (2) developing evaluative judgement of generative AI processes; and (3) generative AI assessment of student evaluative judgements. We argue for developing students' capabilities to identify and calibrate quality of work - uniquely human capabilities at a time of technological acceleration - through existing formative assessment strategies. These approaches circumvent and interrupt students' uncritical usage of generative AI. The relationship between evaluative judgement and generative AI is more than just the application of human judgement to machine outputs. We have a collective responsibility, as educators and learners, to ensure that humans do not relinquish their roles as arbiters of quality.
12	Factors affecting generative artificial intelligence, such as ChatGPT, use in higher education: An application of technology acceptance model ChatGPT actual use; ChatGPT ease of use; ChatGPT self-efficacy; ChatGPT trust; ChatGPT usefulness; generative artificial intelligence The adoption of generative artificial intelligence (GAI) tools, such as ChatGPT, in higher education presents numerous opportunities and challenges. The use of GAI technologies in various fields, including education, has accelerated as technology develops. The widely used language model ChatGPT, developed by OpenAI, has become progressively more important, especially in the field of education. This study employs the technology acceptance model to investigate the factors influencing the employment of ChatGPT within the higher education sector of Pakistan. This study employed the PLS-SEM method for probing data collected from 368 Pakistani university students. The findings indicate that ChatGPT trust positively mediates the affiliation between ChatGPT self-efficacy, ChatGPT actual use, ChatGPT use for information and ChatGPT use for interaction. Further, ChatGPT usefulness and ChatGPT ease of use significantly moderate the association between ChatGPT self-efficacy and ChatGPT trust. Educators must encourage students to use ChatGPT safely to preserve their critical thinking, problem-solving abilities and creativity during assessments. This study contributes to understanding generative AI tools such as ChatGPT that are used in educational settings and provides insights for administrators and policymakers aiming to implement these technologies effectively.
13	Investigating students' cognitive processes in generative AI-assisted digital multimodal composing and traditional writing Cognitive process; Generative artificial intelligence; Digital multimodal composing; Writing Recently, generative artificial intelligence (AI)-powered chatbots such as ChatGPT and Bing Chat have garnered increasing attention on a global scale. Previous studies have focused mostly on the influence of generative AI on writing while few researchers have investigated how generative AI can facilitate students' multimodal writing process. To fill in this gap, we explored the generative AI-assisted composing processes of two groups of English as a foreign language (EFL) writers over two weeks in this qualitative study. One group completed a multimodal PowerPoint (PPT) project, and the other group completed a traditional argumentative essay project. Our data consist of students' screen recordings with think-aloud protocols, final multimodal texts, and post-project interviews. Our analysis showed different patterns in text production across the two groups. Students in the PPT group tended to construct more bridge texts and examples to corroborate their sub-claims in the hierarchical order. They also inclined to borrow the summarized search results from the Bing Chat to expand texts for their PPT slides. With regard to image generation for PPT slides, descriptions of AI images from ChatGPT were used as effective prompts to generate AI images from Bing Image Creator. Moreover, students were interested in producing and refining AI images following the recommended prompts by Bing Chat. They also evaluated these AI images from different perspectives. We conclude the study with a discussion on the pedagogical implications and suggestions for further study.
14	Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence Generative artificial intelligence and science education; Large language models; ChatGPT; Digital technologies The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT's output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education.
15	Generative AI and the future of education: Ragnarok or reformation? A paradoxical perspective from management educators Academic integrity; Bard; ChatGPT; Critical analysis; DALL-E; Ethics; Future of education; Generative AI; Generative artificial intelligence; Google; Education; Educator; Management education; Management educator; OpenAI; Paradox; Paradox theory; Ragnarok; Reformation; Transformation; Transformative education Generative artificial intelligence (AI) has taken the world by storm, with notable tension transpiring in the field of education. Given that Generative AI is rapidly emerging as a transformative innovation, this article endeavors to offer a seminal rejoinder that aims to (i) reconcile the great debate on Generative AI in order to (ii) lay the foundation for Generative AI to co-exist as a transformative resource in the future of education. Using critical analysis as a method and paradox theory as a theoretical lens (i.e., the "how"), this article (i) defines Generative AI and transformative education (i.e., the "ideas"), (ii) establishes the paradoxes of Generative AI (i.e., the "what"), and (iii) provides implications for the future of education from the perspective of management educators (i.e., the "so what"). Noteworthily, the paradoxes of Generative AI are four-fold: (Paradox #1) Generative AI is a 'friend' yet a 'foe', (Paradox #2) Generative AI is 'capable' yet 'dependent', (Paradox #3) Generative AI is 'accessible' yet 'restrictive', and (Paradox #4) Generative AI gets even 'popular' when 'banned' (i.e., the "what"). Through a position that seeks to embrace rather than reject Generative AI, the lessons and implications that emerge from the discussion herein represent a seminal contribution from management educators on this trending topic and should be useful for approaching Generative AI as a game-changer for education reformation in management and the field of education at large, and by extension, mitigating a situation where Generative AI develops into a Ragnarok that dooms the future of education of which management education is a part of (i.e., the "so what").
16	Pixels and Pedagogy: Examining Science Education Imagery by Generative Artificial Intelligence Generative artificial intelligence and science education; DALL-E 3; ChatGPT; GPT4; Digital technologies; Cultural capital The proliferation of generative artificial intelligence (GenAI) means we are witnessing transformative change in education. While GenAI offers exciting possibilities for personalised learning and innovative teaching methodologies, its potential for reinforcing biases and perpetuating stereotypes poses ethical and pedagogical concerns. This article aims to critically examine the images produced by the integration of DALL-E 3 and ChatGPT, focusing on representations of science classrooms and educators. Applying a capital lens, we analyse how these images portray forms of culture (embodied, objectified and institutionalised) and explore if these depictions align with, or contest, stereotypical representations of science education. The science classroom imagery showcased a variety of settings, from what the GenAI described as vintage to contemporary. Our findings reveal the presence of stereotypical elements associated with science educators, including white-lab coats, goggles and beakers. While the images often align with stereotypical views, they also introduce elements of diversity. This article highlights the importance for ongoing vigilance about issues of equity, representation, bias and transparency in GenAI artefacts. This study contributes to broader discourses about the impact of GenAI in reinforcing or dismantling stereotypes associated with science education.
17	GenAI as a translation assistant? A corpus-based study on lexical and syntactic complexity of GPT-post-edited learner translation Generative artificial intelligence; Learner translation; Lexical complexity; Syntactic complexity The advent of generative artificial intelligence (GenAI) models, most notably ChatGPT in late 2022, marked a significant milestone in AI development, attracting widespread attention from various research fields. Among its emerging applications, GenAI demonstrates potential in translation education. This study examines the role of GenAI as a post-editing assistant in learner translation by comparing the lexical and syntactic complexity of second language (L2) translations produced by Hong Kong students, with and without post-editing by GPT. The analysis revealed that GPT post-editing improved lexical complexity in learner translations, though its effect on syntactic complexity was inconsistent. While GPT post-editing resulted in longer clauses, more complex nominals, and an increased use of coordinate phrases, non-edited translations featured greater subordination and more verbal structures. These findings suggest that GenAI holds promise in enhancing translation practice but also highlight the need for critical AI literacy to ensure effective use in translation education, particularly in advancing students' linguistic and instrumental competence.
18	Generative artificial intelligence as an enabler of student feedback engagement: a framework Generative AI; feedback engagement; feedback literacy; ecological perspective; self-regulation Despite the recognised importance of feedback in enhancing student learning, feedback practices in higher education have not achieved the expected effects. A primary issue lies in student disengagement, exacerbated by contextual constraints such as large classes and limited curriculum space and time. The advent of Generative Artificial Intelligence (GenAI) may help overcome these contextual constraints. However, GenAI also poses substantial challenges and ethical dilemmas during the feedback process. Meanwhile, it is essential to recognise that the feedback environment created by GenAI inevitably interacts with students' personal factors, especially their feedback literacy, to jointly influence feedback engagement. Therefore, a question remains whether GenAI can be an effective enabler of student feedback engagement. To answer the question, based on a literature review and theoretical synthesis, we scrutinise student engagement with GenAI in three stages of the feedback process and discuss the interplay of student feedback literacy and the GenAI context. We suggest that the extent to which students are engaged with feedback depends on their degree of feedback literacy as orchestrated in the GenAI context. Finally, we propose a cyclical feedback framework consisting of feedback forethought, feedback control and feedback retrospect to enable student feedback engagement in a GenAI world.
19	Large language models in education: A focus on the complementary relationship between human teachers and ChatGPT ChatGPT; Large language model; Chatbot; AIEd; Human-computer interaction; Artificial intelligence; Large language model-powered chatbot Artificial Intelligence (AI) is developing in a manner that blurs the boundaries between specific areas of application and expands its capability to be used in a wide range of applications. The public release of ChatGPT, a generative AI chatbot powered by a large language model (LLM), represents a significant step forward in this direction. Accordingly, professionals predict that this technology will affect education, including the role of teachers. However, despite some assumptions regarding its influence on education, how teachers may actually use the technology and the nature of its relationship with teachers remain under-investigated. Thus, in this study, the relationship between ChatGPT and teachers was explored with a particular focus on identifying the complementary roles of each in education. Eleven language teachers were asked to use ChatGPT for their instruction during a period of two weeks. They then participated in individual interviews regarding their experiences and provided interaction logs produced during their use of the technology. Through qualitative analysis of the data, four ChatGPT roles (interlocutor, content provider, teaching assistant, and evaluator) and three teacher roles (orchestrating different resources with quality pedagogical decisions, making students active investigators, and raising AI ethical awareness) were identified. Based on the findings, an in-depth discussion of teacher-AI collaboration is presented, highlighting the importance of teachers' pedagogical expertise when using AI tools. Implications regarding the future use of LLM-powered chatbots in education are also provided.
20	Students' perceptions of using ChatGPT in a physics class as a virtual tutor GenAI; ChatGPT; Perception; Misconception; Physics problems The latest development of Generative Artificial Intelligence (GenAI), particularly ChatGPT, has drawn the attention of educational researchers and practitioners. We have witnessed many innovative uses of ChatGPT in STEM classrooms. However, studies regarding students' perceptions of ChatGPT as a virtual tutoring tool in STEM education are rare. The current study investigated undergraduate students' perceptions of using ChatGPT in a physics class as an assistant tool for addressing physics questions. Specifically, the study examined the accuracy of ChatGPT in answering physics questions, the relationship between students' ChatGPT trust levels and answer accuracy, and the influence of trust on students' perceptions of ChatGPT. Our finding indicates that despite the inaccuracy of GenAI in question answering, most students trust its ability to provide correct answers. Trust in GenAI is also associated with students' perceptions of GenAI. In addition, this study sheds light on students' misconceptions toward GenAI and provides suggestions for future considerations in AI literacy teaching and research.
21	Teachers'' agency in the era agency of LLM and generative AI: Designing pedagogical AI agents Generative artificial intelligence (GAI); Pedagogical AI agent; Instructional design; Personalized learning The purpose of this study is to explore the existing problems associated with using generative AI in education and to propose a potential solution for addressing those issues through the design of pedagogical AI agents. The existing problems are examined from two different perspectives: those of teachers and students. The proposed solutions for designing pedagogical AI agents are systematically presented, including main concepts, design considerations, functions, procedures, and structure/templates. An example of how to apply the proposed solution in designing a pedagogical AI agent is provided, illustrating its application in teaching order words (or sequencing words). Finally, the paper concludes with a discussion of potential topics for further research.
22	Facilitating nursingandhealthnursing and health educationeducation byincorporatingby incorporating ChatGPTintoChatGPT into learningdesignslearning designs ChatGPT; Generative artificial intelligence via ChatGPT system; Nursing Training; Computerassisted; learning; Generative artificial intelligence in education Traditional nursing and health education design courses usually only transfer knowledge via lectures, and lack interaction, drills and personalized feedback. However, the development and widespread adoption of generative artificial intelligence via the ChatGPT system presents an opportunity to address these issues. Some CIDI model-based ChatGPT systems have been developed, but how to effectively apply these technologies in nursing education design courses remains a challenging problem for researchers. In order to explore the application mode and effect of generative artificial intelligence via ChatGPT technology in nursing education, this study integrated generative artificial intelligence via the ChatGPT system into the teaching activities of nursing and health education design courses, and used computers as learning tools to guide learners to learn nursing and health knowledge. At the same time, two classes of nursing undergraduates were recruited to conduct a quasi-experiment. One of the classes was the experimental group, which used the generative artificial intelligence via the ChatGPT system for learning; the other class was the control group, which used traditional teaching methods for learning. By analyzing learners' learning efficiency and learning satisfaction, we obtained results about the application effect of generative artificial intelligence via ChatGPT technology in a nursing education design course. According to the experimental results, the generative artificial intelligence via ChatGPT system effectively improved learners' critical thinking ability, problem solving, and learning enjoyment. These results indicate that the generative artificial intelligence via ChatGPT system has great potential in nursing education design courses, and can improve the deficiencies of traditional teaching methods.
23	Supporting Teachers' Professional Development With Generative AI: The Effects on Higher Order Thinking and Self-Efficacy Generative artificial intelligence (AI); higher order thinking; preservice teachers; teacher self-efficacy; teaching skills training Generative artificial intelligence (AI) has emerged as a noteworthy milestone and a consequential advancement in the annals of major disciplines within the domains of human science and technology. This study aims to explore the effects of generative AI-assisted preservice teaching skills training on preservice teachers' self-efficacy and higher order thinking. The participants of this study were 215 preservice mathematics, science, and computer teachers from a university in China. First, a pretest-post-test quasi-experimental design was implemented for an experimental group (teaching skills training by generative AI) and a control group (teaching skills training by traditional methods) by investigating the teacher self-efficacy and higher order thinking of the two groups before and after the experiment. Finally, a semistructured interview comprising open-ended questions was administered to 25 preservice teachers within the experimental group to present their views on generative AI-assisted teaching. The results showed that the scores of preservice teachers in the experimental group, who used generative AI for teachers' professional development, were considerably higher than those of the control group, both in teacher self-efficacy (F = 8.589, p = 0.0084 < 0.05) and higher order thinking (F = 7.217, p = 0.008 < 0.05). It revealed that generative AI can be effective in supporting teachers' professional development. This study produced a practical teachers' professional development method for preservice teachers with generative AI.
24	From surface to deep learning approaches with Generative AI in higher education: an analytical framework of student agency Generative AI; GPT; student agency; learning approaches; higher education Recent emergence of generative artificial intelligence (GenAI) technology has stimulated interests as well as concerns in their potential in teaching and learning. Situated in the new and transforming context, this study provides an avenue for students to introspectively explore their use of GenAI in a postgraduate course. Seventy-four students from three Chinese universities participated in this study. By analyzing student interviews conducted pre- and post-course, alongside their chat logs with GenAI and reflective journal entries detailing their learning approaches, the research uncovers a spectrum of student perspectives on GenAI's impact, ranging from beneficial optimism, to cautious skepticism and adaptable pragmatism. Notably, student agency is identified as a crucial element in relation to these themes. This was articulated in four types of learning activities: receptive, resistive, resourceful, and reflective. The research underscores the importance of supporting and empowering student agency in the learning approaches aided by GenAI in education, highlighting its role in optimizing its use and enhancing autonomous, lifelong learning skills amidst the evolving technologically advanced learning landscape.
25	Will generative AI replace teachers in higher education? A study of teacher and student perceptions ChatGPT; Generative AI; AI Literacy; Social-emotional competencies; Holistic competencies This paper evaluates the potential of generative artificial intelligence (AI) in higher education, specifically its capacity to replace or assist human teachers. By reviewing relevant literature and analysing survey data from students and teachers, this mixed-methods study provides a comprehensive perspective on the future role of educators in the face of advancing generative AI technologies. An online survey was conducted to explore the perceptions of 399 university students and 184 teachers across different disciplines in eight higher education institutions in Hong Kong concerning the use of generative AI technologies. Findings suggest that although some believed generative AI may eventually replace teachers, the majority of participants argued that human teachers possess unique qualities, including critical thinking and emotions, which make them irreplaceable. Similarly, findings also emphasized the importance of social-emotional competencies developed through human interactions, something which generative AI technologies cannot currently replicate. Crucially, this study further found that students value and respect their human teachers, even as generative AI becomes more prevalent. As such, the authors propose that teachers can seek to effectively integrate generative AI to enhance teaching and learning without viewing it as their replacement. To do so, they must understand how generative AI can work well with teachers and students, avoid potential pitfalls, develop AI literacy, and address practical issues including ethics and privacy. Recommendations are offered on how universities, teachers, and students can adopt generative AI technologies in an approach that balances the strengths of human educators with generative AI technologies. As the future of education lies in the synergy between human teachers and generative AI, teachers, students, and universities should all understand and refine their unique qualities in order to effectively navigate the integration of generative AI, ensuring well-rounded and impactful learning experiences.
26	Enhancing self-regulated learning and learning experience in generative AI environments: The critical role of metacognitive support GenAI; learning experience; metacognitive support; self-regulated learning The rapid development of generative artificial intelligence (GenAI) has brought opportunities and new challenges to higher education. Students need a high level of self-regulated learning to adapt to this change. However, it is difficult for students to persist in self-regulation without guidance. Metacognitive support has a significant advantage in enhancing self-regulated learning, but fewer studies have explored the effects of its role in GenAI environments. The purpose of this study was to investigate the impacts of metacognitive support on college students' self-regulated learning and learning experiences in a GenAI environment. A quasi-experiment was designed in which 68 college students were divided into two groups. The experimental group (N = 35) received explicit metacognitive support, while the control group (N = 33) did not receive any metacognitive prompts. The experiment lasted 4 weeks. The study measured students' academic performance, self-regulated learning ability and learning experiences (including cognitive load and technology acceptance). The results indicate that in the GenAI environment, metacognitive support, while not producing significant between-group differences in achievement, enhances students' self-regulated learning abilities particularly in terms of task strategy and self-evaluation, as well as optimizing their learning experience. The study also found that students were at risk of decreasing their level of self-regulated learning if they lacked metacognitive support in the GenAI environment. The conclusion points out that GenAI supports learners to accomplish learning tasks while potentially reducing self-regulated learning effectiveness, and that metacognitive support is key to supporting effective regulation in learners' GenAI environments. This study provides an important theoretical and practical basis for how to better support learners' learning in GenAI environments.Practitioner notes What is already known about this topic SRL is vital for effective learning in digital environments. Generative AI tools, like ChatGPT, can enhance learning but require support. Learners often struggle to apply SRL strategies without guidance. What this paper adds Metacognitive support improves SRL in Generative AI environments. It reduces cognitive load and increases the perceived usefulness of AI tools. Structured support leads to better academic outcomes. Implications for practice and/or policy Teachers should integrate metacognitive support when using AI tools. Teacher training should focus on SRL strategies in tech-rich settings. Policies should promote ethical and effective AI use in education.
27	Students' prompt patterns and its effects in AI-assisted academic writing: Focusing on students' level of AI literacy Generative artificial intelligence; academic writing; GenAI-assisted writing; GenAI-assisted instruction; AI in education; GenAI prompt; AI literacy The increase of generative artificial intelligence (GenAI) in education has emphasized prompt literacy and design, influencing the experience of GenAI-assisted learning. However, there is limited understanding regarding the various prompt patterns that emerge during student-GenAI interaction (SAI) within the context of navigating learning tasks at different levels of AI Literacy or how these patterns are associated with task performance. This study analyzed 19 university students' prompt patterns when interacting with GenAI on academic writing tasks, grouping students by AI literacy level and examining how prompt patterns relate to performance. This study performed content analysis of student-GenAI chat histories and categorical data analysis of student interviews. Pattern differences were then visualized using Gephi 0.10.1. Distinctive prompt patterns were identified: high AI literacy students exhibited descriptive, context-based prompts in collaborative interactions, while low AI literacy students demonstrated general prompts in a student-directed approach. Additionally, student essays were evaluated by five experts to inform how prompt patterns relate to task performance and the Wilcoxon signed-rank test was applied. The two groups demonstrated significant differences across categories of writing performance (content, structure, and expression). This study provides implications for designing and implementing GenAI and student-centered AI-assisted instruction.
28	A classification tool to foster self-regulated learning with generative artificial intelligence by applying self-determination theory: a case of ChatGPT Generative AI; ChatGPT; Self-determination theory; Self-regulated learning; Motivation; Digital support; Delphi study Generative AI such as ChatGPT provides an instant and individualized learning environment, and may have the potential to motivate student self-regulated learning (SRL), more effectively than other non-AI technologies. However, the impact of ChatGPT on student motivation, SRL, and needs satisfaction is unclear. Motivation and the SRL process can be explained using self-determination theory (SDT) and the three phases of forethought, performance, and self-reflection, respectively. Accordingly, a Delphi design was employed in this study to determine how ChatGPT-based learning activities satisfy students' each SDT need, and foster each SRL phase from a teacher perspective. We involved 36 SDT school teachers with extensive expertise in technology enhanced learning to develop a classification tool for learning activities that affect student needs satisfaction and SRL phases using ChatGPT. We collaborated with the teachers in three rounds to investigate and identify the activities, and we revised labels, descriptions, and explanations. The major finding is that a classification tool for 20 learning activities using ChatGPT was developed. The tool suggests how ChatGPT better satisfy SDT-based needs, and fosters the three SRL phrases. This classification tool can assist researchers in replicating, implementing, and integrating successful ChatGPT in education research and development projects. The tool can inspire teachers to modify the activities using generative AI for their own teaching, and inform policymakers on how to develop guidelines for AI in education.
29	The impact of different conversational generative AI chatbots on EFL learners: An analysis of willingness to communicate, foreign language speaking anxiety, and self-perceived communicative competence Generative artificial intelligence (GenAI); GenAI chatbot; Avatar; Willingness to communicate (WTC); Foreign language speaking anxiety (FLSA); Self-perceived communicative competence; (SPCC); English Speaking Based on the Interaction Hypothesis, the study investigates the impact of different conversational Generative Artificial Intelligence (GenAI) chatbots on English as a Foreign Language (EFL) learners' willingness to communicate (WTC), foreign language speaking anxiety (FLSA), selfperceived communicative competence (SPCC) and speaking performance. Three groups of Chinese undergraduate students were recruited: a control group (CG, N = 33) and two experimental groups (EG1, N = 33; EG2, N = 33). The CG interacted with the teacher and classmates during the speaking class. In contrast, EG1 interacted with a text- and voice-based conversational GenAI chatbot called Typebot, while EG2 engaged with a conversational GenAI chatbot that featured both text and voice interaction along with human-like avatars named D-ID Agent. Quantitative analysis using multilevel modelling revealed that EG2 showed significant improvements in WTC and SPCC and a notable reduction in FLSA levels compared to CG. However, the pre- and postspeaking test results showed no significant differences in speaking performance across the groups. Qualitative data from semi-structured interviews supported these findings, highlighting the immersive learning experience and emotional support provided by the human-like avatars. These results suggest that visually embodied GenAI chatbots can effectively enhance the emotional experience during the language learning. The study provides practical insights for language educators on integrating GenAI technologies in language teaching, emphasising the benefits of human-like avatars in fostering a more engaging and supportive learning environment.
30	Exploring the role of self-regulated learnings skills, cognitive flexibility, and metacognitive awareness on generative artificial intelligence attitude Self-regulated learning skills; cognitive flexibility; metacognitive awareness; generative artificial intelligence attitude The use of generative artificial intelligence (GenAI) tools for educational purposes is rapidly becoming widespread. Having a negative attitude may lead to the failure of the integration of these tools. Therefore, it is important to explore the factors that affect students' attitudes towards GenAI tools. In this context, our current study aims to explore the relationship between self-regulated learning skills (SRLS), cognitive flexibility, metacognitive awareness and students' GenAI attitude. In this direction, a correlational study was conducted on 761 university students with GenAI experience, and structural equation modelling (SEM) analysis was performed. Our findings as a result of the analysis show that SRLS and cognitive flexibility have a significant positive effect on GenAI attitudes. In addition, metacognitive awareness is understood to indirectly affect GenAI attitudes by affecting SRLS and cognitive flexibility. These results reveal the importance of SRLS, cognitive flexibility and metacognitive awareness in promoting positive attitudes towards GenAI tools.
31	The new reality of education in the face of advances in generative artificial intelligence artificial intelligence; generative artificial intelligence; ChatGPT; education It is increasingly common to interact with products that seem "intelligent", although the label "artificial intelligence" may have been replaced by other euphemisms. Since November 2022, with the emergence of the ChatGPT tool, there has been an exponential increase in the use of artificial intelligence in all areas. Although ChatGPT is just one of many generative artificial intelligence technologies, its impact on teaching and learning processes has been significant. This article reflects on the advantages, disadvantages, potentials, limits, and challenges of generative artificial intelligence technologies in education to avoid the biases inherent in extremist positions. To this end, we conducted a systematic review of both the tools and the scientific production that have emerged in the six months since the appearance of ChatGPT. Generative artificial intelligence is extremely powerful and improving at an accelerated pace, but it is based on large language models with a probabilistic basis, which means that they have no capacity for reasoning or comprehension and are therefore susceptible to containing errors that need to be contrasted. On the other hand, many of the problems associated with these technologies in educational contexts already existed before their appearance, but now, due to their power, we cannot ignore them, and we must assume what our speed of response will be to analyse and incorporate these tools into our teaching practice.
32	Comparative accuracy of ChatGPT-4, Microsoft Copilot and Google Gemini in the Italian entrance test for healthcare sciences degrees: a cross-sectional study Artificial intelligence; Students; Health occupations; Learning; Education; Nursing; Medical; Physical therapy modalities; Speech therapy; Midwifery Background Artificial intelligence (AI) chatbots are emerging educational tools for students in healthcare science. However, assessing their accuracy is essential prior to adoption in educational settings. This study aimed to assess the accuracy of predicting the correct answers from three AI chatbots (ChatGPT-4, Microsoft Copilot and Google Gemini) in the Italian entrance standardized examination test of healthcare science degrees (CINECA test). Secondarily, we assessed the narrative coherence of the AI chatbots' responses (i.e., text output) based on three qualitative metrics: the logical rationale behind the chosen answer, the presence of information internal to the question, and presence of information external to the question. Methods An observational cross-sectional design was performed in September of 2023. Accuracy of the three chatbots was evaluated for the CINECA test, where questions were formatted using a multiple-choice structure with a single best answer. The outcome is binary (correct or incorrect). Chi-squared test and a post hoc analysis with Bonferroni correction assessed differences among chatbots performance in accuracy. A p-value of < 0.05 was considered statistically significant. A sensitivity analysis was performed, excluding answers that were not applicable (e.g., images). Narrative coherence was analyzed by absolute and relative frequencies of correct answers and errors. Results Overall, of the 820 CINECA multiple-choice questions inputted into all chatbots, 20 questions were not imported in ChatGPT-4 (n = 808) and Google Gemini (n = 808) due to technical limitations. We found statistically significant differences in the ChatGPT-4 vs Google Gemini and Microsoft Copilot vs Google Gemini comparisons (p-value < 0.001). The narrative coherence of AI chatbots revealed "Logical reasoning" as the prevalent correct answer (n = 622, 81.5%) and "Logical error" as the prevalent incorrect answer (n = 40, 88.9%). Conclusions Our main findings reveal that: (A) AI chatbots performed well; (B) ChatGPT-4 and Microsoft Copilot performed better than Google Gemini; and (C) their narrative coherence is primarily logical. Although AI chatbots showed promising accuracy in predicting the correct answer in the Italian entrance university standardized examination test, we encourage candidates to cautiously incorporate this new technology to supplement their learning rather than a primary resource. Trial registration Not required.
33	Factors Influencing University Students' Behavioural Intention to Use Generative Artificial Intelligence for Educational Purposes Based on a Revised UTAUT2 Model behavioural intention; generative AI; PLS-SEM; university students; UTAUT2 BackgroundGenerative artificial intelligence (AI) represents a significant technological leap, with platforms like OpenAI's ChatGPT and Baidu's Ernie Bot at the forefront of innovation. This technology has seen widespread adoption across various sectors of society and is anticipated to revolutionise the educational landscape, especially in the domain of tertiary education. However, there is a gap in understanding factors influencing university students' behavioural intention to use generative AI, leading to hesitation in its adoption.ObjectivesThe primary objective of this study was to investigate the factors that influence university students' behavioural intention to engage with and utilise generative AI. The study sought to delve into the fundamental reasons and obstacles that university students encounter when contemplating the adoption of this technology for their academic endeavours.MethodsThe study used a quantitative research design, utilising a revised version of the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) model. Data were collected from a sample of 380 university students in Changsha, the capital city of Hunan in China. Partial least squares structural equation modelling (PLS-SEM) was used to analyse the relationships between the variables of the model, which included performance expectancy (PE), effort expectancy (EE), social influence (SI), facilitating conditions (FC), learning value, habit and behavioural intention.ResultsThe analysis revealed that PE and EE have a direct impact on learning value. Additionally, SI and FC were found to directly affect the formation of habit. Among these factors, learning value emerged as the most potent predictor of university students' behavioural intention to use generative AI. Habit also demonstrated a significant, albeit smaller, effect on behavioural intention.ConclusionsThe study's findings underscore the importance of learning value in driving the adoption of generative AI among university students. Efforts to enhance the learning value of generative AI could significantly increase its uptake in higher education. Furthermore, the role of habit, while less pronounced, suggests that consistent exposure and use can foster a greater inclination towards generative AI. These insights provide a foundation for targeted interventions aimed at improving the integration and application of generative AI within educational settings. Stakeholders, including educators, policymakers and designers of generative AI, can leverage these findings to create an environment conducive to the adoption and effective use of generative AI in higher education.
34	Understanding the place and value of GenAI feedback: a recognition-based framework Generative AI; feedback; higher education; recognition; respect Generative Artificial Intelligence (GenAI) systems demonstrate impressive capabilities in providing various forms of feedback. However, claims to its potential overlook a fundamental aspect of effective feedback between humans: recognition between teacher and student. This paper critically examines the role of GenAI in providing feedback within higher education contexts, drawing on both the established feedback literature and philosophical work on recognition. Effective feedback is predicated on trusting and respectful relationships, which are in turn grounded in mutual recognition of shared vulnerability and agency. GenAI systems, lacking the capacity for genuine recognition, operate outside of this relational framework. Therefore, while valuable, GenAI feedback cannot fully replicate the pedagogical efficacy of human-provided feedback. However, the limitations of GenAI feedback may at the same time offer unique pedagogical opportunities. We propose that GenAI systems can provide a unique environment for students to receive and engage with feedback. This environment may help students build confidence and prepare for more meaningful engagement in recognitive feedback practices with peers and teachers. We therefore propose a novel framework distinguishing between "recognitive" and "extra-recognitive" feedback. This distinction allows for a more nuanced analysis of GenAI's potential in feedback, offering a means of appropriately integrating GenAI into pedagogical practice.
35	The influence of AI text generators on critical thinking skills in UK business schools Artificial intelligence; critical thinking skills; generative AI; postgraduate higher education; AI text generators This study investigates the influence of generative artificial intelligence (GAI), specifically AI text generators (ChatGPT), on critical thinking skills in UK postgraduate business school students. Using Bloom's taxonomy as theoretical underpinning, we adopt a mixed-method research employing a sample of 107 participants to investigate both the influence and challenges of these technologies in higher education. Our findings reveal that the most significant improvements occurred at the lower levels of Bloom's taxonomy. We identify concerns relating to reliability, accuracy, and potential ethical implications of its application in higher education. The significance of this paper spans across, pedagogy, policy and practice, offering insights into the complex relationship between AI technologies and critical thinking skills. While highlighting the multifaceted aspects of the impact of AI in education, this article serves as a guide to educators and policymakers, stressing the importance of a comprehensive approach to fostering critical thinking and other transferable skills in the higher education landscape.
36	The Role of Materiality in an Era of Generative Artificial Intelligence Artificial intelligence; Epistemic insight; Materiality; Scientific practice; Science studies The introduction of generative artificial intelligence (GenAI) tools like ChatGPT has raised many challenging questions about the nature of teaching, learning, and assessment in every subject area, including science. Unlike other disciplines, natural science is unique because the ontological and epistemological understanding of nature is fundamentally rooted in our interaction with material objects in the physical world. GenAI, powered by statistical probability arising from a massive corpus of text, is devoid of any connection to the physical world. The use of GenAI thus raises concerns about our connection to reality and its effect on science education. This paper emphasizes the importance of materiality (or material reality) in shaping scientific knowledge and argues for its recognition in the era of GenAI. Drawing on the perspectives of new materialism and science studies, the paper highlights how materiality forms an indispensable aspect of human knowledge and meaning-making, particularly in the discipline of science. It further explains how materiality is central to the epistemic authority of science and cautions the outputs generated by GenAI that lack contextualization to a material reality. The paper concludes by providing recommendations for research and teaching that recognize the role of materiality in the context of GenAI, specifically in practical work, scientific argumentation, and learning with GenAI. As we navigate a future dominated by GenAI, understanding how the epistemic authority of science arises from our connection to the physical world will become a crucial consideration in science education.
37	Beware of metacognitive laziness: Effects of generative artificial intelligence on learning motivation, processes, and performance ChatGPT; experimental study; generative AI; hybrid intelligence; learning analytics With the continuous development of technological and educational innovation, learners nowadays can obtain a variety of supports from agents such as teachers, peers, education technologies, and recently, generative artificial intelligence such as ChatGPT. In particular, there has been a surge of academic interest in human-AI collaboration and hybrid intelligence in learning. The concept of hybrid intelligence is still at a nascent stage, and how learners can benefit from a symbiotic relationship with various agents such as AI, human experts and intelligent learning systems is still unknown. The emerging concept of hybrid intelligence also lacks deep insights and understanding of the mechanisms and consequences of hybrid human-AI learning based on strong empirical research. In order to address this gap, we conducted a randomised experimental study and compared learners' motivations, self-regulated learning processes and learning performances on a writing task among different groups who had support from different agents, that is, ChatGPT (also referred to as the AI group), chat with a human expert, writing analytics tools, and no extra tool. A total of 117 university students were recruited, and their multi-channel learning, performance and motivation data were collected and analysed. The results revealed that: (1) learners who received different learning support showed no difference in post-task intrinsic motivation; (2) there were significant differences in the frequency and sequences of the self-regulated learning processes among groups; (3) ChatGPT group outperformed in the essay score improvement but their knowledge gain and transfer were not significantly different. Our research found that in the absence of differences in motivation, learners with different supports still exhibited different self-regulated learning processes, ultimately leading to differentiated performance. What is particularly noteworthy is that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger "metacognitive laziness". In conclusion, understanding and leveraging the respective strengths and weaknesses of different agents in learning is critical in the field of future hybrid intelligence.
38	Students' voices on generative AI: perceptions, benefits, and challenges in higher education ChatGPT; Generative AI; Student perception; AI literacy; Risks; Advantages; Holistic competencies This study explores university students' perceptions of generative AI (GenAI) technologies, such as ChatGPT, in higher education, focusing on familiarity, their willingness to engage, potential benefits and challenges, and effective integration. A survey of 399 undergraduate and postgraduate students from various disciplines in Hong Kong revealed a generally positive attitude towards GenAI in teaching and learning. Students recognized the potential for personalized learning support, writing and brainstorming assistance, and research and analysis capabilities. However, concerns about accuracy, privacy, ethical issues, and the impact on personal development, career prospects, and societal values were also expressed. According to John Biggs' 3P model, student perceptions significantly influence learning approaches and outcomes. By understanding students' perceptions, educators and policymakers can tailor GenAI technologies to address needs and concerns while promoting effective learning outcomes. Insights from this study can inform policy development around the integration of GenAI technologies into higher education. By understanding students' perceptions and addressing their concerns, policymakers can create well-informed guidelines and strategies for the responsible and effective implementation of GenAI tools, ultimately enhancing teaching and learning experiences in higher education.
39	ChatGPT as an automated essay scoring tool in the writing classrooms: how it compares with human scoring Generative AI; ChatGPT; Automated essay scoring; Automated writing evaluation; Argumentative essays With the generative artificial intelligence (AI) tool's remarkable capabilities in understanding and generating meaningful content, intriguing questions have been raised about its potential as an automated essay scoring (AES) system. One such tool is ChatGPT, which is capable of scoring any written work based on predefined criteria. However, limited information is available about the reliability of this tool in scoring the different dimensions of writing quality. Thus, this study examines the relationship between the scores assigned by ChatGPT and a human rater and how consistent ChatGPT-assigned scores are when taken at multiple time points. This study employed a cross-sectional quantitative approach in analyzing 50 argumentative essays from each proficiency level (A2_0, B1_1, B1_2, and B2_0), totaling 200. These essays were rated by ChatGPT and an experienced human rater. Using correlational analysis, the results reveal that ChatGPT's scoring did not align closely with an experienced human rater (i.e., weak to moderate relationships) and failed to establish consistency after two rounds of scoring (i.e., low intraclass correlation coefficient values). These results were primarily attributed to ChatGPT's scoring algorithm, training data, model updates, and inherent randomness. Implications for writing assessment and future studies are discussed.
40	High heels, compass, spider-man, or drug? Metaphor analysis of generative artificial intelligence in academic writing Artificial intelligence; Writing; Metaphor analysis; Cross-cultural skills; Interdisciplinary knowledge This research employed metaphor analysis to explore 277 postgraduate students' perceptions of the role of generative artificial intelligence (GenAI) in academic writing. All participants were international students, from a total of 14 countries and regions, studying in the United Kingdom. Data collection was carried out in two phases. The first was a survey comprising demographic and metaphor-related questions, and the second involved metaphor checking, in which participants provided screenshots of their interactions with GenAI. The data, which were analyzed both qualitatively and quantitatively, yielded 53 unique metaphors for the concept of GenAI in academic writing. We divided these into four conceptual categories in what we term the 4T Pyramid Model: Technical Support (representative metaphor: high-heeled shoes), Text Development (compass), Transformative Potential (Spider-Man), and Threat (drug). The respondents' academic disciplines influenced their perceptions of GenAI, but overall, the results suggest that most viewed it as transformative, i.e., more than just a writing tool. This study's innovative methodology integrating metaphor analysis with real user interactions offers a framework, aligned with Bloom's Taxonomy, that reveals the multi-level benefits and potential risks of GenAI. It also provides actionable insights for AI literacy education, including strategies for effective prompt design.
41	Developing language teachers' professional generative AI competence: An intervention study in an initial language teacher education course  Generative Artificial Intelligence (GenAI) tools have been argued to have transformative potential in education; yet existing literature suggests that language teachers generally lack the abilities to leverage these tools effectively and critically. Conducted in an initial language teacher education programme at a Hong Kong university, this mixed-method intervention study aims to explore the effects of explicit training for using GenAI tools for language teaching in rising pre-service language teachers' professional GenAI competence (P-GenAI-C). 54 M.Ed students took part in an 11-week course intervention aiming to enhance the five aspects in the P-GenAI-C framework. Analysis of pre- and post-intervention questionnaires, which encompassed a mix of open and closed items to gather participants' knowledge and perceptions of utilising GenAI tools, as well as the follow-up interviews, revealed that the intervention was effective in stretching all aspects of pre-service teachers' P-GenAI-C. While there was greater evidence of improvement in participants' pedagogical competence and critical awareness of GenAI tools deployment, there was less evidence of development in other aspects, such as teachers' capacity to guide their students to use GenAI tools effectively and responsibly. This discrepancy might be attributed to the lack of such content in the course intervention. Implications for incorporating elements of P-GenAI-C into teacher preparation courses and programmes are discussed.
42	ChatGPT improves creative problem-solving performance in university students: An experimental study Generative AI; ChatGPT; Creativity; Metacognitive monitoring; Metacognitive experiences; Ill-defined problem -solving task University students often employ generative artificial intelligence tools such as ChatGPT in resolution of ill-defined problem-solving tasks. However, the experimental evidence about effects of ChatGPT on complex problem-solving performance is still missing. In this preregistered experiment, the impact of ChatGPT on performance in a complex creative problem-solving task was investigated in 77 university students solving a task with ChatGPT in comparison to 68 students solving a task without it. ChatGPT use significantly improved self-efficacy for task resolution (d = 0.65) and enhanced the quality (d = 0.69), elaboration (d = 0.61), and originality (d = 0.55) of solutions. Moreover, participants with ChatGPT assistance perceived task as easier (d = 0.56) and requiring less mental effort (d = 0.58). However, use of ChatGPT did not make task resolution more interesting (d = 0.08), and the impact of ChatGPT on metacognitive monitoring accuracy was unclear. Although there were no significant differences in absolute accuracy between students solving the task with and without the assistance of ChatGPT, the absence of correlation between self-evaluation judgments and performance suggests that participants struggled to calibrate their self-evaluations when using ChatGPT. Notably, the perceived usefulness of ChatGPT appeared to inform self-evaluation judgments, resulting in higher inaccuracy. The implications for hybrid human-AI regulation (HHAIR) theory are discussed. To regulate effectively, students using AI tools should focus on valid metacognitive cues instead of the perceived ease of ChatGPT-assisted problem-solving.
43	Generative artificial intelligence (ChatGPT): Implications for management educators Academic research; Teaching; Learning; Digital transformation; Management education; Artificial intelligence; ChatGPT ChatGPT has been one of the most talked about computer programs amongst management educators in recent weeks due to its transformative ability to change how assessments are undertaken and graded. Unlike other educational technologies that can be tracked when used, ChatGPT has superior abilities that make it virtually untraceable when used. This creates a dilemma for management educators wanting to utilise the technology whilst staying relevant but also interested in authentic learning. Thus, it is critical for management educators to quickly implement policies regarding ChatGPT and subsequent new generative artificial intelligence because of its ease of use and affordability. This article is conceptual in nature and discusses ChatGPT as a generative form of artificial intelligence that presents challenges for management educators that need to be addressed through appropriate strategies. Thereby contributing to the literature on how technological innovations can be included in curriculum design and management learning practices. Practical and managerial implications are stated that highlight the critical need to reexamine existing education practices as a way of incorporating new technological innovation that can be utilised in a beneficial way.
44	Transforming Assessment: The Impacts and Implications of Large Language Models and Generative AI assessment; generative AI; LLMs The remarkable strides in artificial intelligence (AI), exemplified by ChatGPT, have unveiled a wealth of opportunities and challenges in assessment. Applying cutting-edge large language models (LLMs) and generative AI to assessment holds great promise in boosting efficiency, mitigating bias, and facilitating customized evaluations. Conversely, these innovations raise significant concerns regarding validity, reliability, transparency, fairness, equity, and test security, necessitating careful thinking when applying them in assessments. In this article, we discuss the impacts and implications of LLMs and generative AI on critical dimensions of assessment with example use cases and call for a community effort to equip assessment professionals with the needed AI literacy to harness the potential effectively.
45	Can Generative AI and ChatGPT Outperform Humans on Cognitive-Demanding Problem-Solving Tasks in Science? Generative artificial intelligence (GAI); ChatGPT; GPT-4; NAEP; Science assessment; Cognitive load; Problem-solving This study aimed to examine an assumption regarding whether generative artificial intelligence (GAI) tools can overcome the cognitive intensity that humans suffer when solving problems. We examine the performance of ChatGPT and GPT-4 on NAEP science assessments and compare their performance to students by cognitive demands of the items. Fifty-four 2019 NAEP science assessment tasks were coded by content experts using a two-dimensional cognitive load framework, including task cognitive complexity and dimensionality. ChatGPT and GPT-4 answered the questions individually and were scored using the scoring keys provided by NAEP. The analysis of the available data for this study was based on the average student ability scores for students who answered each item correctly and the percentage of students who responded to individual items. The results showed that both ChatGPT and GPT-4 consistently outperformed most students who answered each individual item in the NAEP science assessments. As the cognitive demand for NAEP science assessments increases, statistically higher average student ability scores are required to correctly address the questions. This pattern was observed for Grades 4, 8, and 12 students respectively. However, ChatGPT and GPT-4 were not statistically sensitive to the increase of cognitive demands of the tasks, except for Grade 4. As the first study focusing on comparing cutting-edge GAI and K-12 students in problem-solving in science, this finding implies the need for changes to educational objectives to prepare students with competence to work with GAI tools such as ChatGPT and GPT-4 in the future. Education ought to emphasize the cultivation of advanced cognitive skills rather than depending solely on tasks that demand cognitive intensity. This approach would foster critical thinking, analytical skills, and the application of knowledge in novel contexts among students. Furthermore, the findings suggest that researchers should innovate assessment practices by moving away from cognitive intensity tasks toward creativity and analytical skills to more efficiently avoid the negative effects of GAI on testing.
46	Pedagogical framework for hybrid intelligent feedback Artificial intelligence; artificial cognition; feedback; generative AI; hybrid intelligent feedback; human-AI collaboration Generative AI (GenAI) has gained attention as a new feedback source in education because it can generate human-like text. However, its use in feedback lacks a strong pedagogical framework, which is necessary for effective implementation. This paper addresses this gap. It outlines human-centered feedback challenges, and then explores human and artificial cognition differences, highlighting the need for hybrid intelligence. Next, it positions GenAI feedback within feedback theory and proposes a definition for GenAI feedback. The paper conceptualizes the role of GenAI feedback as either an independent source or as part of a collaborative process with humans referred to as "Hybrid Intelligent Feedback". Building on this conceptualization, it discusses the approaches and principles of hybrid intelligent feedback and then proposes a pedagogical framework that outlines the implementation steps for hybrid intelligent feedback. The paper concludes by describing the pedagogical framework and outlining recommendations for future research on hybrid intelligent feedback.
47	Knowledge (Co-)Construction Among Artificial Intelligence, Novice Teachers, and Experienced Teachers in an Online Professional Learning Community artificial intelligence; online professional learning community; teacher professional development Background: There are various challenges to teachers' use of generative artificial intelligence (GenAI) for professional learning. Although GenAI is expected to play a transformative role in teachers' learning, its impact on them remains subtle. Objectives: Guided by community of practice, this paper examines the integration of GenAI into an online professional learning community (OPLC) to facilitate knowledge co-construction among GenAI, novice teachers and experienced teachers. Methods: We used a mixed-methods approach that included topic modelling and sentiment analysis on the quantitative side and content analysis for the qualitative data. Results: We identified the top three latent themes in the OPLC's discourse-(1) generating instructional material, (2) assessment, and (3) pedagogy-and six distinct teacher-GenAI interaction profiles. For novice teachers, these included 'engaged AI explorers', 'selective satisfiers' and 'silent strategists'; and among experienced teachers, we discerned 'careful critics', 'reflective realists' and 'cautious contemplators'. Novice teachers exhibited technological adaptivity, while experienced ones engaged reflectively with content and focused more on students, and GenAI proved effective at providing instructional materials. Conclusions: The findings demonstrate how GenAI can contribute to knowledge co-construction, as a facilitator of rather than a replacement for human interaction.
48	Enhancing academic performance of business students using generative AI: An interactive-constructive-active-passive (ICAP) self-determination perspective ChatGPT; Technology integration; ICAP framework; Self-determination theory; Academic performance; Epistemic curiosity Generative artificial intelligence (GAI) tools, such as ChatGPT, have emerged as valuable assets in higher education. Despite their potential benefits in academic support, questions persist about the concrete advantages of integrating this technology into learning processes and its impact on academic outcomes. This research addresses this gap by investigating the influence of technology integration on academic performance, employing the Interactive-Constructive-Active-Passive (ICAP) framework and self-determination theory. The empirical findings from Chinese business students using Wenjuanxing platform reveal a positive impact of technology integration on business students' motivation, encompassing their learning desires, self-efficacy, and future beliefs, ultimately leading to enhanced academic performance. Notably, while epistemic curiosity augments the effects of technology integration on learning desires and future beliefs, its influence on self-efficacy is not significant. This suggests that curiosity alone might not be enough to alter deeply ingrained beliefs about one's capabilities. In conclusion, this study underscores the academic significance of these findings and their practical implications for educators and business students in optimizing ChatGPT's potential for academic success.
49	The false positives and false negatives of generative AI detection tools in education and academic research: The case of ChatGPT Artificial intelligence; Generative pre-trained transformer; Machine generated contents (MGC); False positive; negative; Text generation; ChatGPT Generative Pre-trained Transformers like ChatGPT are examples of AI systems which produce human-like responses in different forms such as text or images that have demonstrated excellent performance in producing logical and contextually relevant answers. However, the false positive/ negative detection of generative AI has been noted as a challenge. In this article, statistical ex-periments are conducted to test the chances of false positive and false negative detection of AI -generated text. It was found that the detected likelihoods of generative AI in articles' abstracts is much lower than that found in paragraphs taken from the literature section of the selected articles. This means that literature parts have higher likelihoods to falsely demonstrate AI -generated text. On the other hand, when genuine texts are compared with AI-generated texts, it is observed that there is a noticeable margin of overlap between their distributions and therefore type I and type II errors fall within the realm of possibility. We show that despite these challenges, generative AI like ChatGPT continues to be a promising tool for communication and information retrieval. However, it is vital to address the concerns regarding false detection of AI generated text and ensure that these models are used in ethical and responsible conduct.
50	Generative AI and the future of higher education: a threat to academic integrity or reformation? Evidence from multicultural perspectives GenAI; Higher education; Potential; Concerns; Ethical regulations; Cultural dimensions In recent years, higher education (HE) globally has witnessed extensive adoption of technology, particularly in teaching and research. The emergence of generative Artificial Intelligence (GenAI) further accelerates this trend. However, the increasing sophistication of GenAI tools has raised concerns about their potential to automate teaching and research processes. Despite widespread research on GenAI in various fields, there is a lack of multicultural perspectives on its impact and concerns in HE. This study addresses this gap by examining the usage, benefits, and concerns of GenAI in higher education from a multicultural standpoint. We employed an online survey that collected responses from 1217 participants across 76 countries, encompassing a broad range of gender categories, academic disciplines, geographical locations, and cultural orientations. Our findings revealed a high level of awareness and familiarity with GenAI tools among respondents. A significant portion had prior experience and expressed the intention to continue using these tools, primarily for information retrieval and text paraphrasing. The study emphasizes the importance of GenAI integration in higher education, highlighting both its potential benefits and concerns. Notably, there is a strong correlation between cultural dimensions and respondents' views on the benefits and concerns related to GenAI, including its potential as academic dishonesty and the need for ethical guidelines. We, therefore, argued that responsible use of GenAI tools can enhance learning processes, but addressing concerns may require robust policies that are responsive to cultural expectations. We discussed the findings and offered recommendations for researchers, educators, and policymakers, aiming to promote the ethical and effective integration of GenAI tools in higher education.
51	A scoping review on how generative artificial intelligence transforms assessment in higher education Generative artificial intelligence; Scoping review; Higher education; Assessment; Educational policy; Professional development; Assessment literacy; AI literacy Generative artificial intelligence provides both opportunities and challenges for higher education. Existing literature has not properly investigated how this technology would impact assessment in higher education. This scoping review took a forward-thinking approach to investigate how generative artificial intelligence transforms assessment in higher education. We used the PRISMA extension for scoping reviews to select articles for review and report the results. In the screening, we retrieved 969 articles and selected 32 empirical studies for analysis. Most of the articles were published in 2023. We used three levels-students, teachers, and institutions-to analyses the articles. Our results suggested that assessment should be transformed to cultivate students' self-regulated learning skills, responsible learning, and integrity. To successfully transform assessment in higher education, the review suggested that (i) teacher professional development activities for assessment, AI, and digital literacy should be provided, (ii) teachers' beliefs about human and AI assessment should be strengthened, and (iii) teachers should be innovative and holistic in their teaching to reflect the assessment transformation. Educational institutions are recommended to review and rethink their assessment policies, as well as provide more inter-disciplinary programs and teaching.
52	Editorial Position Paper: Exploring the Potential of Generative Artificial Intelligence in Education: Applications, Challenges, and Future Research Directions Generative artificial intelligence; ChatGPT; Midjourney; Artificial Intelligence in education; Programming prompt Generative artificial intelligence (GAI) applications, such as ChatGPT (Chat Generative Pre -trained Transformer) and Midjourney, have recently attracted much attention from researchers and school teachers. While many people are eager to learn more about GAI applications, some scholars are concerned about the potential misuse of them. It is predicted that the use of GAI applications will increase rapidly in the coming years. Therefore, it is important to consider the challenges and research issues through some concrete application examples of using GAI for education. In this position paper, the authors aim to address these issues from the perspectives of academic research and educational objectives. Along with defining GAI, several illustrative examples of using GAI applications in educational settings are provided. Moreover, potential research issues of GAI-based learning, including research design, relevant learning strategies, research focus, and measuring tools, are discussed. ET&S journal is especially welcoming research on unlocking the potential of GAI for education to realize the two notions of "Knowing [why] is the essential element for learners to have in-depth understanding" and "It is all about prompts: Get rid of the 'search' mindset and use 'programming prompt' instead."
53	Is it harmful or helpful? Examining the causes and consequences of generative AI usage among university students Workload; Time pressure; Sensitivity to quality; Sensitivity to rewards; ChatGPT usage; Procrastination; Memory loss; Academic performance While the discussion on generative artificial intelligence, such as ChatGPT, is making waves in academia and the popular press, there is a need for more insight into the use of ChatGPT among students and the potential harmful or beneficial consequences associated with its usage. Using samples from two studies, the current research examined the causes and consequences of ChatGPT usage among university students. Study 1 developed and validated an eight-item scale to measure ChatGPT usage by conducting a survey among university students (N = 165). Study 2 used a three-wave time-lagged design to collect data from university students (N = 494) to further validate the scale and test the study's hypotheses. Study 2 also examined the effects of academic workload, academic time pressure, sensitivity to rewards, and sensitivity to quality on ChatGPT usage. Study 2 further examined the effects of ChatGPT usage on students' levels of procrastination, memory loss, and academic performance. Study 1 provided evidence for the validity and reliability of the ChatGPT usage scale. Furthermore, study 2 revealed that when students faced higher academic workload and time pressure, they were more likely to use ChatGPT. In contrast, students who were sensitive to rewards were less likely to use ChatGPT. Not surprisingly, use of ChatGPT was likely to develop tendencies for procrastination and memory loss and dampen the students' academic performance. Finally, academic workload, time pressure, and sensitivity to rewards had indirect effects on students' outcomes through ChatGPT usage.
54	What Deserve Studying the Most? A Q-Methodology Approach to Explore Stakeholders' Perspectives on Research Priorities in GenAI-Supported Second Language Education generative artificial intelligence; perspectives; Q methodology; research priorities; second language education Recently, there has been a significant increase in research on Generative Artificial Intelligence (GenAI) in the domain of second language (L2) education. Given the limited resources, it is essential for GenAI research to focus on key areas. However, there is still uncertainty about which topics should be prioritised. Research priorities are often shaped by individual researchers' personal interests, which can skew the focus of many studies. Additionally, stakeholder perspectives on these topics can vary widely. Therefore, this study employs the Q methodology to reveal the consensus among different stakeholder groups. To this end, a total of 19 participants, including six researchers, six teachers and seven students, engaged in a Q-sort exercise involving 34 statements. Through KADE software, the subsequent Centroid Factor Analysis and varimax rotation were used to extract patterns. The analysis revealed three common perspectives across stakeholder groups: psychological factors of teachers and students, multiple scenarios of measurement and the improvement of L2 competence. These findings provide valuable insights that can inform and refine research agendas in GenAI for L2 education, optimising the allocation of resources.
55	Do generative AI technologies play a double-edged sword role in education? Findings from hybrid approach using PLS-SEM and fsQCA Epistemic curiosity; Fuzzy-set qualitative comparative analysis; Generative AI technologies; Knowledge acquisition; Learning performance; Social interaction Based on the self-determination theory (SDT), this evaluates the effects of generative artificial intelligence (Gen-AI) on learning performance within China's education sector, emphasizing the roles of social interaction, utilitarian benefit, knowledge acquisition, and epistemic curiosity. The study employs a dual method, using PLS-SEM and fsQCA approaches for data analysis. Data were collected through an online questionnaire from students and teachers from Chinese institutes. The findings suggest that students and teachers have positive opinions on the influence of Gen-AI on learning performance through social interaction and knowledge acquisition. Utilitarian benefits positively mediate the affiliation between Gen-AI and teachers' learning performance, but in the case of students, they negatively mediate. Furthermore, epistemic curiosity acts as a positive moderator between Gen-AI technologies and social interaction and knowledge acquisition, but it has a negative relationship with Gen-AI technologies and utilitarian benefits. Furthermore, the fsQCA analysis reveals robust configurations with high consistency, explaining learning performance outcomes reliably and highlighting significant and unique contributions of specific configurations. The implications of this study emphasize how crucial generative AI technologies are in educational frameworks to optimize their potential benefits and enhance learning outcomes in China's quickly changing educational landscape.
56	Empowering student self-regulated learning and science education through ChatGPT: A pioneering pilot study chatbot; ChatGPT; generative AI; large language model; science education; self-regulated learning In recent years, AI technologies have been developed to promote students' self-regulated learning (SRL) and proactive learning in digital learning environments. This paper discusses a comparative study between generative AI-based (SRLbot) and rule-based AI chatbots (Nemobot) in a 3-week science learning experience with 74 Secondary 4 students in Hong Kong. The experimental group used SRLbot to maintain a regular study habit and facilitate their SRL, while the control group utilized rule-based AI chatbots. Results showed that SRLbot effectively enhanced students' science knowledge, behavioural engagement and motivation. Quantile regression analysis indicated that the number of interactions significantly predicted variations in SRL. Students appreciated the personalized recommendations and flexibility of SRLbot, which adjusted responses based on their specific learning and SRL scenarios. The ChatGPT-enhanced instructional design reduced learning anxiety and promoted learning performance, motivation and sustained learning habits. Students' feedback on learning challenges, psychological support and self-regulation behaviours provided insights into their progress and experience with this technology. SRLbot's adaptability and personalized approach distinguished it from rule-based chatbots. The findings offer valuable evidence for AI developers and educators to consider generative AI settings and chatbot design, facilitating greater success in online science learning.
57	A critical review of GenAI policies in higher education assessment: a call to reconsider the "originality" of students' work Generative AI; policy analysis; assessment; ChatGPT; higher education This study offers a critical examination of university policies developed to address recent challenges presented by generative AI (GenAI) to higher education assessment. Drawing on Bacchi's 'What's the problem represented to be' (WPR) framework, we analysed the GenAI policies of 20 world-leading universities to explore what are considered problems in this AI-mediated assessment landscape and how these problems are represented in policies. Although miscellaneous GenAI-related problems were mentioned in these policies (e.g. reliability of AI-generated outputs, equal access to GenAI), the primary problem represented is that students may not submit original work for assessment. In the current framing, GenAI is often viewed as a type of external assistance separate from the student's independent efforts and intellectual contribution, thereby undermining the originality of their work. We argue that such problem representation fails to acknowledge how the rise of GenAI further complicates the process of producing original work and what it means by originality in a time when knowledge production becomes increasingly distributed, collaborative and mediated by technology. Therefore, a critical silence in higher education policies concerns the evolving notion of originality in the digital age and a more inclusive approach to address the originality of students' work is required.
58	Performance of artificial intelligence on Turkish dental specialization exam: can ChatGPT-4.0 and gemini advanced achieve comparable results to humans? AI; Artificial Intelligence; ChatGPT; Dentistry; Gemini; Large Language models BackgroundAI-powered chatbots have spread to various fields including dental education and clinical assistance to treatment planning. The aim of this study is to assess and compare leading AI-powered chatbot performances in dental specialization exam (DUS) administered in Turkey and compare it with the best performer of that year. MethodsDUS questions for 2020 and 2021 were directed to ChatGPT-4.0 and Gemini Advanced individually. DUS questions were manually entered into AI-powered chatbot in their original form, in Turkish. The results obtained were compared with each other and the year's best performers. Candidates who score at least 45 points on this centralized exam are deemed to have passed and are eligible to select their preferred department and institution. The data was statistically analyzed using Pearson's chi-squared test (p < 0.05). ResultsChatGPT-4.0 received 83.3% correct response rate on the 2020 exam, while Gemini Advanced received 65% correct response rate. On the 2021 exam, ChatGPT-4.0 received 80.5% correct response rate, whereas Gemini Advanced received 60.2% correct response rate. ChatGPT-4.0 outperformed Gemini Advanced in both exams (p < 0.05). AI-powered chatbots performed worse in overall score (for 2020: ChatGPT-4.0, 65,5 and Gemini Advanced, 50.1; for 2021: ChatGPT-4.0, 65,6 and Gemini Advanced, 48.6) when compared to overall scores of the best performer of that year (68.5 points for year 2020 and 72.3 points for year 2021). This poor performance also includes the basic sciences and clinical sciences sections (p < 0.001). Additionally, periodontology was the clinical specialty in which both AI-powered chatbots achieved the best results, the lowest performance was determined in the endodontics and orthodontics. ConclusionAI-powered chatbots, namely ChatGPT-4.0 and Gemini Advanced, passed the DUS by exceeding the threshold score of 45. However, they still lagged behind the top performers of that year, particularly in basic sciences, clinical sciences, and overall score. Additionally, they exhibited lower performance in some clinical specialties such as endodontics and orthodontics.
59	ChatGPT-supported collaborative argumentation: Integrating collaboration script and argument mapping to enhance EFL students' argumentation skills Argumentation learning; Argument mapping; ChatGPT; Collaboration script; EFL; Interactive learning environments Argumentation is a complex skill essential for English as a Foreign Language (EFL) students to effectively use their English language and reasoning abilities in writing and speaking. Constructing arguments without proper collaborative scaffolding and technological support can be cognitively demanding. Generative artificial intelligence (Gen AI) in learning shows potential to meet students' individual needs. In this quasi-experimental study, we proposed using ChatGPT, a large language model, to guide students through three stages of collaboration script: preparation, interaction, and reflection stages. It ensures active participation and contribute to the collaborative task, while facilitating the knowledge construction in argument mapping to organize and represent the structure of arguments such as clarifying claim. A total of 67 freshmen university students participated, with 34 of them using ChatGPT-supported collaborative argumentation (ChatGPT-CA) and 33 using conventional-based collaborative argumentation (C-CA) which relied on a conventional pedagogical method without Gen AI support. The findings showed that the ChatGPT-CA approach significantly enhanced EFL students' argumentative speaking performance, critical thinking awareness, and collaboration tendency compared to the C-CA approach with large effect sizes (eta 2 = 0.33; 0.29; 0.33). Furthermore, using ChatGPT to learn argumentation improved the quality of arguments for students at different English proficiency levels. However, limitations such as the influence of prompt quality on ChatGPT's effectiveness were noted. Therefore, ensuring high-quality prompts is crucial for educators. This study provides valuable insights for developing EFL students' argumentation skills based on their proficiency levels and highlights the potential of integrating ChatGPT with proven pedagogical strategies to enhance argumentation skills in EFL contexts.
60	A study on the impact of Generative Artificial Intelligence supported Situational Interactive Teaching on students' 'flow' experience and learning effectiveness - a case study of legal education in China Generative Artificial Intelligence; Situational Interactive Teaching; flow experience; learning effect; legal education The rapid advancement of Generative Artificial Intelligence Technology has increasingly drawn attention to its potential applications in the educational sector. This study aims to investigate the effects of Situational Interactive Teaching, facilitated by generative artificial intelligence, on students' learning outcomes and flow experiences. A series of experiments were designed to compare the performance of a Generative Artificial Intelligence-supported Situational Interactive Teaching Method with a Traditional Video Interactive Teaching Method. Data was collected using research tools such as questionnaires and test questions to assess students' cognitive levels, learning effectiveness, flow experiences, and subjective evaluations during the instructional process. The analysis revealed distinct differences between the two teaching methods. The findings suggest that compared to traditional teaching methods, Generative Artificial Intelligence-supported Situational Interactive Teaching significantly improves students' learning outcomes in cognitive, skill, and affective domains, while also enhancing flow experiences. These positive effects are not limited by individual student differences, indicating broad applicability. Furthermore, this teaching approach can foster a positive feedback loop between learning effectiveness and flow experience. In conclusion, this study confirms the effective application of generative artificial intelligence technology in legal education, providing empirical evidence for the promotion of this innovative teaching model in the educational field.
61	Enhancing postgraduate digital academic writing proficiency: the interplay of artificial intelligence tools and ChatGPT Artificial intelligence; AI tools; generative AI; academic writing; ChatGPT; postgraduate students Artificial Intelligence (AI) has rapidly emerged as a pivotal force in a multitude of sectors. This research explores the growing convergence of AI tools, such as ChatGPT, in the field of academic writing, with a focus on 136 postgraduate students from China. These students were randomized into groups that utilized AI-integrated tools in both online and offline environments. The study involved designing hybrid instructional modules that blend online and offline elements. Furthermore, an extensive questionnaire was used to evaluate the advancements of postgraduate students in domains such as digital readiness, writing self-efficacy, student engagement, and academic emotional health. The results from this investigation highlight significant improvements in several facets of postgraduate involvement, including behavioral, emotional, and cognitive engagement, as well as writing self-efficacy. The study also probes the impact of digital readiness on academic involvement, revealing a positive association with student engagement, writing self-efficacy, and academic sentiments. By augmenting students' technical proficiency, digital literacy, and acclimation to digital tools and platforms, educational institutions can bolster academic engagement, amplify writing confidence, and foster favorable academic emotion.
62	Critical analysis of the technological affordances, challenges and future directions of Generative AI in education: a systematic review Generative AI; education; systematic literature review; technological affordance; challenges Generative artificial intelligence has been regarded as a transformative tool. While responsible and ethical applications could bring opportunities to education, their misuse could pose demanding challenges. It is necessary to clarify the technological affordances and challenges in a normative way to lay the foundation for future development. This study addressed the dearth of literature by performing a systematic review, aiming to (i) explore the utility and availability from the technological affordances perspective; (ii) summarize the current challenges in risks prevention; and (iii) propose possible directions for future research and practice. A total of 27 academic articles published in core journals between 2020 and 2023 were analyzed, and the inductive grounded approach was used to categorize the coding schemes. The findings revealed four technological affordances: accessibility, personalization, automation, and interactivity; and five challenges: academic integrity risk, response errors and bias, over-dependence risk, the widening digital divide, and privacy and security. We propose future directions, encourage educational organizations to formulate guidelines for the ethical use of AI in education, call on educators to embrace future trends in AI education instead of shunning its use, and guide students to treat it as a thought aid and reference, rather than relying on it entirely.
63	Does Generative Artificial Intelligence Improve the Academic Achievement of College Students? A Meta-Analysis college students; generative artificial intelligence (Gen-AI); academic achievement; instruction design; meta-analysis The use of generative artificial intelligence (Gen-AI) to assist college students in their studies has become a trend. However, there is no academic consensus on whether Gen-AI can enhance the academic achievement of college students. Using a meta-analytic approach, this study aims to investigate the effectiveness of Gen-AI in improving the academic achievement of college students and to explore the effects of different moderating variables. A total of 28 articles (65 independent studies, 1909 participants) met the inclusion criteria for this study. The results showed that Gen-AI significantly improved college students' academic achievement with a medium effect size (Hedges's g = 0.533, 95% CI [0.408,0.659], p < .05). There were within-group differences in the three moderator variables, activity categories, sample size, and generated content, when the generated content was text (g = 0.554, p < .05), and sample size of 21-40 (g = 0.776, p < .05), the use of independent learning styles (g = 0.600, p < .05) had the most significant improvement in college student's academic achievement. The intervention duration, the discipline types, and the assessment tools also had a moderate positive impact on college students' academic achievement, but there were no significant within-group differences in any of the moderating variables. This study provides a theoretical basis and empirical evidence for the scientific application of Gen-AI and the development of educational technology policy.
64	Generative AI chatbots in higher education: a review of an emerging research area AI chatbots; Generative AI; Large language models; Discourses; Theories of learning Artificial intelligence (AI) chatbots trained on large language models are an example of generative AI which brings promises and threats to the higher education sector. In this study, we examine the emerging research area of AI chatbots in higher education (HE), focusing specifically on empirical studies conducted since the release of ChatGPT. Our review includes 23 research articles published between December 2022 and December 2023 exploring the use of AI chatbots in HE settings. We take a three-pronged approach to the empirical data. We first examine the state of the emerging field of AI chatbots in HE. Second, we identify the theories of learning used in the empirical studies on AI chatbots in HE. Third, we scrutinise the discourses of AI in HE framing the latest empirical work on AI chatbots. Our findings contribute to a better understanding of the eclectic state of the nascent research area of AI chatbots in HE, the lack of common conceptual groundings about human learning, and the presence of both dystopian and utopian discourses about the future role of AI chatbots in HE.
65	AI-generated feedback on writing: insights into efficacy and ENL student preference Automated writing evaluation; ChatGPT; Artificial intelligence; Language education The question of how generative AI tools, such as large language models and chatbots, can be leveraged ethically and effectively in education is ongoing. Given the critical role that writing plays in learning and assessment within educational institutions, it is of growing importance for educators to make thoughtful and informed decisions as to how and in what capacity generative AI tools should be leveraged to assist in the development of students' writing skills. This paper reports on two longitudinal studies. Study 1 examined learning outcomes of 48 university English as a new language (ENL) learners in a six-week long repeated measures quasi experimental design where the experimental group received writing feedback generated from ChatGPT (GPT-4) and the control group received feedback from their human tutor. Study 2 analyzed the perceptions of a different group of 43 ENLs who received feedback from both ChatGPT and their tutor. Results of study 1 showed no difference in learning outcomes between the two groups. Study 2 results revealed a near even split in preference for AI-generated or human-generated feedback, with clear advantages to both forms of feedback apparent from the data. The main implication of these studies is that the use of AI-generated feedback can likely be incorporated into ENL essay evaluation without affecting learning outcomes, although we recommend a blended approach that utilizes the strengths of both forms of feedback. The main contribution of this paper is in addressing generative AI as an automatic essay evaluator while incorporating learner perspectives.
66	The role of generative AI and hybrid feedback in improving L2 writing skills: a comparative study Generative AI; L2 writing; academic writing; feedback; critical thinking This study examines the impact of Generative AI (GenAI) - generated feedback and hybrid feedback (GenAI and human tutor input) on L2 academic writing skills. Over 12 weeks, 60 Chinese EFL students were divided into two groups: Group 1 received only GenAI feedback, while Group 2 received hybrid feedback. Writing performance was assessed using GRE writing rubrics. Results showed that GenAI feedback improved Group 1's writing performance, particularly in grammar and sentence variety. However, its impact on higher - order skills like critical thinking and organization was limited. In contrast, Group 2 demonstrated greater improvement, with significant gains in organization, critical thinking, and sentence variety. The hybrid feedback group also reported higher motivation and more positive feedback perceptions. These findings suggest that while GenAI feedback is effective for basic writing skills, hybrid feedback is more beneficial for developing complex academic writing skills. The study highlights the importance of combining AI and human feedback to meet diverse learning needs in L2 writing instruction. Future research should explore the long - term effects of hybrid feedback and its application in different writing contexts.
67	The effects of generative AI on initial language teacher education: The perceptions of teacher educators Generative AI; Initial language teacher education; ChatGPT; Teacher educators Since the public release of ChatGPT in November 2022, generative AI tools-capable of creating human-like content such as audio, code, images, text, simulations, 3D objects, and videos-have gained significant attention. While the impact of these tools on language teaching and learning has been widely speculated, the perspective of language teacher educators concerning their influence on initial language teacher education (ILTE) remains unexplored. This study investigates how teacher educators, who play a crucial role in adapting ILTE to technological advancements, perceive the effects of generative AI tools on ILTE. Data were collected through in-depth interviews with thirteen English language teacher educators from all four Hong Kong governmentfunded universities offering ILTE. Findings reveal that participants believe generative AI tools will substantially affect the ILTE curriculum, instruction, and assessment. However, most participants believed they lacked the confidence and competence to address the implications of generative AI tools effectively. This study highlights the need for further research and training to support teacher educators in adapting ILTE to the emerging influence of generative AI.
68	AI in the classroom: Exploring students' interaction with ChatGPT in programming learning Student-AI interaction; ChatGPT integration; Programming education; AI in education As being more prevalent in educational settings, understanding the impact of artificial intelligence tools on student behaviors and interactions has become crucial. In this regard, this study investigates the dynamic interactions between students and ChatGPT in programming learning, focusing on how different instructional interventions influence their learning and AI-interaction. Conducted over three sessions, students were allowed to use ChatGPT to complete programming tasks. The first session had no guidance, the second included hands-on training in prompt writing and effective ChatGPT use, and the third provided a lab guide with sample prompts. After each session, students took a post-test on the activity's subject. Analyzing students' prompting behaviors, five AI interaction profiles were identified: AI-Reliant Code Generators, AI-Reliant Code Generator & Refiners, AI-Collaborative Coders, AI-Assisted Code Refiners, and AI-Independent Coders. These profiles were examined to understand their evolution across interventions and their relationship with students' learning performance. Findings revealed significant changes in profile distribution across interventions, and a notable difference between students' post-test scores and their AI interaction profiles. Besides, training in prompting skills and effective use of AI significantly impacted students' interactions with AI. These insights can contribute to the knowledge of integrating generative AI tools in education, highlighting how AI can enhance teaching practices. Understanding student-AI interaction dynamics can allow educators to tailor instructional strategies for optimal learning. This study also underscores the importance of guidance on effective AI use and prompting skills, which can lead students to use AI more meaningfully for their learning.
69	Expert or machine? Comparing the effect of pairing student teacher with in-service teacher and ChatGPT on their critical thinking, learning performance, and cognitive load in an integrated-STEM course STEM education; collaborative learning; ChatGPT; student teacher; AI-assisted learning For student teachers' professional development, the emergence of generative artificial intelligence (AI) represents both opportunity and challenge. This exploratory quasi-experimental study aims to investigate the effects of "Human-Human" and "Human-Machine" collaborative learning approaches on the SETM teaching training performance of student teachers. Twenty-three student teachers were divided into two groups within a single class, each adopting one learning method. The experiment lasted for two months with weekly three-hour sessions. Data were analysed focusing on critical thinking, learning performance, and cognitive load between the groups. The results indicated that student teachers using ChatGPT showed higher critical thinking systematicity, task completion efficiency, and experienced lower cognitive load. Student teachers paired with in-service teachers slightly outperformed those with ChatGPT on the final teaching design proposal. These findings underscore the potential and varying strengths of AI tools like ChatGPT and human teachers. For further research, refined collaborative learning scaffolding are recommended to explore the impact and potential of AI-assisted and in-service teacher-involved collaboration. The study's implications could guide educators, policymakers, and AI developers in optimizing the AI-enhanced collaborative learning strategies and shed light on the new formation of human-machine collaborative intelligence in the scope of education.
70	A comprehensive AI policy education framework for university teaching and learning AI policy framework; Artificial intelligence; ChatGPT; Ethics; Assessment This study aims to develop an AI education policy for higher education by examining the perceptions and implications of text generative AI technologies. Data was collected from 457 students and 180 teachers and staff across various disciplines in Hong Kong universities, using both quantitative and qualitative research methods. Based on the findings, the study proposes an AI Ecological Education Policy Framework to address the multifaceted implications of AI integration in university teaching and learning. This framework is organized into three dimensions: Pedagogical, Governance, and Operational. The Pedagogical dimension concentrates on using AI to improve teaching and learning outcomes, while the Governance dimension tackles issues related to privacy, security, and accountability. The Operational dimension addresses matters concerning infrastructure and training. The framework fosters a nuanced understanding of the implications of AI integration in academic settings, ensuring that stakeholders are aware of their responsibilities and can take appropriate actions accordingly.
71	The synergy of generative AI and inquiry-based learning: transforming the landscape of English teaching and learning AI (Artificial intelligence) tools; language learning; teaching; education/educational; EFL (English as a foreign language); ChatGPT This study investigates the integration of artificial intelligence (AI) tools, such as ChatGPT, into English as a Foreign Language (EFL) teacher learning, aiming to transcend the traditional, test-centric constraints of language education through inquiry-based learning (IBL). Conducted over a semester, the research involved thirteen in-service teachers who engaged in crafting lesson plans, executing microteaching sessions, and documenting their reflections. These qualitative data sources provided insights into how AI can enhance language teaching by personalizing content and supporting the development of communicative skills. The analysis through thematic analysis revealed that AI technologies empowered teachers to design interactive and adaptive learning materials, including picture books and karaoke exercises, thereby fostering a more dynamic and student-centered learning environment. In-service teachers noted that the adaptability of AI tools not only facilitated the creation of compelling lessons but also significantly improved students' listening and speaking skills. The findings advocate for the strategic incorporation of AI in EFL teaching, suggesting that such technologies can lead to innovative pedagogical approaches that are attuned to the diverse needs of learners. This study underscores the potential of AI to revolutionize language education.
72	Applying a modified technology acceptance model to explain higher education students' usage of ChatGPT: A serial multiple mediation model with knowledge sharing as a moderator Technology acceptance model; Behavior intention to use ChatGPT; Actual use of ChatGPT; Knowledge sharing Generative artificial intelligence (AI), such as ChatGPT, has taken the world by storm, especially in the education sector, because of its capacity to produce responses that are contextually relevant and appear to imitate human language. This has increased concerns from both scholars and practitioners regarding the potential impacts of ChatGPT on students' learning. However, research on higher education students' adoption of ChatGPT is still scant. Drawing on the modified technology acceptance model (TAM) and a sample of 1389 higher education students recruited in 11 universities in Vietnam with a stratified random sampling approach, the findings of this study indicated that effort expectancy not only directly affected students' actual usage of ChatGPT, but also serially indirectly increased their actual use of ChatGPT through performance expectancy and intentions to use ChatGPT. Additionally, knowledge sharing was found to significantly increase higher education students' transformation from having the intention to use ChatGPT to actual users of ChatGPT. The theoretical and managerial implications of this are discussed in this paper in order to gain benefits and manage the potential threats from this new technology.
73	Acceptance and use of ChatGPT in the academic community ChatGPT; UTAUT2; Technology acceptance; Higher education; Academic community; Generative artificial intelligence Since OpenAI released ChatGPT, the discussion on its usage in education has been conducted by students and teachers of every education level. Also, many studies have been performed on the tool's possibilities and the threats related to its usage, such as incomplete or inaccurate information obtained or even plagiarism. Many universities worldwide have introduced specific regulations on ChatGPT usage in academic work. Furthermore, research on using ChatGPT by students and their attitudes towards it has appeared. However, a research gap exists in higher education teachers' acceptance of AI solutions. The goal of this research was to explore the level of acceptance of the usage of ChatGPT by academics in Poland, as well as point out factors influencing their intention to use this tool. The study motivation was related to an ongoing academic discussion mainly focusing on the disadvantages of AI solutions used in scientific work and the willingness to fill the gap by showing teachers' attitudes toward AI. The data was collected online by inviting academic teachers from Polish public universities to complete the prepared survey. The survey was prepared using the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) model extended with Personal Innovativeness. It revealed the acceptance level of ChatGPT usage in Polish universities by teachers and researchers and the antecedents influencing willingness to use this technology in academic work. The paper contributes to the theory of AI usage by structuring the studies regarding ChatGPT application for teaching and research, and provides practical recommendations on ChatGPT adoption in the work of academics.
74	Students' reflections on their experience with ChatGPT artificial intelligence; ChatGPT; critical thinking; education; sustainability Background: The emergence of Generative Artificial Intelligence has brought a number of ethical and practical issues to higher education. Solid experimental evidence is yet inadequate to set the functional rules for the new technology. Objectives: The objective of this study is to analyse the experience of undergraduate students' interaction with ChatGPT and contribute to identifying the problems arising from the widespread use of artificial intelligence. Methods: Junior university students (N = 25) were assigned the task of working on their seminar essays with the aid of ChatGPT. Most students were novices with this tool (the study was conducted in the spring of 2023). Their essays were analysed qualitatively, according to the principles of the general inductive approach. Results and Conclusions: The initial attitudes towards artificial intelligence were almost equally distributed from enthusiastic to indifferent and cautious, with one student refusing to interact with the chatbot on ideological grounds. After the first experience, most of the students declared themselves adopters of the new technology. We have found some evidence for enhancing critical thinking competence when using ChatGPT, as well as examples of unquestioned reliance on its outputs. The tendency to personification of the chatbot was apparent in the students' essays. Implications: The findings show how easily the students embrace artificial intelligence and suggest a failure of any attempts for its strict regulation. This, on the other hand, underlines the need for emphasis on personal and research-oriented approaches in teaching and learning.
75	ChatGPT in medical school: how successful is AI in progress testing? Medical education; progress test; learning; artificial intelligence; machine learning Background As generative artificial intelligence (AI), ChatGPT provides easy access to a wide range of information, including factual knowledge in the field of medicine. Given that knowledge acquisition is a basic determinant of physicians' performance, teaching and testing different levels of medical knowledge is a central task of medical schools. To measure the factual knowledge level of the ChatGPT responses, we compared the performance of ChatGPT with that of medical students in a progress test. Methods A total of 400 multiple-choice questions (MCQs) from the progress test in German-speaking countries were entered into ChatGPT's user interface to obtain the percentage of correctly answered questions. We calculated the correlations of the correctness of ChatGPT responses with behavior in terms of response time, word count, and difficulty of a progress test question. Results Of the 395 responses evaluated, 65.5% of the progress test questions answered by ChatGPT were correct. On average, ChatGPT required 22.8 s (SD 17.5) for a complete response, containing 36.2 (SD 28.1) words. There was no correlation between the time used and word count with the accuracy of the ChatGPT response (correlation coefficient for time rho = -0.08, 95% CI [-0.18, 0.02], t(393) = -1.55, p = 0.121; for word count rho = -0.03, 95% CI [-0.13, 0.07], t(393) = -0.54, p = 0.592). There was a significant correlation between the difficulty index of the MCQs and the accuracy of the ChatGPT response (correlation coefficient for difficulty: rho = 0.16, 95% CI [0.06, 0.25], t(393) = 3.19, p = 0.002). Conclusion ChatGPT was able to correctly answer two-thirds of all MCQs at the German state licensing exam level in Progress Test Medicine and outperformed almost all medical students in years 1-3. The ChatGPT answers can be compared with the performance of medical students in the second half of their studies.
76	ChatGPT awareness, acceptance, and adoption in higher education: the role of trust as a cornerstone ChatGPT adoption intention; Perceived trust; Perceived ease of use; ChatGPT awareness; Perceived usefulness; Perceived intelligence As technology continues to advance, the integration of generative artificial intelligence tools in various sectors, including education, has gained momentum. ChatGPT, an extensively recognized language model created by OpenAI, has gained significant importance, particularly in education. This study investigates the awareness, acceptance, and adoption of ChatGPT, a state-of-the-art language model developed by OpenAI, in higher education institutions across China. This study applies the partial least squares structural equation modeling (PLS-SEM) method for examining data collected from 320 Chinese university students. The study's conceptual framework integrates key determinants from the Technology Acceptance Model (TAM) and extends it by incorporating perceived intelligence as a critical factor in the adoption process. The study findings reveal that ChatGPT awareness significantly influences the intention to adopt ChatGPT. Perceived ease of use, usefulness, and intelligence significantly mediate the association between ChatGPT awareness and adoption intention of ChatGPT. Additionally, perceived trust significantly moderates the relationship between ChatGPT awareness and perceived ease of use, usefulness, and intelligence. Moving forward, in order to maintain students' critical thinking skills and inventiveness in their assessment writing, assessments must promote the safe use of ChatGPT. Therefore, educators will be crucial in ensuring that artificial intelligence tools are used in assessments ethically and suitably by providing clear guidelines and instructions.
77	Learning by playing with generative AI: design and evaluation of a role-playing educational game with generative AI as scaffolding for instant feedback interaction Generative AI; ChatGPT; prompting; interactive scaffolding; game-based learning In this study, an online contextualized educational game was designed to provide interactive simulated dialogues using generative AI scaffolding (using ChatPDF) in a contextualized game as scaffolding for immediate feedback, where learners can access guides and explore knowledge. This study analyzed learners' behaviors while performing AI prompting in the interactive scaffolding, as well as learners' psychological responses. A total of 59 students participated in this study. The results of the study showed that learners had significantly high flow and low activity anxiety in the game tasks, while game feedback and scaffolding usefulness had significant effects on learning aids. The generative AI instant feedback interactive scaffolding had a certain high percentage of direct answers or indirect suggestions, which is suitable for interactive scaffolding.
78	When artificial intelligence substitutes humans in higher education: the cost of loneliness, student success, and retention AI; ChatGPT; chatbot; intention to leave; sense of belonging; university students Artificial intelligence (AI) may be the new-new-norm in a post-pandemic learning environment. There is a growing number of university students using AI like ChatGPT and Bard to support their academic experience. Much of the AI in higher education research to date has focused on academic integrity and matters of authorship; yet, there may be unintended consequences beyond these concerns for students. That is, there may be people who reduce their formal social interactions while using these tools. This study evaluates 387 university students and their relationship to - and with - artificial intelligence large-language model-based tools. Using structural equation modelling, the study finds evidence that while AI chatbots designed for information provision may be associated with student performance, when social support, psychological wellbeing, loneliness, and sense of belonging are considered it has a net negative effect on achievement. This study tests an AI-specific form of social support, and the cost it may pose to student success, wellbeing, and retention. Indeed, while AI chatbot usage may be associated with poorer social outcomes, human-substitution activity that may be occurring when a student chooses to seek support from an AI rather than a human (e.g. a librarian, professor, or student advisor) may pose interesting learning and teaching policy implications. We explore the implications of this from the lens of student success and belonging.
79	Modelling Generative AI Acceptance, Perceived Teachers' Enthusiasm and Self-Efficacy to English as a Foreign Language Learners' Well-Being in the Digital Era English as a foreign language; generative AI acceptance; learners' well-being; perceived teachers' enthusiasm; self-efficacy As artificial intelligence (AI) has been integrated into foreign language (FL) education, learners' well-being is influenced by various factors, including technological, personal and contextual elements. However, few studies explored how external and internal factors jointly shape FL learners' well-being in the era of generative AI. To fill this gap, this study explores the effects of generative AI acceptance, perceived teachers' enthusiasm and self-efficacy on FL learners' well-being by investigating 613 university learners of English as a foreign language (EFL). The structural equation modelling results reveal that (1) generative AI acceptance positively predicts EFL learners' well-being and self-efficacy; (2) perceived teachers' enthusiasm does not predict learners' well-being and positively predicts EFL learners' self-efficacy; and (3) the self-efficacy for receptive skills mediates the relationship between generative AI acceptance/perceived teachers' enthusiasm and EFL learners' well-being, whereas self-efficacy for productive skills does not play the mediation role. This research broadens the understanding of the antecedents of EFL learners' well-being and extends the application of self-efficacy theory in the AI-driven educational environment, providing significant pedagogical implications.
80	Systematics review on artificial intelligence chatbots and ChatGPT for language learning and research from self-determination theory (SDT): what are the roles of teachers? Chatbot; language learning; self-determination theory; teacher AI and digital competence; TPACK; ChatGPT Recent advances in artificial intelligence (AI) give chatbots, e.g. ChatGPT, more human-like interaction and conversational capability. AI chatbots are becoming more popular for supporting language learning. Most current review research disregards the significance of teachers' roles in chatbot-assisted language learning. Self-determination theory (SDT) explains the roles by suggesting how teachers satisfy student needs and how chatbots thwart those needs. Therefore, this systemic review aims to: (i) suggest the roles that teachers play in student English learning with AI chatbot; (ii) discuss how those roles satisfy SDT needs of the students; and (iii) discuss the challenges in this learning. This review selected 23 articles published throughout the last ten years (2014-2023). The findings offer (i) four empirical and theoretical contributions: technological pedagogical content knowledge (TPACK) for chatbots, needs satisfaction from teachers, needs thwarting from chatbots, and SDT-based research designs for chatbots; (ii) two practical suggestions: understanding technological knowledge of chatbots and SDT needs support for chatbots; and (iii) six research directions: experimental studies, student language proficiency, more teacher roles, revisiting TPACK, future development of chatbots, and large language model teacher-like chatbots. Overall, the findings enhance our knowledge of TPACK and teacher digital and AI competences for chatbot-assisted language learning.
81	Exploring AI-mediated informal digital learning of English (AI-IDLE): a mixed-method investigation of Chinese EFL learners' AI adoption and experiences AI-IDLE; Language learning beyond the classroom; GPT technologies; technology acceptance model; AI literacies Recent advancements in natural language processing and large language models have ushered language learning into the age of artificial intelligence (AI). Recognizing the affordances of generative AI tools, this paper aims to examine the degree to which L2 learners accepted and leveraged large language model platforms (e.g. ChatGPT, Bing Chat) for the informal digital learning of English (IDLE) purposes. Employing an explanatory sequential mixed-method design, this study draws on the technology acceptance model (TAM) and collects data via an adapted TAM questionnaire and an interview guide. A total of 867 Chinese EFL (English as a foreign language) learners answered the online survey, while 20 attended the post-survey interviews. Drawing on a validated structural model that elucidates the inter-factor relationships of perceived ease of use, perceived usefulness, intention to use, and actual use, the quantitative analysis provides statistical accounts for EFL learners' adoption of Generative Pre-trained Transformer (GPT) technologies. The qualitative findings, derived from the interview data, reveal three key themes: (1) how perceived usefulness of chatbots for IDLE emerges from hands-on experimentation with these tools; (2) how intention to use increases as learners negotiate chatbot affordances and constraints; and (3) how actual use of chatbots for IDLE involves using these tools as tutors or conversation partners. Connections between quantitative and qualitative findings enhance our understanding of how EFL learners negotiate the affordances and constraints of highly capable AI technologies to participate in creative IDLE practices. By understanding these practices, this study draws attention to the attitudes and practices that constitute AI literacies, ultimately offering implications for future classroom practices and research.
82	Scale validation and latent profile identification of GenAI competence for pre-service second language teachers GenAI competence; pre-service L2 teachers; scale development; psychometric properties; latent profile analysis Pre-service second language (L2) teachers can benefit from Generative Artificial Intelligence (GenAI), yet there is a lack of reliable instrument to evaluate their GenAI competence. To fill this void, two studies were conducted. Study 1 aimed to create a GenAI Competence Scale for Chinese Pre-service L2 Teachers. Based on exploratory factor analysis of 350 samples, a 21-item scale was developed with a three-factor structure: Awareness and Willingness, Knowledge and Application, and Social Responsibility. Confirmatory factor analysis of 358 samples verified the scale's ideal model fit, along with its high validity (convergent, discriminant, and criterion-related), reliability, and cross-gender invariance. Study 2 utilized Latent Profile Analysis to identify three distinct profiles among 708 Chinese pre-service L2 teachers' GenAI competence: (i) moderate levels of Awareness and Willingness, relatively low Knowledge and Application, and moderate Social Responsibility (C1: 22.74 %), (ii) moderately high levels of Awareness and Willingness, relatively low Knowledge and Application, and moderately high Social Responsibility (C2: 65.82 %), and (iii) high levels of Awareness and Willingness, moderate Knowledge and Application, and high Social Responsibility (C3: 11.44 %). We anticipate that future scholars will adopt this scale across diverse L2 education settings, conducting some in-depth explorations to enhance the generalizability of findings, deepen the understanding of GenAI competence among pre-service educators, and contribute to the advancement of relevant theoretical frameworks and practical applications.
83	Literacy in the Time of Artificial Intelligence  The latest mutation of Artificial Intelligence, Generative AI, is more than anything a technology of writing. It is a machine that can write. In a world-historical frame, the significance of this cannot be understated. This is a technology in which the unnatural language of code tangles with the natural language of everyday life. Its form of writing, moreover, is multimodal, able not only to write text as conventionally understood, but also to "read" images by matching textual labels and to "write" images from textual prompts. Within the scope of this peculiarly mechanical manufacturing of writing are mathematics, actionable software procedure, and algorithm. This paper explores the consequences of Generative AI for literacy teaching and learning. In its first part, we speak theoretically and historically, suggesting that this development is perhaps as momentous for society and education as Pi Sheng's invention of moveable type and Gutenberg's printing press-and in its peculiar ways just as problematic. In the paper's second part, we go on to propose that literacy in the time of AI requires a new way to speak about itself, a revised "grammar" of sorts. In a third part, we discuss an experimental application we have developed that puts Generative AI to work in support of literacy and learning. We end with some findings and implications for literacy education and with a proposal for what we will call cyber-social literacy learning.
84	Incorporating AI in foreign language education: An investigation into ChatGPT's effect on foreign language learners AI in language learning; Artificial intelligence; ChatGPT; Chatbots; Educational technology; Online learning ChatGPT, an artificial intelligence application, has emerged as a promising educational tool with a wide range of applications, attracting the attention of researchers and educators. This qualitative case study, chosen for its ability to provide an in-depth exploration of the nuanced effects of AI on the foreign language learning process within its real-world educational context, aimed to utilize ChatGPT in foreign language education, addressing a gap in existing research by offering insights into the potential, benefits, and drawbacks of this innovative approach. The study involved 13 preparatory class students studying at the School of Foreign Languages at a university in Turkey. The students were introduced to ChatGPT through learning experiences over a span of four weeks by the researcher as a language teacher. The qualitative data collected from the interviews were analysed using thematic analysis. The findings suggest that ChatGPT positively affects students' learning experiences, especially in writing, grammar, and vocabulary acquisition, and enhances motivation and engagement through its versatile and accessible nature in various learning activities. These insights contribute to understanding the utility and constraints of employing ChatGPT technology in foreign language instruction and can inform educators and researchers in developing effective teaching strategies and in designing curricula.
85	Is Chatgpt a menace for creative writing ability? An experiment AI; ChatGPT; creative writing; creativity; experiment; writing ability BackgroundThe increasing prevalence of Artificial Intelligence (AI) language models, exemplified by ChatGPT, has sparked inquiries into their influence on creative writing skills in educational contexts. This study aims to quantitatively investigate whether ChatGPT's use negatively affects university students' creative writing abilities, focusing on originality, content presentation, accuracy, and elaboration in essays. The research adopts an experimental approach to shed light on this concern.ObjectiveThis study aims to quantitatively investigate whether the utilization of ChatGPT, an AI chatbot, adversely affects specific dimensions of creative writing skills among university students, with an emphasis on originality, content presentation, accuracy, and elaboration.MethodThe experimental study involves 600 students from 10 universities, divided into a control and an experimental group (EGp). The EGp incorporates ChatGPT in their creative writing process as an intervention. The study evaluates originality, content presentation, accuracy, and elaboration, utilizing the Wilcoxon Signed-Rank Test for analysis.Results and ConclusionThe findings reveal a detrimental association between ChatGPT use and university students' creative writing abilities. Analysing both machine-based and human-based assessments substantiates earlier qualitative observations regarding ChatGPT's adverse impact on creative writing. This study highlights the necessity of approaching AI integration, particularly in creative writing disciplines, with caution. While AI tools have merits, their integration should be thoughtful, considering the potential drawbacks. These insights inform future research and educational practices, guiding the effective incorporation of AI while nurturing students' writing skills. What is already known about this topicChatGPT poses an ethical dilemma regarding its use in the field of academiaQualitative claims and opinions have been raised in prior studies regarding its use in the creative writing processPrior studies have both supported and opposed its use but with very limited quantitative approaches while most of the opinions remain qualitativeSome prior studies opine in support of ChatGPT's ability as an authorSeveral factors measuring creativity has been identified by previous studies but a constructive approach in the light of advanced Artificial Intelligence (AI) based chatbots like ChatGPT is missing in such literatureAn experimental approach to provide a valid quantitative proof of the qualitative claims over ChatGPT's detrimental effect towards creativity in writing, which was absent in prior studiesA multifactor-based formula to measure creativity in a quantitative formA quantitative view of the factors that are affected in either a positive way or a negative way in a user by ChatGPT, providing a holistic picture to determine its extent of useA statistical and theoretical understanding over an unexplored topic like creative writing in the light of ChatGPTA quantitative proof why ChatGPT should not be considered as an authorImplications for practice and/or policyEducators may implement changes in assigning tasks to students compared to their earlier practices, based on the identified factors that are being affected negatively, to ensure ChatGPT does not hinder a student's creativity at a greater extentThe extent of using ChatGPT should be limited to self-learning as positive effect was experienced through the experimentPolicymakers may use the findings of the study to impose strict policies in academia for ensuring academic integrity (Example: must use of plagiarism detecting software for checking scripts, assigning tasks to students which require more analytical abilities, providing tasks which are not properly readable by LLM's like ChatGPT such as image-based questions, case studies etc.)
86	Comparing the quality of human and ChatGPT feedback of students' writing Automated writing evaluation; Formative feedback; Writing instruction Background: Offering students formative feedback on their writing is an effective way to facilitate writing development. Recent advances in AI (i.e., ChatGPT) may function as an automated writing evaluation tool, increasing the amount of feedback students receive and diminishing the burden on teachers to provide frequent feedback to large classes. Aims: We examined the ability of generative AI (ChatGPT) to provide formative feedback. We compared the quality of human and AI feedback by scoring the feedback each provided on secondary student essays. We scored the degree to which feedback (a) was criteria-based, (b) provided clear directions for improvement, (c) was accurate, (d) prioritized essential features, and (e) used a supportive tone. Sample: 200 pieces of human-generated formative feedback and 200 pieces of AI-generated formative feedback for the same essays. Methods: We examined whether ChatGPT and human feedback differed in quality for the whole sample, for compositions that differed in overall quality, and for native English speakers and English learners by comparing descriptive statistics and effect sizes. Results: Human raters were better at providing high-quality feedback to students in all categories other than criteria-based. AI and humans showed differences in feedback quality based on essay quality. Feedback did not vary by language status for humans or AI. Conclusion: Well-trained evaluators provided higher quality feedback than ChatGPT. Considering the ease of generating feedback through ChatGPT and its overall quality, generative AI may still be useful in some contexts, particularly in formative early drafts or instances where a well-trained educator is unavailable.
87	ChatGPT in higher education - a synthesis of the literature and a future research agenda ChatGPT; Artificial Intelligence; Generative AI; Higher education; Plagiarism; Academic integrity; Systematic review; Bibliometric analysis ChatGPT has emerged as a significant subject of research and exploration, casting a critical spotlight on teaching and learning practices in the higher education domain. This study examines the most influential articles, leading journals, and productive countries concerning citations and publications related to ChatGPT in higher education, while also shedding light on emerging thematic and geographic clusters within research on ChatGPT's role and challenges in teaching and learning at higher education institutions. Forty-seven research papers from the Scopus database were shortlisted for bibliometric analysis. The findings indicate that the use of ChatGPT in higher education, particularly issues of academic integrity and research, has been studied extensively by scholars in the United States, who have produced the largest volume of publications, alongside the highest number of citations. This study uncovers four distinct thematic clusters (academic integrity, learning environment, student engagement, and scholarly research) and highlights the predominant areas of focus in research related to ChatGPT in higher education, including student examinations, academic integrity, student learning, and field-specific research, through a country-based bibliographic analysis. Plagiarism is a significant concern in the use of ChatGPT, which may reduce students' ability to produce imaginative, inventive, and original material. This study offers valuable insights into the current state of ChatGPT in higher education literature, providing essential guidance for scholars, researchers, and policymakers.
88	Challenge, integration, and change: ChatGPT and future anatomical education ChatGPT; artificial intelligence; anatomy; medical education; educational reform With the vigorous development of ChatGPT and its application in the field of education, a new era of the collaborative development of human and artificial intelligence and the symbiosis of education has come. Integrating artificial intelligence (AI) into medical education has the potential to revolutionize it. Large language models, such as ChatGPT, can be used as virtual teaching aids to provide students with individualized and immediate medical knowledge, and conduct interactive simulation learning and detection. In this paper, we discuss the application of ChatGPT in anatomy teaching and its various application levels based on our own teaching experiences, and discuss the advantages and disadvantages of ChatGPT in anatomy teaching. ChatGPT increases student engagement and strengthens students' ability to learn independently. At the same time, ChatGPT faces many challenges and limitations in medical education. Medical educators must keep pace with the rapid changes in technology, taking into account ChatGPT's impact on curriculum design, assessment strategies and teaching methods. Discussing the application of ChatGPT in medical education, especially anatomy teaching, is helpful to the effective integration and application of artificial intelligence tools in medical education.
89	Student Perceptions of ChatGPT Use in a College Essay Assignment: Implications for Learning, Grading, and Trust in Artificial Intelligence Chatbots; Writing; Education; Artificial intelligence; Human factors; Ethics; Task analysis; Artificial intelligence (AI); ChatGPT; education; student perceptions; writing This article examined student experiences before and after an essay writing assignment that required the use of ChatGPT within an undergraduate engineering course. Utilizing a pre-post study design, we gathered data from 24 participants to evaluate ChatGPT's support for both completing and grading an essay assignment, exploring its educational value and impact on the learning process. Our quantitative and thematic analyses uncovered that ChatGPT did not simplify the writing process. Instead, the tool transformed the student learning experience yielding mixed responses. Participants reported finding ChatGPT valuable for learning, and their comfort with its ethical and benevolent aspects increased postuse. Concerns with ChatGPT included poor accuracy and limited feedback on the confidence of its output. Students preferred instructors to use ChatGPT to help grade their assignments, with appropriate oversight. They did not trust ChatGPT to grade by itself. Student views of ChatGPT evolved from a perceived "cheating tool" to a collaborative resource that requires human oversight and calibrated trust. Implications for writing, education, and trust in artificial intelligence are discussed.
90	From concerns to benefits: a comprehensive study of ChatGPT usage in education Artificial Intelligence; Chatbots; ChatGPT; Self-learning; Personalization; Behavioral intention; Innovativeness Artificial Intelligence (AI) chatbots are increasingly becoming integral components of the digital learning ecosystem. As AI technologies continue to evolve, it is crucial to understand the factors influencing their adoption and use among students in higher education. This study is undertaken against this backdrop to explore the behavioral determinants associated with the use of the AI Chatbot, ChatGPT, among university students. The investigation delves into the role of ChatGPT's self-learning capabilities and their influence on students' knowledge acquisition and application, subsequently affecting the individual impact. It further elucidates the correlation of chatbot personalization with novelty value and benefits, underscoring their importance in shaping students' behavioral intentions. Notably, individual impact is revealed to have a positive association with perceived benefits and behavioral intention. The study also brings to light potential barriers to AI chatbot adoption, identifying privacy concerns, technophobia, and guilt feelings as significant detractors from behavioral intention. However, despite these impediments, innovativeness emerges as a positive influencer, enhancing behavioral intention and actual behavior. This comprehensive exploration of the multifaceted influences on student behavior in the context of AI chatbot utilization provides a robust foundation for future research. It also offers invaluable insights for AI chatbot developers and educators, aiding them in crafting more effective strategies for AI integration in educational settings.
91	ChatGPT: Empowering lifelong learning in the digital age of higher education AI; Higher education; Quality education; ChatGPT; Smart learning Artificial intelligence (AI) technologies have the potential to completely transform how we teach and learn in higher education. ChatGPT, a language model developed by OpenAI, is one such tool that can deliver individualized recommendations to students, increase collaboration and communication, and improve student learning results. However, there are some obstacles to overcome, such as ethical concerns and implementation issues. This study reviews related work on the use of artificial intelligence in education, with a focus on ChatGPT and its possible applications in higher education. It also examines the benefits and drawbacks of adopting ChatGPT in higher education, as well as implementation advice. Finally, the report discusses future directions for ChatGPT research in higher education. According to the findings of this paper, ChatGPT represents a significant opportunity for higher education institutions to improve the quality and accessibility of education; however, its implementation must be approached with caution and a clear understanding of the opportunities and challenges involved.
92	The interplay of learning, analytics and artificial intelligence in education: A vision for hybrid intelligence artificial intelligence; educational technology; future of education; generative AI; human cognition; hybrid intelligence; learning analytics This paper presents a multidimensional view of AI's role in education, emphasising the intricate interplay among AI, analytics and human learning processes. Here, I challenge the prevalent narrow conceptualisation of AI as tools in Education, exemplified in generative AI tools, and argue for the importance of alternative conceptualisations of AI for achieving human-AI hybrid intelligence. I highlight the differences between human intelligence and artificial information processing, the importance of hybrid human-AI systems to extend human cognition and posit that AI can also serve as an instrument for understanding human learning. Early learning sciences and AI in Education Research (AIED), which saw AI as an analogy for human intelligence, have diverged from this perspective, prompting a need to rekindle this connection. The paper presents three unique conceptualisations of AI: the externalisation of human cognition, the internalisation of AI models to influence human mental models and the extension of human cognition via tightly coupled human-AI hybrid intelligence systems. Examples from current research and practice are examined as instances of the three conceptualisations in education, highlighting the potential value and limitations of each conceptualisation for human competence development, as well as the perils of overemphasis on approaches that replace human learning opportunities with AI tools. The paper concludes with advocacy for a broader approach to AIED that goes beyond considerations on the design and development of AI and includes educating people about AI and innovating educational systems to remain relevant in an AI ubiquitous world.
93	Exploring the impact of ChatGPT on education: A web mining and machine learning approach ChatGPT; Artificial intelligence; Education; Teaching; Learning ChatGPT, an artificial intelligence model, has garnered significant interest within education. This study examined public sentiment regarding ChatGPT's influence on education by utilizing web mining and natural language processing (NLP) techniques. By adopting an empirical approach and leveraging machine learning models to process 2003 web articles, the study extracts valuable insights. The results indicate that ChatGPT has emerged as a crucial educational tool, offering advantages for both students and educators. Notably, the study emphasized ChatGPT's role in enhancing students' writing abilities and fostering dynamic, interactive learning environments. ChatGPT's capacity to address a broad spectrum of questions demonstrates its versatility and adaptability, contributing to more inclusive and personalized educational experiences. However, the study also uncovered challenges tied to academic integrity, such as plagiarism and cheating, which stem from incorporating AI-driven tools like ChatGPT into education. This raises concerns regarding ethical aspects, including responsible AI usage and data privacy, and highlights the need for institutions to develop guidelines and policies for AI tool implementation in education. This study's findings hold theoretical and practical implications for integrating ChatGPT into educational settings. It is the first to employ web mining and NLP techniques to analyze public opinions on ChatGPT's impact on education comprehensively.
94	Learning to work with the black box: Pedagogy for a world with artificial intelligence artificial intelligence; generative AI; higher education; evaluative judgement; relational epistemology Artificial intelligence (AI) is increasingly integrating into our society. University education needs to maintain its relevance in an AI-mediated world, but the higher education sector is only beginning to engage deeply with the implications of AI within society. We define AI according to a relational epistemology, where, in the context of a particular interaction, a computational artefact provides a judgement about an optimal course of action and that this judgement cannot be traced. Therefore, by definition, AI must always act as a 'black box'. Rather than seeking to explain 'black boxes', we argue that a pedagogy for an AI-mediated world involves learning to work with opaque, partial and ambiguous situations, which reflect the entangled relationships between people and technologies. Such a pedagogy asks learners locate AI as socially bounded, where AI is always understood within the contexts of its use. We outline two particular approaches to achieve this: (a) orienting students to quality standards that surround AIs, what might be called the tacit and explicit 'rules of the game'; and (b) providing meaningful interactions with AI systems.
95	Learning and Teaching in the Era of Generative Artificial Intelligence Technologies: An In-Depth Exploration Using Multi-Analytical SEM-ANN Approach desire for learning; e-learning competence; facilitating conditions; GAI technologies; SEM-ANN; teachers' learning performance The arrival of generative artificial intelligence (GAI) technologies marks a significant transformation in the educational landscape, with implications for teaching and learning performance. These technologies can generate content, simulate interactions, and adapt to learners' needs, offering opportunities for interactive learning experiences. In China's education sector, incorporating GAI technologies can address educational challenges, enhance teaching practices, and improve performance. This study scrutinises the impact of GAI technologies on learning performance in the education sector, focusing on the mediating roles of e-learning competence (EC), desire for learning (DL), and beliefs about the future (BF), as well as the moderating role of facilitating conditions amongst Chinese educators. Data was collected from 411 teachers across various educational institutions in China using purposive sampling. PLS-SEM and ANN were employed to assess the suggested structural model. The study results indicate that GAI technologies significantly influence learning performance by mediating EC, DL, and BF roles. Furthermore, facilitating conditions positively moderate the association amongst GAI technologies and EC, DL, and BF. This study underscores the critical role of self-determination theory in shaping the effective incorporation of GAI technologies in education, offering valuable insights to improve teaching and learning outcomes in the Chinese education sector.
96	Development of a generative AI-powered teachable agent for middle school mathematics learning: A design-based research study AI-assisted learning environment; generative AI; learning-by-teaching; mathematics learning; teachable agent This paper reports on a design-based research (DBR) study that aims to devise an artificial intelligence (AI)-powered teachable agent that supports secondary school students' learning-by-teaching practices of mathematics learning content. A long-standing pedagogical practice of learning-by-teaching is powered by a recent advancement of generative AI technologies, yielding our teachable agent called ALTER-Math. This study chronicles one usability testing and three cycles of iterative design and implementation process of ALTER-Math. The three empirical studies involved a total of 320 middle school students and six teachers in authentic classroom settings. The first study was exploratory, focusing on the qualitative feedback from the students and teachers through open-ended surveys, interviews and classroom observations. The second study yielded a medium-high (M = 3.26) quantitative survey result on students' perceived engagement and usability on top of the qualitative findings. Finally, the final study included pre- and post-knowledge tests in a quasi-experimental study design as well as student and teacher interviews. The final study revealed a bigger significant knowledge improvement in students who used ALTER-Math compared to the control group, suggesting a positive impact of AI-powered teachable agents on students' learning. The design implications learned from multiple iterations are discussed to inform the future design of AI-powered learning technologies.Practitioner notes What is already known about this topic Learning-by-teaching is a long-standing effective pedagogical strategy to enhance students' domain knowledge and feelings of responsibility in learning. Various teachable agents have been developed and have demonstrated benefits in students' learning. Generative AI offers the potential to provide naturalistic, contextualised and adaptive conversations. What this paper adds Develops a novel generative AI-powered teachable agent for middle school mathematics learning, called ALTER-Math. Reports the iterative design process involving empirical classroom implementations of ALTER-Math. Reveals a bigger significant improvement in the student's mathematical knowledge after using ALTER-Math, compared to the control group. Implications for practice and/or policy Researchers can be inspired by this design example of a theoretically grounded generative AI learning technology. Educational technology designers could hear the real voices of students and teachers about the generative AI learning technologies. Researchers and educational technology designers could be directed by the design implications to the future design of AI-powered learning technologies and teachable agents.
97	First-year students AI-competence as a predictor for intended and de facto use of AI-tools for supporting learning processes in higher education Artificial Intelligence; Higher education; Learning process; AI tool; Chatbot The influence of Artificial Intelligence on higher education is increasing. As important drivers for student retention and learning success, generative AI-tools like translators, paraphrasers and most lately chatbots can support students in their learning processes. The perceptions and expectations of first-years students related to AI-tools have not yet been researched in-depth. The same can be stated about necessary requirements and skills for the purposeful use of AI-tools. The research work examines the relationship between first-year students' knowledge, skills and attitudes and their use of AI-tools for their learning processes. Analysing the data of 634 first-year students revealed that attitudes towards AI significantly explains the intended use of AI tools. Additionally, the perceived benefits of AI-technology are predictors for students' perception of AI-robots as cooperation partners for humans. Educators in higher education must facilitate students' AI competencies and integrate AI-tools into instructional designs. As a result, students learning processes will be improved.
98	Do you have AI dependency? The roles of academic self-efficacy, academic stress, and performance expectations on problematic AI usage behavior Artificial intelligence; AI dependency; Academic self-efficacy; Academic stress; Performance expectations; ChatGPT Although previous studies have highlighted the problematic artificial intelligence (AI) usage behaviors in educational contexts, such as overreliance on AI, no study has explored the antecedents and potential consequences that contribute to this problem. Therefore, this study investigates the causes and consequences of AI dependency using ChatGPT as an example. Using the Interaction of the Person-Affect-Cognition-Execution (I-PACE) model, this study explores the internal associations between academic self-efficacy, academic stress, performance expectations, and AI dependency. It also identifies the negative consequences of AI dependency. Analysis of data from 300 university students revealed that the relationship between academic self-efficacy and AI dependency was mediated by academic stress and performance expectations. The top five negative effects of AI dependency include increased laziness, the spread of misinformation, a lower level of creativity, and reduced critical and independent thinking. The findings provide explanations and solutions to mitigate the negative effects of AI dependency.
99	Factors influencing students' acceptance and use generative artificial intelligence in elementary education: an expansion of the UTAUT model Generative artificial intelligence; Unified theory of acceptance and use of technology (UTAUT); Task-technology fit theory; Gender; Elementary education; PLS-SEM This research examines the influence of integrating generative artificial intelligence (GAI) in education, focusing on its acceptance and utilization among elementary education students. Grounded in the Task-Technology Fit (TTF) Theory and an expanded iteration of the Unified Theory of Acceptance and Use of Technology (UTAUT) model, the study analyzes key constructs-Performance Expectancy, Effort Expectancy, Social Influence, and Facilitating Conditions-on students' behavioral intentions and usage behaviors concerning GAI. The UTAUT model, which integrates elements from multiple theories and is widely applied in educational contexts to understand technology adoption behaviors, provides a robust theoretical framework. Additionally, TTF theory, emphasizing the alignment of technology with specific instructional tasks, enhances our understanding of GAI acceptance. This study also investigates the moderating effects of TTF and gender within this framework. Data analysis, conducted through PLS-SEM, is based on responses from 279 elementary education students in China who completed an 8-week course incorporating GAI. Results indicate that Performance Expectancy, Social Influence, and Effort Expectancy significantly influence Behavioral Intention, while Facilitating Conditions have the strongest impact on actual Use Behavior, surpassing their influence on Behavioral Intention. Furthermore, Task-Technology Fit moderates both Performance Expectancy and Effort Expectancy in students' consideration of GAI use. However, gender does not demonstrate a moderating effect in the overall model. These findings deepen our understanding of elementary school students' acceptance of GAI technology and provide practical guidance for developers, educational policymakers, teachers, and researchers to effectively integrate GAI into elementary education while maintaining teaching quality.
100	Revisiting Integrated Model of Technology Acceptance Among the Generative AI-Powered Foreign Language Speaking Practice: Through the Lens of Positive Psychology and Intrinsic Motivation Doubao; EAP talk; EFL; english speaking skills; GenAI chatbots; IMTA; intrinsic motivation; positive psychology Research on the factors influencing the acceptance of GenAI in language learning has expanded widely; however, few studies have focused on the role of language learning emotions. To enhance the effectiveness of GenAI-powered English-speaking instruction and the learning experience, this study expands on the Integrated Model of Technology Acceptance (IMTA) by investigating the role of various emotions and willingness to communicate in different contexts as intrinsic motivators for the acceptance of GenAI-powered conversational chatbots. Using a questionnaire (n = 368) and pre- and post-tests, the study found that EFL learners with higher communicative confidence and greater foreign language learning boredom tend to perceive GenAI chatbots as less useful for developing speaking skills. While GenAI successfully aided them in improving their speaking skills through both theme-based and free dialogues, learners who are more willing to engage in face-to-face interactions with peers and teachers may not find chatbots as productive or engaging as human counterparts. The results suggest that EFL teachers should be aware of the limitations of GenAI and students' individual differences, integrating GenAI into their classrooms in a way that aligns with student's proficiency and preferences to create a harmonious and efficient GenAI-supported language learning environment. This also underscores the importance of developing teachers' AI competence in the GenAI era.
101	Is ChatGPT an evil or an angel for second language education and research? A phenomenographic study of research-active EFL teachers' perceptions artificial intelligence; ChatGPT; educational technology; phenomenographic analysis; research-active EFL teacher Artificial intelligence (AI) is influencing different aspects of human life. An AI-powered technology, which has been recently released, is ChatGPT. It is a cutting-edge technology that influences second/foreign language (L2) education. Although there is increasing research on the benefits and misfits of this chatbot in different disciplines, L2 education lacks a thorough investigation. To fill this lacuna, this phenomenographic study examined the perceptions of research-active English as a Foreign Language (EFL) teachers regarding the potentials and pitfalls of ChatGPT for L2 learning, teaching, assessment, and research. To this end, a semistructured interview was held with 30 Iranian EFL teachers with varying educational backgrounds and AI integration experiences. The results of content and thematic analysis indicated that ChatGPT is a double-edged sword that can both benefit and hurt these areas of L2 education. The most notable potentials were augmenting learner autonomy, providing personalized learning, reducing teachers' teaching workload, designing assessment rubrics, and summarizing lengthy papers and theses to save L2 researchers' time and energy. Concerning pitfalls, it was reported that ChatGPT might kill creativity and academic integrity, encourage cheating in online exams, spread fake and misinformation into the world of research, and cherish high-tech plagiarism. Some practical suggestions are made to empower L2 educators and researchers to survive in the world of AI.
102	Hello GPT! Goodbye home examination? An exploratory study of AI chatbots impact on university teachers' assessment practices AI-chatbots; assessment; higher education; home examination; Turing test; > AI chatbots have recently fuelled debate regarding education practices in higher education institutions worldwide. Focusing on Generative AI and ChatGPT in particular, our study examines how AI chatbots impact university teachers' assessment practices, exploring teachers' perceptions about how ChatGPT performs in response to home examination prompts in undergraduate contexts. University teachers (n = 24) from four different departments in humanities and social sciences participated in Turing Test-inspired experiments, where they blindly assessed student and ChatGPT-written responses to home examination questions. Additionally, we conducted semi-structured interviews in focus groups with the same teachers examining their reflections about the quality of the texts they assessed. Regarding chatbot-generated texts, we found a passing rate range across the cohort (37.5 - 85.7%) and a chatbot-written suspicion range (14-23%). Regarding the student-written texts, we identified patterns of downgrading, suggesting that teachers were more critical when grading student-written texts. Drawing on post-phenomenology and mediation theory, we discuss AI chatbots as a potentially disruptive technology in higher education practices.
103	Interacting with ChatGPT in essay writing: A study of L2 learners' task motivation generative AI; ChatGPT; task motivation; essay writing; L2 learners This study explored the effects of interacting with ChatGPT 4.0 on L2 learners' motivation to write English argumentative essays. Conducted at a public university in a non-English-speaking country, the study had an experimental and mixed-methods design. It utilized both quantitative and qualitative data analyses to inform the development of effective AI-enhanced tailored interventions for teaching L2 essay writing. Overall, the results revealed that interacting with ChatGPT 4.0 had a positive lasting effect on learners' motivation to write argumentative essays in English. However, a decline in their motivation at the delayed post-intervention stage suggested the need to maintain a balance between utilizing ChatGPT as a writing support tool and enhancing their independent writing capabilities. Learners attributed the increase in their motivation to several factors, including their perceived improvement in essay writing skills, the supportive learning environment created by ChatGPT as a tutor, positive interactions with it, and the development of meta-cognitive awareness by addressing their specific writing issues. The study highlights the potential of AI-based tools in enhancing L2 learners' motivation in English classrooms.
104	Utilising artificial intelligence-enhanced writing mediation to develop academic writing skills in EFL learners: a qualitative study AI-enhanced writing mediation; ChatGPT; academic writing skills; EFL learners As innovative artificial intelligence (AI) platforms continue to demonstrate their effectiveness in mediating learners' language learning, further exploration is necessary to realise how AI contributes to English language learners' writing skills development. Following Vygotskian social constructivist theory of learning, we employed a qualitative research design to explore the impact of AI-enhanced writing mediation on English as a foreign language (EFL) learners' academic writing skills. Fourteen EFL learners, preparing for the IELTS examination, actively participated in interactive writing activities utilising ChatGPT, regarded as an AI platform, wherein they received implicit and explicit writing mediation to develop their academic writing skills. By tracking the microgenetic development of the learners, conducting observations of their interactive writing activities with the AI platform, and keeping a reflexive journal, the findings corroborated that the AI platform's writing mediation substantially contributed to the learners' academic writing skills development. Employing follow-up think-aloud interviews, the learners also highlighted their positive attitudes and perceptions towards the role of AI-enhanced writing mediation in developing their academic writing skills. The study provides pedagogical and practical implications for developing AI-enhanced writing mediation for EFL learners.
105	Data-Driven Artificial Intelligence in Education: A Comprehensive Review Artificial intelligence; Education; Surveys; Data mining; Market research; Systematics; Recommender systems; Artificial intelligence (AI) in education; e-learning; educational data mining (EDM); generative AI for education; intelligent tutoring systems (ITS); machine learning (ML) in education; personalized learning As education constitutes an essential development standard for individuals and societies, researchers have been exploring the use of artificial intelligence (AI) in this domain and have embedded the technology within it through a myriad of applications. In order to provide a detailed overview of the efforts, this article pays particular attention to these developments by highlighting key application areas of data-driven AI in education; it also analyzes existing tools, research trends, as well as limitations of the role data-driven AI can play in education. In particular, this article reviews various applications of AI in education including student grading and assessments, student retention and drop-out predictions, sentiment analysis, intelligent tutoring, classroom monitoring, and recommender systems. This article also provides a detailed bibliometric analysis to highlight the salient research trends in AI in education over nine years (2014-2022) and further provides a detailed description of the tools and platforms developed as the outcome of research and development efforts in AI in education. For the bibliometric analysis, articles from several top venues are analyzed to explore research trends in the domain. The analysis shows sufficient contribution in the domain from different parts of the world with a clear lead for the United States. Moreover, students' grading and evaluation have been observed as the most widely explored application. Despite the significant success, we observed several aspects of education where AI alone has not contributed much. We believe such detailed analysis is expected to provide a baseline for future research in the domain.
106	Factors influencing Chinese pre-service teachers' adoption of generative AI in teaching: an empirical study based on UTAUT2 and PLS-SEM GAI; Perceived risk; PLS-SEM; Pre-service teachers; UTAUT2 Although Generative Artificial Intelligence (GAI) has demonstrated significant potential in education, there is a lack of research on pre-service teachers' behavioral intentions toward GAI. This study is based on the UTAUT2 model and, for the first time, introduces perceived risk as a key variable to systematically investigate the factors influencing Chinese pre-service teachers' behavioral intentions and future usage of GAI in teaching. The innovation of this study lies in its analysis of the unique needs of pre-service teachers across disciplines, which reveals critical factors in technology acceptance. These findings offer new theoretical insights and practical guidance for the effective application of GAI in K-12 education. The study involved 563 pre-service teachers from three renowned teacher training universities in China. Data were collected using an online questionnaire platform and analysed using Partial Least Squares Structural Equation Modelling (PLS-SEM). The results indicated that effort expectancy, social influence, hedonic motivation, and habit significantly enhanced pre-service teachers' behavioural intention to use GAI in future teaching. At the same time, perceived risk had a negative effect. In addition, performance expectaancy, facilitating conditions, and price value did not significantly influence behavioural intentions, but behavioural intentions and facilitating conditions had significant predictive effects on future use. Based on the findings, this study provides practical recommendations for optimising the user experience of GAI tools, enhancing technical support, and reducing perceived risk.
107	Artificial Intelligence in Nursing: New Opportunities and Challenges AI; Artificial Intelligence; Education; Nurse; Nursing education To explore the opportunities and challenges of artificial intelligence (AI) in nursing and its impact. Bibliographic review using Arksey and O'Malley's framework, enhanced by Levac, Colquhoun and O'Brien and following PRISMA guidelines, including qualitative and mixed studies. MeSH terms and keywords such as nursing education and ethical considerations were used in databases such as PubMed, Scopus, Web of Science, CINAHL, IEEE Xplore and Google Scholar. Of all, 53 studies were included, highlighting various opportunities and challenges of AI integration and opportunities for personalised learning, training improvement and evaluation. Highlighting challenges related to academic integrity, accuracy, data privacy and security, for the development of critical thinking skills. The integration of AI in nursing education offers significant advantages for improving the quality and effectiveness of education, such as academic integrity, critical thinking and equitable access, for this reason, faculty training should be geared toward the integration of AI in nursing education.
108	The Motivational Impact of GenAI Tools in Language Learning: a Quasi-Experiment Study AI Chatbot; GenAI tools; language motivation; self-determination theory; structure equation modelling; (sic)(sic)(sic)(sic)(sic)(sic); (sic)(sic)(sic)(sic)(sic)(sic); (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic); (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic); (sic)(sic)(sic)(sic)(sic)(sic) The evolution of generative artificial intelligence (GenAI) technologies may have markedly influenced language learning. Through offering personalised support, GenAI-driven chatbots have potentially transformed how learners engage with and sustain their motivation in learning languages. Drawing on self-determination theory (SDT), this study explores the impact of using GenAI tools on the autonomous motivation of a group of Chinese university students learning English by examining how GenAI tool integration influences their basic psychological needs (BPN) of autonomy, competence and relatedness, and the development of their language motivation over a four-month academic term. A quasi-experimental design was employed for two groups (N = 355), with the experimental group incorporated GenAI tools into their learning routine, while the control group followed traditional classroom instruction. The structural model indicated a notable enhancement in the influence of Time 2 autonomy on Time 2 autonomous motivation, observed exclusively within the experimental group. The repeated measures ANOVA indicated that integrating GenAI tools significantly enhanced students' autonomous motivation compared to traditional methods. The findings suggest that strategic implementation of GenAI tools can effectively boost motivation in language learning, offering valuable insights for the consideration of their use in the educational system. (sic)(sic)(sic)(sic)(sic)(sic)(sic)(GenAI)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)GenAI(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic),(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)355(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)GenAI(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)2(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)2(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)(sic)GenAI(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).(sic)(sic)(sic)(sic)(sic)(sic)(sic), GenAI(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic), (sic)GenAI(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic)(sic).
109	Automated writing evaluation systems: A systematic review of Grammarly, Pigai, and Criterion with a perspective on future directions in the age of generative artificial intelligence Automated writing evaluation; Grammarly; Pigai; Criterion; Feedback; Artificial intelligence With the burgeoning popularity and swift advancements of automated writing evaluation (AWE) systems in language classrooms, scholarly and practical interest in this area has noticeably increased. This systematic review aims to comprehensively investigate current research on three prominent AWE systems: Grammarly, Pigai, and Criterion. Objectives include assessing each system's characteristics, advantages, and drawbacks, analyzing prior studies' frameworks, methodologies, findings, and implications, and identifying research gaps and future directions. The analysis of 39 articles underscored an escalating interest in scrutinizing AWE systems, predominantly focusing on their efficacy and learners' viewpoints. The findings demonstrated the positive impact of AWE systems on enhancing students' writing proficiency, with both learners and educators conveying positive attitudes towards these digital tools. However, several noteworthy research gaps endure, including the need to further investigate the usage patterns of AWE tools, expanding the participants to wider language proficiency and research comparing AWE feedback with peer feedback. The majority of the studies focused on non-native English-speaking university students over a single academic semester, using quantitative and mixed research methods. The review concludes by offering insights and recommendations for educators and researchers in the field, stressing the importance of tackling the identified research gaps and further delving into the potential of AWE systems in the age of generative artificial intelligence.
110	From virtual assistant to writing mentor: Exploring the impact of a ChatGPT-based writing instruction protocol on EFL teachers' self-efficacy and learners' writing skill artificial intelligence (AI); ChatGPT; L2 writing; positive psychology; teacher self-efficacy Language teaching is a highly emotional profession that can affect the teachers' well-being and learners' achievement. However, studies have yet to explore the potential of positive psychology interventions and artificial intelligence (AI) tools to promote the psycho-emotional aspects of second language (L2) teachers and learners. Further, studies regarding the effectiveness of AI in promoting the learners' language skills could have been expansive. Responding to these gaps, researchers chose ChatGPT, an AI-powered chatbot capable of generating natural and coherent texts, as a potential tool to foster positive emotions and interactions between Iranian English language teachers (n = 12) and learners (n = 48) in the L2 writing context. We operationalized ChatGPT in a three-phased writing instruction protocol (CGWIP): (1) a planning phase, where teachers used ChatGPT to brainstorm ideas and generate outlines for each session; (2) an instruction phase, where teachers used ChatGPT to engage the learners in writing process, analyse and reflect on their drafts, and (3) an assessment phase, where teachers used ChatGPT to simulate IELTS writing exam and provided detailed and constructive feedback to the learners. We further tested the effectiveness of CGWIP on teachers' self-efficacy and learners' writing skills before and after a 10-week instruction program. The Independent Samples t-test results showed that CGWIP significantly enhanced teachers' self-efficacy compared to the control group. Also, the results of One Way ANCOVA revealed that CGWIP significantly improved learners' writing skills and that these effects persisted over time. The study implied that the protocol can nurture teachers' efficiency by helping them in various aspects of L2 writing instruction, including brainstorming, revising, providing feedback, and assessment, which in turn, improves learners' writing skills.
111	Human-AI collaboration patterns in AI-assisted academic writing Higher education; artificial intelligence (AI); doctoral studies; academic writing; self-regulated learning Artificial Intelligence (AI) has increasingly influenced higher education, notably in academic writing where AI-powered assisting tools offer both opportunities and challenges. Recently, the rapid growth of generative AI (GAI) has brought its impacts into sharper focus, yet the dynamics of its utilisation in academic writing remain largely unexplored. This paper focuses on examining the nature of human-AI interactions in academic writing, specifically investigating the strategies doctoral students employ when collaborating with a GAI-powered assisting tool. This study involves 626 recorded activities on how ten doctoral students interact with GAI-powered assisting tool during academic writing. AI-driven learning analytics approach was adopted for three layered analyses: (1) data pre-processing and analysis with quantitative content analysis, (2) sequence analysis with Hidden Markov Model (HMM) and hierarchical sequence clustering, and (3) pattern analysis with process mining. Findings indicate that doctoral students engaging in iterative, highly interactive processes with the GAI-powered assisting tool generally achieve better performance in the writing task. In contrast, those who use GAI merely as a supplementary information source, maintaining a linear writing approach, tend to get lower writing performance. This study points to the need for further investigations into human-AI collaboration in learning in higher education, with implications for tailored educational strategies and solutions.
112	Deconstructing University Learners' Adoption Intention Towards AIGC Technology: A Mixed-Methods Study Using ChatGPT as an Example artificial intelligence generated content; ChatGPT; fuzzy-set qualitative comparative analysis; grounded theory; higher education BackgroundChatGPT, as a cutting-edge technology in education, is set to significantly transform the educational landscape, raising concerns about technological ethics and educational equity. Existing studies have not fully explored learners' intentions to adopt artificial intelligence generated content (AIGC) technology, highlighting the need for deeper insights into the factors influencing adoption.ObjectivesThis study aims to investigate higher education learners' adoption intentions towards AIGC technology, with a focus on understanding the underlying reasons and future prospects for its application in education.MethodsThe research is divided into two phases. First, an exploratory analysis involving practical activities and interviews develops an action decision framework for AIGC adoption. Second, a confirmatory analysis using fuzzy-set qualitative comparative analysis on 233 valid questionnaires identifies six configurations associated with high adoption intentions, emphasising the roles of AI literacy and perceived behavioural control.Results and ConclusionsThe study reveals key factors influencing AIGC adoption, including the importance of AI literacy and perceived behavioural control. It provides actionable insights for educators and learners to prepare for and effectively integrate AIGC technology, ensuring equitable and adaptive educational practices.
113	Examining the moderating effect of motivation on technology acceptance of generative AI for English as a foreign language learning Generative AI; Technology acceptance; UTAUT2; Moderating effect; Self-determination theory; Motivation; English as a foreign language Grounded in the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2), this study investigates the interplay between key UTAUT2 constructs and motivation modeled by Self-Determination Theory (SDT) in shaping English as a Foreign Language (EFL) learners' behavioral intention and actual use of generative AI tools. Accordingly, three research questions were devised, including (1) What are the structural relationships between the UTAUT2 constructs for EFL learners to accept and use generative AI for English learning? (2) Does EFL learners' SDT motivation influence their behavioral intention toward and actual use of generative AI? and (3) What are the moderating effects of EFL learners' SDT motivation toward their acceptance and use of generative AI? A comprehensive survey involving 620 Chinese undergraduates assessed their technology acceptance and SDT motivation of generative AI tools in the EFL learning context. Confirmatory factor analysis and structural equation modeling were employed to analyze the data. Results indicate robust model fit indices, both with and without considering moderating effects. Performance expectancy, effort expectancy, social influence, hedonic motivation, habit, and SDT motivation serve as significant predictors of EFL learners' behavioral intention towards generative AI tools, while price value does not demonstrate a significant impact on behavioral intention. Additionally, behavioral intention and SDT motivation jointly and significantly predict EFL learners' actual use of the technology. Importantly, introducing SDT motivation as a moderator unveils additional insights. Facilitating conditions exerts a significant influence on both behavioral intention and actual use, indicating a significant moderating effect of SDT moderation on these two pathways. Moreover, SDT motivation also significantly moderates the relationships between facilitating conditions and behavioral intention as well as between facilitating conditions and actual use, adding depth to our understanding of the nuanced interplay between motivation and technology acceptance of generative AI tools. The study concludes with insightful discussions on the findings, acknowledging the robust contributions and highlighting areas for future research to further enrich our understanding of EFL learners' adoption of generative AI tools in the context of UTAUT2 with SDT moderation.
114	The factors affecting teachers' adoption of AI technologies: A unified model of external and internal determinants AI adoption; Education; Intrinsic motivation; Self-efficacy; Institutional support; Information credibility This study examines factors influencing teachers' intention to adopt Generative AI technologies in education by extending the Technology Acceptance Model (TAM). The proposed comprehensive model incorporates both external factors (exposure to AI information, information credibility, and institutional support) and internal factors (intrinsic motivation and self-efficacy). A survey of 400 teachers reveals that teachers' exposure to credible AI information positively influences perceptions of Generative AI usefulness, which ultimately impacts their intention to use AI. Importantly, institutional support has both direct and indirect effects on teachers' intention to use AI, with the indirect effect mediated by the internal factors of intrinsic motivation and self-efficacy. This research complements TAM theory by integrating psychological and contextual factors, offering a nuanced framework for understanding Generative AI adoption in educational settings. The findings suggest that for educational leaders and policymakers, developing strategies that allocate resources for infrastructure, technical support, and professional development-such as Generative AI training programs-will be crucial in driving Generative AI adoption among teachers. By addressing both external and internal determinants, this study provides a comprehensive perspective of the dynamics behind technology acceptance in the classroom.
115	Effectiveness of artificial intelligence integration in design-based learning on design thinking mindset, creative and reflective thinking skills: An experimental study Artificial intelligence; Design-based learning activities; ChatGPT, Design thinking mindset; Thinking skills; Storytelling Integrating Artificial Intelligence (AI) into learning activities is an essential opportunity to develop students' varied thinking skills. On the other hand, design-based learning (DBL) can more effectively foster creative design processes with AI technologies to overcome real-world challenges. In this context, AI-supported DBL activities have a significant potential for teaching and developing thinking skills. However, there is a lack of experimental interventions in the literature examining the effects of integrating AI into learner-centered methods on active engagement and thinking skills. The current study aims to explore the effectiveness of AI integration as a guidance and collaboration tool in a DBL process. In this context, the effect of the experimental application on the participants' design thinking mindset, creative self-efficacy (CSE), and reflective thinking (RT) self-efficacy levels and the relationship between them were examined. The participants used ChatGPT and Midjourney in the digital story development process as part of the experimental treatment. The only difference between the control and experimental groups in the digital storytelling process is the AI applications used in the experimental treatment (ChatGPT and Midjourney). In this quasi-experimental method study, participants were randomly assigned to treatment, an AI integration intervention, at the departmental level. 87 participants (undergraduate students) in the experimental group and 99 (undergraduate students) in the control group. The implementation process lasted five weeks. Partial Least Squares (PLS), Structural Equation Modeling (SEM), and Multi-Group Analysis (MGA) were made according to the measurements made at the T0 point before the experiment and at the T1 point after the experiment. According to the research result, the intervention in both groups contributed to the creative self-efficacy, critical reflection, and reflection development of the participants. On the other hand, the design thinking mindset levels of both groups did not show a significant difference in the comparison of the T0 point and the T1 point.
116	AI and English language teaching: Affordances and challenges AI; AIEd; artificial intelligence; education; English foreign language; English language learning; English language teaching; GenAI; generative AI English is one of the most used languages for jobs, markets, tourism, discourse and international connectivity. However, English learners face many challenges in gaining English language skills. Extant studies show that AI has affordances to support in English language teaching and learning ELT/L. This study answers the call to examine specific challenges and affordances for using AI in ELT/L. A systematic review method was used with PRISMA principles to identify 42 studies. Findings reveal the geographical locations of studies, learner ages and years of study. Grounded coding was then used to identify affordances of the use of AI in ELT/L in the areas of speaking, writing, reading, pedagogy and self-regulation. AI in ELT/L challenges uncovered were technology breakdowns, limited capabilities, fear and standardising language. Policymakers, funders, practitioners and educational leaders can use the information provided in this study to gain a holistic understanding of the current trend in the use of AI in ELT/L, and practical implications are provided to guide future use of AI.Practitioner notes What is already known about this topic English is one of the most used languages for jobs, markets, tourism, discourse and international connectivity. Empirical evidence shows that pupils can often face difficulties when learning English, with challenges such as irregularity in English spelling. AI has supported language teaching and learning with studies showing that AI can support language-specific skills. What this paper adds Provides the scholarly community with a unique systematic review in the use of AI in ELT/L across learner levels. Identifies affordances of AI in ELT/L in speaking, writing, reading, pedagogy and self-regulation. Identifies challenges of AI in ELT/L in technology breakdowns, limited capabilities, fear and standardising language. Provides researchers with a review of the field with identification of gaps and future research opportunities. Implications for practice and/or policy Provides practical implications from the findings for educators, policy makers and program designers. Highlights the gaps in academic knowledge as a lack in the use of AI for assessment in ELT/L.
117	Practical and ethical challenges of large language models in education: A systematic scoping review artificial intelligence; BERT; ChatGPT; education; GPT-3; large language models; pre-trained language models; systematic scoping review Educational technology innovations leveraging large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (eg, question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs-based innovations in authentic educational contexts. To address this, we conducted a systematic scoping review of 118 peer-reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The findings revealed 53 use cases for LLMs in automating education tasks, categorised into nine main categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. Additionally, we also identified several practical and ethical challenges, including low technological readiness, lack of replicability and transparency and insufficient privacy and beneficence considerations. The findings were summarised into three recommendations for future studies, including updating existing innovations with state-of-the-art models (eg, GPT-3/4), embracing the initiative of open-sourcing models/systems, and adopting a human-centred approach throughout the developmental process. As the intersection of AI and education is continuously evolving, the findings of this study can serve as an essential reference point for researchers, allowing them to leverage the strengths, learn from the limitations, and uncover potential research opportunities enabled by ChatGPT and other generative AI models.
118	Investigation of the moderation effect of gender and study level on the acceptance and use of generative AI by higher education students: Comparative evidence from Poland and Egypt ChatGPT; higher education; moderating effect; technology acceptance This study delves into the implications of incorporating AI tools, specifically ChatGPT, in higher education contexts. With a primary focus on understanding the acceptance and utilization of ChatGPT among university students, the research utilizes the Unified Theory of Acceptance and Use of Technology (UTAUT) as the guiding framework. The investigation probes into four crucial constructs of UTAUT-performance expectancy, effort expectancy, social influence and facilitating conditions-to understand their impact on the intent and actual use behaviour of students. The study relies on data collected from six universities in two countries and assessed through descriptive statistics and structural equation modelling techniques, and also takes into account participants' gender and study level. The key findings show that performance expectancy, effort expectancy, and social influence significantly influence behavioural intention. Furthermore, behavioural intention, when considered alongside facilitating conditions, influences actual use behaviour. This research also explores the moderating impact of gender and study level on the relationships among these variables. The results not only augment our comprehension of technology acceptance in the context of AI tools but also provide valuable input for formulating strategies that promote effective incorporation of ChatGPT in higher education. The study underscores the need for effective awareness initiatives, bespoke training programmes, and intuitive tool designs to bolster students' perceptions and foster the wider adoption of AI tools in education
119	Effects of an AI-supported approach to peer feedback on university EFL students' feedback quality and writing ability Peer feedback; EFL students; Writing instruction; Artificial intelligence; ChatGPT This study examined the impact of an artificial intelligence (AI)-supported approach to peer feedback provision on the feedback quality and writing ability of English as a foreign language (EFL) student reviewers. The researchers integrated an AI chatbot named Eva into an online peer review system to assist students in generating feedback. A total of 124 Chinese undergraduate students participated in nine peer review tasks over three weeks, with 64 students in the experimental group (using Eva) and 60 students in the control group (without AI support). Pre- and post-tests were conducted to assess the quality of student reviewers' peer feedback and these feedback providers' writing performance before and after the intervention. The findings revealed that the intervention significantly enhanced students' feedback quality. Additionally, the study showed that the proposed approach improved feedback providers' writing ability. This research underscores the potential of AI technology in enhancing EFL writing instruction.
120	A systematic review of ChatGPT use in K-12 education artificial intelligence; ChatGPT; K-12 education; systematic review This systematic review, adhering to the PRISMA framework, investigated the utilisation of ChatGPT, a language model developed by OpenAI, throughout Kindergarten to 12th grade (K-12) educational settings. The review synthesises findings from 13 selected papers, encompassing the strengths, weaknesses, opportunities, and threats (SWOT) analysis of ChatGPT's implementation in K-12 education, implications for various stakeholders, and practical recommendations. It is highlighted that ChatGPT could empower educators through curriculum, lesson planning, materials generation, differentiation, and optimising student learning experience through personalised learning. However, concerns regarding academic integrity and output quality must be addressed. The paper provides pedagogical recommendations and ethical considerations to utilise ChatGPT better. It contributes to the ongoing discourse about AI, particularly ChatGPT's role in K-12 education, further inspiring future research and educational practices and facilitating the effective integration of ChatGPT into K-12 educational settings where collaboration arises as a key role, in particular under the approach of co-design for learning.
121	The influence of ChatGPT on student engagement: A systematic review and future research agenda OpenAI; Student engagement; Systematic review; Artificial intelligence ChatGPT, a state-of-the-art artificial intelligence (AI) chatbot, has gained considerable attention as a transformative yet controversial tool for enhancing teaching and learning experiences. Several reviews and numerous articles have been written about harnessing ChatGPT in education since its release on November 30, 2022. Besides summarising its strengths, weaknesses, opportunities, and threats (SWOT) as identified in previous systematic reviews of ChatGPT research, this systematic review aims to develop a new understanding of its influence on student engagement by synthesising the existing related research using a three-dimensional framework comprising behavioural, emotional, and cognitive aspects. We searched relevant databases and included 72 empirical studies published within one year of ChatGPT's initial release. The findings reveal robust but narrowly focused evidence related to behavioural engagement (i.e., work with ChatGPT) and disengagement (i.e., academic dishonesty). The evidence related to the emotional aspect is mixed, with instances of both engagement (e.g., satisfaction and interest/fun) and disengagement (e.g., disappointment and worry/anxiety). There is broad but weak evidence regarding cognitive engagement (e.g., increased understanding and positive self-perception) and disengagement (e.g., reduced critical thinking and overreliance). Our review uncovers several under-explored indicators of student engagement, pointing to the need for further research. Specifically, future studies could focus on students' study habits and attendance (behavioural engagement), social interaction (emotional engagement), and self-regulation and critical thinking (cognitive engagement) in ChatGPT-supported learning environments.
122	Impact of ChatGPT on learners in a L2 writing practicum: An exploratory investigation ChatGPT; Technology-enhanced writing; Automatic text generation; Plagiarism; AI-enhanced education Technology-enhanced language learning has exerted positive effects on the performance and engagement of L2 learners. Since the advent of tools based on recent advancement in artificial intelligence (AI), educators have made major strides in applying state-of-the-art technologies to writing classrooms. In November 2022, an AI-powered chatbot named ChatGPT capable of automatic text generation was introduced to the public. The study tried to apply ChatGPT's text generation feature in a one-week L2 writing practicum. The study adopted a qualitative approach to investigate students' behaviors and reflections in their exposure to ChatGPT in writing classrooms. The developmental features in learning activities and reflective perceptions were triangulated for the piloting evaluation of the impact of ChatGPT on L2 writing learners. The findings revealed the affordance and potential applicability of the tool in L2 writing pedagogy. Additionally, the tool also showcased an automatic workflow that could maximize the efficiency in composing writing. However, participants generally expressed their concern with its threats to academic honesty and educational equity. The study impelled the reconceptualization of plagiarism in the new era, development of regulatory policies and pedagogical guidance to regulate proper utilization of the tool. Being a pioneering effort, the study accentuated future research directions for more insights into the application of ChatGPT in L2 learning, and the establishment of corresponding pedagogical adjustments.
123	A SWOT analysis of ChatGPT: Implications for educational practice and research Artificial intelligence; ChatGPT; educational technologies; higher education; SWOT analysis ChatGPT is an AI tool that has sparked debates about its potential implications for education. We used the SWOT analysis framework to outline ChatGPT's strengths and weaknesses and to discuss its opportunities for and threats to education. The strengths include using a sophisticated natural language model to generate plausible answers, self-improving capability, and providing personalised and real-time responses. As such, ChatGPT can increase access to information, facilitate personalised and complex learning, and decrease teaching workload, thereby making key processes and tasks more efficient. The weaknesses are a lack of deep understanding, difficulty in evaluating the quality of responses, a risk of bias and discrimination, and a lack of higher-order thinking skills. Threats to education include a lack of understanding of the context, threatening academic integrity, perpetuating discrimination in education, democratising plagiarism, and declining high-order cognitive skills. We provide agenda for educational practice and research in times of ChatGPT.
124	Chatting and cheating: Ensuring academic integrity in the era of ChatGPT Machine-generated writing; plagiarism; higher education; detection and prevention The use of artificial intelligence in academia is a hot topic in the education field. ChatGPT is an AI tool that offers a range of benefits, including increased student engagement, collaboration, and accessibility. However, is also raises concerns regarding academic honesty and plagiarism. This paper examines the opportunities and challenges of using ChatGPT in higher education, and discusses the potential risks and rewards of these tools. The paper also considers the difficulties of detecting and preventing academic dishonesty, and suggests strategies that universities can adopt to ensure ethical and responsible use of these tools. These strategies include developing policies and procedures, providing training and support, and using various methods to detect and prevent cheating. The paper concludes that while the use of AI in higher education presents both opportunities and challenges, universities can effectively address these concerns by taking a proactive and ethical approach to the use of these tools.
125	Health profession students' perceptions of ChatGPT in healthcare and education: insights from a mixed-methods study Artificial Intelligence; ChatGPT; Health Profession Students; Medical Education; Mixed-Methods Study; Perception; Integration ObjectiveThe aim of this study was to investigate the perceptions of health profession students regarding ChatGPT use and the potential impact of integrating ChatGPT in healthcare and education.BackgroundArtificial Intelligence is increasingly utilized in medical education and clinical profession training. However, since its introduction, ChatGPT remains relatively unexplored in terms of health profession students' acceptance of its use in education and practice.DesignThis study employed a mixed-methods approach, using a web-based survey.MethodsThe study involved a convenience sample recruited through various methods, including Faculty of Medicine announcements, social media, and snowball sampling, during the second semester (March to June 2023). Data were collected using a structured questionnaire with closed-ended questions and three open-ended questions. The final sample comprised 217 undergraduate health profession students, including 73 (33.6%) nursing students, 65 (30.0%) medical students, and 79 (36.4%) occupational therapy, physiotherapy, and speech therapy students.ResultsAmong the surveyed students, 86.2% were familiar with ChatGPT, with generally positive perceptions as reflected by a mean score of 4.04 (SD = 0.62) on a scale of 1 to 5. Positive feedback was particularly noted with respect to ChatGPT's role in information retrieval and summarization. The qualitative data revealed three main themes: experiences with ChatGPT, its impact on the quality of healthcare, and its integration into the curriculum. The findings highlight benefits such as serving as a convenient tool for accessing information, reducing human errors, and fostering innovative learning approaches. However, they also underscore areas of concern, including ethical considerations, challenges in fostering critical thinking, and issues related to verification. The absence of significant differences between the different fields of study indicates consistent perceptions across nursing, medicine, and other health profession students.ConclusionsOur findings underscore the necessity for continuous refinement to enhance ChatGPT's accuracy, reliability, and alignment with the diverse educational needs of health professions. These insights not only deepen our understanding of student perceptions of ChatGPT in healthcare education but also have significant implications for the future integration of AI in health profession practice. The study emphasizes the importance of a careful balance between leveraging the benefits of AI tools and addressing ethical and pedagogical concerns.
126	Exploring the potential of an AI-based Chatbot (ChatGPT) in enhancing English as a Foreign Language (EFL) teaching: perceptions of EFL Faculty Members EFL; Faculty members perceptions; ChatGPT; Applied college; Northern Border University The aim of this survey study was to investigate the perceptions of ten English as a Foreign Language (EFL) faculty members at Northern Border University regarding the effectiveness of ChatGPT in supporting their students' English language learning. The study utilized in-depth interviews with the faculty members as the primary data collection method. The results of the interviews demonstrated that the faculty members held varying opinions about the efficacy of ChatGPT. Some faculty members acknowledged its usefulness in providing rapid and accurate responses to a wide range of questions, while others expressed concerns that ChatGPT might hinder students' development of critical thinking and research skills, and potentially reinforce biases or misinformation. The study sample perceives ChatGPT as a valuable tool for complementing and enhancing traditional EFL teaching methods. Nonetheless, the faculty members recognized ChatGPT's value as a teaching and learning aid and recommended further experimental research to evaluate its effectiveness. The study emphasizes the potential of ChatGPT as a tool for enhancing EFL students' English language proficiency.
127	Factors influencing students' intention to adopt and use ChatGPT in higher education: A study in the Vietnamese context ChatGPT; Human-computer interface; Adoption intention; Vietnam; Higher education ChatGPT, an extensively recognised language model created by OpenAI, has gained significant prominence across various industries, particularly in education. This study aimed to investigate the factors that influence students' intentions to adopt and utilise ChatGPT for their academic studies. The study used a Structural Equation Model (SEM) for analysing the data gathered from 108 participants, comprising both undergraduate and postgraduate students enrolled in public and private universities in Vietnam. The findings indicated that students' inclination to adopt ChatGPT (referred to as adoption intention or AI) was influenced by their perception of its user-friendliness (PEU). However, the perceived usefulness (PU) of ChatGPT did not have a direct impact on students' adoption intention; instead, it had an indirect influence through personalisation (with a positive effect) and interactivity (with a negative effect). Importantly, there was no significant indirect effect of PU on AI mediated by perceived trust and perceived intelligence. This study is one of the initial empirical inquiries into ChatGPT adoption within an Asian context, providing valuable insights in this emerging area of research. As the use of ChatGPT by students becomes increasingly inevitable, educational institutions should carefully consider integrating it into the assessment process. It is crucial to design assessments that encourage responsible usage of ChatGPT, preserving students' critical thinking abilities and creativity in their assessment writing. Moving forward, educators will play a pivotal role by offering clear guidelines and instructions that set out the appropriate and ethical use of artificial intelligence tools in the assessments.
128	Using ChatGPT to promote research competency: English as a Foreign Language undergraduates&apos; perceptions and practices across varied metacognitive awareness levels artificial intelligence (AI); ChatGPT, research competency; EFL undergraduates; metacognitive awareness Background: Introducing new technologies in education sparks debates, disrupting traditional practices, and requiring teacher adaptation. ChatGPT is an example. Research explores its benefits and concerns in education, with recommendations for classroom use. Nevertheless, limited evidence supports ChatGPT as a tool for supporting English as a Foreign Language (EFL) students' research competency. Moreover, while the literature primarily focuses on the perspectives of scholars and teachers, it is essential to incorporate students' viewpoints in order to maximize the potential of this technology. Objectives: The present study investigated EFL undergraduates' perceptions and practices of ChatGPT as a tool for promoting their research competency. Additionally, the study examined the potential influence of metacognitive awareness (MA) levels in this context. Methods: The study utilized a mixed-method research design, collecting quantitative and qualitative data from 27 EFL undergraduates (12 with low MA and 15 with high MA) over one semester. Data sources included a self-report questionnaire, self-study log, and semi-structured interviews. Results and conclusions: Quantitative analysis showed significant differences between low and high MA groups in their perceptions of ChatGPT (U = 37.500, Z = 2.570). Regression analysis revealed a positive correlation between MA scores and students' perceptions and practices of ChatGPT. Qualitative analysis revealed diverse perceptions and practices of ChatGPT between the high MA and low MA groups, showcasing behaviours ranging from replication to using ChatGPT as a thought-stimulating and supportive tool, accessing supplementary information, and seeking guidance. Key factors for effective ChatGPT use included prompt formulation, systematic thinking, self-regulation strategies, and trust in AI.
129	Student interaction with ChatGPT can promote complex critical thinking skills Artificial intelligence; Critical thinking; Education Background: The widespread adoption of AI-based chatbots has revolutionized the interaction between individuals and machines, providing personalized and immediate responses. Within the educational sector, students increasingly rely on ChatGPT to address academic challenges, but the consequences of this interaction on critical thinking abilities are not well understood. This study aims to explore the relationship between factors such as attitudes and trust towards AI, engagement, knowledge, and the ability to solve complex critical thinking in a sample of Italian students. Methods: Two hundred and thirteen students completed self-report questionnaires and performance measures on the Critical Reasoning Assessment. Results: The results highlighted significant relationships among the variables considered, emphasizing a direct impact of attitude and trust on knowledge and engagement with AI. Furthermore, engagement proved to have a particularly significant impact on critical thinking performance compared to knowledge. Conclusions: These findings are relevant in the educational context, suggesting that interaction with AI-based chatbots can be a valuable resource for the development of students' critical thinking skills. However, it is emphasized the importance of adopting an educational approach that fosters active engagement and in-depth understanding to promote the critical analysis of information provided by AI-based chatbots.
130	Impacts of ChatGPT-assisted writing for EFL English majors: Feasibility and challenges ChatGPT; Artificial intelligence; AI-assisted writing; EFL writing; NLP To determine the impacts of using ChatGPT to assist English as a foreign language (EFL) English college majors in revising essays and the possibility of leading to higher scores and potentially causing unfairness. A prospective, double-blinded, paired-comparison study was conducted in Feb. 2023. A total of 44 students provided 44 original essays and 44 ChatGPT-assisted revised essays, which were rated by two independent graders in a randomized and crossover fashion to minimize grading bias. The original and revision scores were paired for before-after comparison. Eight control essays were also rated by both graders to ensure inter-rater reliability. This study used a rigorous experimental design to confirm that ChatGPT-assisted revised essays led to significantly higher scores for EFL college English majors. Significant improvements were observed in all four dimensions of writing quality assessment, with the largest effects observed in vocabulary, followed by grammar, organization, and content. ChatGPT-assisted revised essays shifted the score curve from a normal distribution to a skewed distribution towards higher grades, with the greatest increase in revision scores seen among students who had lower original scores. This disproportionate improvement raises concerns about fairness in evaluation. The findings suggest that ChatGPT is effective in providing timely feedback to EFL English majors in an affordable manner, but it also highlights the potential for unfairness in writing evaluation. We should note that ChatGPT-assisted revisions do not reveal learners' writing competence. Therefore, new forms of writing performance assessment should be implemented in EFL composition classes in this AI era.
131	Disclosing the Correlation Between Using ChatGPT and Well-Being in EFL Learners: Considering the Mediating Role of Emotion Regulation ChatGPT; EFL learners; emotion regulation; well-being Artificial Intelligence (AI)-driven chatbots, such as ChatGPT, have significantly impacted education, especially for English as a Foreign Language (EFL) learners. However, there is paucity of empirical evidence concerning the role of chatbots in psycho-emotional constructs like well-being and emotion regulation. It is important to address this issue because it can further our understanding of the ways through which using ChatGPT affects psycho-emotional constructs in EFL learners. This study aimed to unpack the intersection between using ChatGPT and well-being, with a focus on the mediating role of emotion regulation in the EFL context of Iran. Using convenience sampling, 492 EFL learners (205 males and 287 females) were invited to complete validated scales measuring ChatGPT use, well-being, and emotion regulation. The outcomes of structural equation modelling revealed a strong mediation effect of emotion regulation in the relationship between using ChatGPT and well-being. Additionally, significant positive correlations were found between using ChatGPT and both well-being and emotion regulation. Besides, a significant positive relationship was established between emotion regulation and well-being among the EFL learners. The results imply that the integration of ChatGPT into the Iranian EFL learning environment can be beneficial, considering its positive correlations with both well-being and emotion regulation among the Iranian EFL learners.
132	ChatGPT adoption and its influence on faculty well-being: An empirical research in higher education ChatGPT; TAM framework; Faculty well-being; Perceived usefulness; Easy-of-use; Enjoyment; Happiness; Energy; Stress Rapid technological advancements of recent decades have fueled, among other aspects, a global boom in the utilization of artificial intelligence (AI) tools across a variety of areas. Higher education, like other domains, has embraced these innovations, with ChatGPT emerging as one of the latest additions. Faculty perception, ability, and willingness to adopt these new tools remain fundamental factors in understanding their proliferation and adoption. However, it's equally important to strike a balance between reaping the benefits of technology and safeguarding the well-being of faculty members. Against this backdrop, this study assesses the impact of a series of factors on ChatGPT adoption among university faculty members, taking as reference the Technology Acceptance Model (TAM). Additionally, we analyze the impact of ChatGPT adoption on faculty well-being. All hypotheses are tested using covariance-based structural equation modeling (CB-SEM). The findings highlight the positive influence of perceived usefulness, ease of use and enjoyment on ChatGPT adoption. Moreover, ChatGPT adoption seems to boost faculty' happiness and energy, while diminishing their stress levels. Theoretical and practical implications are discussed in the last section.
133	Feedback sources in essay writing: peer-generated or AI-generated feedback? AI-generated feedback; ChatGPT; Essay writing; Feedback sources; Higher education; Peer feedback Peer feedback is introduced as an effective learning strategy, especially in large-size classes where teachers face high workloads. However, for complex tasks such as writing an argumentative essay, without support peers may not provide high-quality feedback since it requires a high level of cognitive processing, critical thinking skills, and a deep understanding of the subject. With the promising developments in Artificial Intelligence (AI), particularly after the emergence of ChatGPT, there is a global argument that whether AI tools can be seen as a new source of feedback or not for complex tasks. The answer to this question is not completely clear yet as there are limited studies and our understanding remains constrained. In this study, we used ChatGPT as a source of feedback for students' argumentative essay writing tasks and we compared the quality of ChatGPT-generated feedback with peer feedback. The participant pool consisted of 74 graduate students from a Dutch university. The study unfolded in two phases: firstly, students' essay data were collected as they composed essays on one of the given topics; subsequently, peer feedback and ChatGPT-generated feedback data were collected through engaging peers in a feedback process and using ChatGPT as a feedback source. Two coding schemes including coding schemes for essay analysis and coding schemes for feedback analysis were used to measure the quality of essays and feedback. Then, a MANOVA analysis was employed to determine any distinctions between the feedback generated by peers and ChatGPT. Additionally, Spearman's correlation was utilized to explore potential links between the essay quality and the feedback generated by peers and ChatGPT. The results showed a significant difference between feedback generated by ChatGPT and peers. While ChatGPT provided more descriptive feedback including information about how the essay is written, peers provided feedback including information about identification of the problem in the essay. The overarching look at the results suggests a potential complementary role for ChatGPT and students in the feedback process. Regarding the relationship between the quality of essays and the quality of the feedback provided by ChatGPT and peers, we found no overall significant relationship. These findings imply that the quality of the essays does not impact both ChatGPT and peer feedback quality. The implications of this study are valuable, shedding light on the prospective use of ChatGPT as a feedback source, particularly for complex tasks like argumentative essay writing. We discussed the findings and delved into the implications for future research and practical applications in educational contexts.
134	Discourses of artificial intelligence in higher education: a critical literature review Higher education; Discourse analysis; Artificial intelligence; Critical literature review; Qualitative methods Artificial intelligence (AI) holds significant implications for higher education; however, references to AI in the literature are often vague and open to debate. In order to understand how to progress AI-related research and analysis, this critical review systematically searched top higher education journals for references to the term 'artificial intelligence'. We reviewed definitions and conducted a discourse analysis of included texts. Our findings identify few, confusing definitions and little overt reference to AI as a research object. We delineated two Discourses. The Discourse of imperative change outlines how AI is seen as an inevitable change to which all must respond. Additionally, the Discourse of altering authority describes how texts position AI as decentring the teacher and spreading authority across staff, machines, corporations and students. Our analysis prompts a call for new research foci that attend to the social implications of AI, including tracing accountability in AI-mediated practices and exploring how AI influences learning and teaching relationships.
135	Few-shot is enough: exploring ChatGPT prompt engineering method for automatic question generation in english education Automatic Question Generation; Prompt Engineering; ChatGPT; Large Language Model; English Education Through design and development research (DDR), we aimed to create a validated automatic question generation (AQG) system using large language models (LLMs) like ChatGPT, enhanced by prompting engineering techniques. While AQG has become increasingly integral to online learning for its efficiency in generating questions, issues such as inconsistent question quality and the absence of transparent and validated evaluation methods persist. Our research focused on creating a prompt engineering protocol tailored for AQG. This protocol underwent several iterations of refinement and validation to improve its performance. By gathering validation scores and qualitative feedback on the produced questions and the system's framework, we examined the effectiveness of the system. The study findings indicate that our combined use of LLMs and prompt engineering in AQG produces questions with statistically significant validity. Our research further illuminates academic and design considerations for AQG design in English education: (a) certain question types might not be optimal for generation via ChatGPT, (b) ChatGPT sheds light on the potential for collaborative AI-teacher efforts in question generation, especially within English education.
136	Artificial Intelligence-Supported Student Engagement Research: Text Mining and Systematic Analysis applications; artificial intelligence; student engagement; systematic review; text mining; trends Artificial intelligence (AI) is increasingly exploited to promote student engagement. This study combined topic modelling, keyword analysis, trend test and systematic analysis methodologies to analyse AI-supported student engagement (AIsE) studies regarding research keywords and topics, AI roles, AI systems and algorithms, methods and domains, samples and outcomes. Findings included the following: (1) frequent-used and emerging keywords comprised 'machine learning', 'artificial intelligence chatbot' and 'collaborative knowledge building'. (2) Frequently studied topics included 'AI for MOOCs and self-regulated learning' and 'affective computing and emotional engagement'. (3) Most studies adopted intelligent tutoring systems, traditional machine learning methods and natural language processing. (4) Emotional engagement regarding affective or psychological states among college students received the most attention. (5) Most studies adopted quantitative approaches and concerned computer science and language education. Accordingly, we highlighted AI's roles as tutors, advisors, partners, tutees and regulators for behavioural, cognitive and emotional engagement to inspire AI's effective integration into education.
137	Untangling the Relationship Between AI-Mediated Informal Digital Learning of English (AI-IDLE), foreign Language Enjoyment and the Ideal L2 Self: Evidence From Chinese University EFL Students AI-mediated language learning; foreign language enjoyment; informal digital learning of English (IDLE); L2 motivation; the ideal L2 self Artificial intelligence-mediated informal digital learning of English (AI-IDLE) might strengthen second language (L2) learners' motivational self-concept (e.g., the ideal L2 self) and enhance their foreign language enjoyment (FLE) by enabling them to build confidence, engagement, and willingness to practice their English skills in a self-directed, instant feedback, and non-judgemental learning environment. In our explanatory mixed-method study, we collected questionnaire data from 299 Chinese undergraduate English as a foreign language (EFL) learners and interviewed 12 of them. Structural equation modelling showed that students who participated in AI-IDLE more often reported a clearer ideal L2 self and greater FLE, but those with a greater ideal L2 self did not report more FLE. In addition, gender did not moderate the impact of AI-IDLE on FLE. Analysis of the interview data not only corroborated the quantitative results but also highlighted that while EFL learners can acquire a sense of FLE and vivid ideal L2 selves as they agentively negotiate the affordances of generative AI for informal language learning purposes, the sense of FLE and motivational force may shift across contexts to shape their continued investment in AI-IDLE practices. By comparing and integrating the quantitative and qualitative insights, this study highlights the pedagogical potential of AI-IDLE activities that can strengthen EFL learners' motivation, enjoyment, and commitment to English learning.
138	The factors influencing teacher education students' willingness to adopt artificial intelligence technology for information-based teaching Technology acceptance model; artificial intelligence literacy; education students; Chinese universities; information-based teaching This study, rooted in the Technology Acceptance Model (TAM), investigates the multifaceted factors that influence teacher education students in Information-Based Teaching to embrace artificial intelligence technologies. To enrich the TAM framework, we have incorporated elements such as Artificial Intelligence Literacy (AIL), Subjective Norms (SN), and Output Quality (OQ), with the aim of examining their respective effects on the willingness of teacher education students to adopt AI technologies. To substantiate this theoretical framework, we conducted empirical research involving teacher education students from various Chinese universities. Our findings affirm the robustness of the TAM in explaining the inclination of teacher education students, engaged in the actual teaching process within a digitized educational environment, to adopt AI technologies. Through this model, our study underscores the pivotal role of Artificial Intelligence Literacy (AIL) in influencing educators' acceptance of AI technologies, establishing a foundational cornerstone for subsequent explorations within the theoretical landscape of the TAM. In this study, we identify Perceived Usefulness (PU) and Artificial Intelligence Literacy (AIL) as the primary factors affecting Behavioral Intention (BI) to use AI technologies. Consequently, to foster broader adoption of AI technologies by educators, it is essential to emphasize their tangible benefits and superiority in teaching, with the goal of promoting the extended utilization of AI in digitalized instruction.
139	Students' appraisals post-ChatGPT use: Students' narrative after using ChatGPT for writing Artificial intelligence; ChatGPT; technology-enhanced writing; students' perception on ChatGPT, essay writing This study aims to explore the students' experience with ChatGPT in providing scaffolding for writing essays. It also discloses students' appraisals of utilising ChatGPT. Drawing upon data from semi-structured interviews, this study involved 12 students learning English as a Foreign Language who utilised ChatGPT in academic writing classes. The findings revealed that students derived advantages from using ChatGPT for translation, writing accuracy, writing efficiency, idea generation, and practical use. This study also reveals students' criticism in terms of inaccurate information generated as well as the possibility of students committing academic dishonesty when using ChatGPT. This study indicates that although students use ChatGPT to help them write their essays, they have the awareness to fact-check the information to avoid committing academic dishonesty.
140	Effects of higher education institutes' artificial intelligence capability on students' self-efficacy, creativity and learning performance Artificial intelligence capability; Higher education institute; Learning performance; Student creativity; Self-efficacy; PLS-SEM; Higher-order Constructs Artificial Intelligence (AI) has become an important technology affecting the development of society and education, and it is crucial to explore AI to enhance students' creativity and learning performance. This research proposes the model and hypothesis based on the resource-based theory and related research. AI of higher education institute (HEI) affects students' learning performance and combines the existing literature to develop measurement tools and to obtain a formal questionnaire after pre-research and received 561 valid questionnaires collected from HEIs in China that have applied AI. Then we used SmartPLS 3.0 to construct a partial least squares structural equation model (PLS-SEM) for data analysis on the received data samples. The research results show that: 1) HEIs' artificial intelligence capability is a three-order variable and formed by three formative second-order variables such as resources (data, technical, basic resources), skills (technical skills, teaching applications, collaboration competencies), and consciousness (reform, innovation consciousness); 2) HEIs' artificial intelligence capability significantly affects students' self-efficacy and creativity; 3) HEIs' artificial intelligence capability affects students' learning performance via two mediating variables: student creativity and self-efficacy. This study focuses on AI applications within the HEI, confirms the new explanatory power of resource-based theory in technological practices, and deconstructs the intrinsic mechanics, especially in relationships between students' creativity, self-efficacy, and learning performance. This research also puts forward suggestions to reserve and deploy artificial intelligence resources, improve the digital literacy of teachers and students, use AI to drive teaching and learning, and improve students' creativity and learning performance.
141	The application of AI technologies in STEM education: a systematic review from 2011 to 2021 Artificial intelligence; Artificial intelligence in education; STEM education; General system theory; Educational system Background The application of artificial intelligence (AI) in STEM education (AI-STEM), as an emerging field, is confronted with a challenge of integrating diverse AI techniques and complex educational elements to meet instructional and learning needs. To gain a comprehensive understanding of AI applications in STEM education, this study conducted a systematic review to examine 63 empirical AI-STEM research from 2011 to 2021, grounded upon a general system theory (GST) framework. Results The results examined the major elements in the AI-STEM system as well as the effects of AI in STEM education. Six categories of AI applications were summarized and the results further showed the distribution relationships of the AI categories with other elements (i.e., information, subject, medium, environment) in AI-STEM. Moreover, the review revealed the educational and technological effects of AI in STEM education. Conclusions The application of AI technology in STEM education is confronted with the challenge of integrating diverse AI techniques in the complex STEM educational system. Grounded upon a GST framework, this research reviewed the empirical AI-STEM studies from 2011 to 2021 and proposed educational, technological, and theoretical implications to apply AI techniques in STEM education. Overall, the potential of AI technology for enhancing STEM education is fertile ground to be further explored together with studies aimed at investigating the integration of technology and educational system.
142	Using ChatGPT for second language writing: Pitfalls and potentials Chatbots; Immersive technology; L2 writing; Computer -assisted language learning Recent advances in artificial intelligence have given rise to the use of chatbots as a viable tool for language learning. One such tool is ChatGPT, which engages users in natural and human-like interactive experiences. While ChatGPT has the potential to be an effective tutor and source of language input, some academics have expressed concerns about its impact on writing pedagogy and academic integrity. Thus, this tech review aims to explore the potential benefits and challenges of using ChatGPT for second language (L2) writing. This review concludes with some recommendations for L2 writing classroom practices.
143	Empowering education development through AIGC: A systematic literature review Artificial intelligence generated content; ChatGPT; Artificial intelligence; Systematic literature review; Educational technology As an exemplary representative of AIGC products, ChatGPT has ushered in new possibilities for the field of education. Leveraging its robust text generation and comprehension capabilities, it has had a revolutionary impact on pedagogy, learning experiences, personalized education and other aspects. However, to date, there has been no comprehensive review of AIGC technology's application in education. In light of this gap, this study employs a systematic literature review and selects 134 relevant publications on AIGC's educational application from 4 databases: EBSCO, EI Compendex, Scopus, and Web of Science. The study aims to explore the macro development status and future trends in AIGC's educational application. The following findings emerge: 1) In the AIGC's educational application field, the United States is the most active country. Theoretical research dominates the research types in this domain; 2) Research on AIGC's educational application is primarily published in journals and academic conferences in the fields of educational technology and medicine; 3) Research topics primarily focus on five themes: AIGC technology performance assessment, AIGC technology instructional application, AIGC technology enhancing learning outcomes, AIGC technology educational application's Advantages and Disadvantages analysis, and AIGC technology educational application prospects. 4) Through Grounded Theory, the study delves into the core advantages and potential risks of AIGC's educational application, deconstructing the scenarios and logic of AIGC's educational application. 5) Based on a review of existing literature, the study provides valuable future agendas from both theoretical and practical application perspectives. Discussing the future research agenda contributes to clarifying key issues related to the integration of AI and education, promoting more intelligent, effective, and sustainable educational methods and tools, which is of great significance for advancing innovation and development in the field of education.
144	A systematic review of research on speech-recognition chatbots for language learning: Implications for future directions in the era of large language models Chatbot; large language model; ChatGPT; artificial intelligence; automatic speech recognition; intelligent personal assistant; language learning; computer-assisted language learning Chatbot research has received growing attention due to the rapid diversification of chatbot technology, as demonstrated by the emergence of large language models (LLMs) and their integration with automatic speech recognition. However, among various chatbot types, speech-recognition chatbots have received limited attention in relevant research reviews, despite their increasing potential for language learning. To fill this gap, 32 empirical studies on speech-recognition chatbots for language learning were reviewed. The following information was reviewed for each study: basic publication information, research focus, location of chatbot use, methodology, group design format, participant information, intervention duration, target language, device type adopted, and chatbot role. An upward trend in research quantity starting in 2020 was identified, which accelerated exponentially in 2022. College students were more likely than other groups to be involved in research, and English as a second or foreign language was the most common target language. Most studies focused on participants' perceptions of chatbots and the degree to which using chatbots helped them develop their speaking or listening proficiency. Methodologically, single-chatbot design using mixed methods was the most common design format, and most studies were conducted for more than one month in laboratory or classroom settings. Conventional mobile devices, such as smartphones, tablet PCs, and smart speakers without a screen, were the most frequently adopted device types. The chatbots' most common role was as conversational partner. A detailed discussion of these results and their implications for future research on speech-recognition chatbots, particularly regarding the use of LLM-powered chatbots, is provided.
145	AI versus human-generated multiple-choice questions for medical education: a cohort study in a high-stakes examination Artificial intelligence; Educational measurement; Multiple choice questions; Medical education; Cognitive processes Background The creation of high-quality multiple-choice questions (MCQs) is essential for medical education assessments but is resource-intensive and time-consuming when done by human experts. Large language models (LLMs) like ChatGPT-4o offer a promising alternative, but their efficacy remains unclear, particularly in high-stakes exams. Objective This study aimed to evaluate the quality and psychometric properties of ChatGPT-4o-generated MCQs compared to human-created MCQs in a high-stakes medical licensing exam. Methods A prospective cohort study was conducted among medical doctors preparing for the Primary Examination on Emergency Medicine (PEEM) organised by the Hong Kong College of Emergency Medicine in August 2024. Participants attempted two sets of 100 MCQs-one AI-generated and one human-generated. Expert reviewers assessed MCQs for factual correctness, relevance, difficulty, alignment with Bloom's taxonomy (remember, understand, apply and analyse), and item writing flaws. Psychometric analyses were performed, including difficulty and discrimination indices and KR-20 reliability. Candidate performance and time efficiency were also evaluated. Results Among 24 participants, AI-generated MCQs were easier (mean difficulty index = 0.78 +/- 0.22 vs. 0.69 +/- 0.23, p < 0.01) but showed similar discrimination indices to human MCQs (mean = 0.22 +/- 0.23 vs. 0.26 +/- 0.26). Agreement was moderate (ICC = 0.62, p = 0.01, 95% CI: 0.12-0.84). Expert reviews identified more factual inaccuracies (6% vs. 4%), irrelevance (6% vs. 0%), and inappropriate difficulty levels (14% vs. 1%) in AI MCQs. AI questions primarily tested lower-order cognitive skills, while human MCQs better assessed higher-order skills (chi(2) = 14.27, p = 0.003). AI significantly reduced time spent on question generation (24.5 vs. 96 person-hours). Conclusion ChatGPT-4o demonstrates the potential for efficiently generating MCQs but lacks the depth needed for complex assessments. Human review remains essential to ensure quality. Combining AI efficiency with expert oversight could optimise question creation for high-stakes exams, offering a scalable model for medical education that balances time efficiency and content quality.
146	Relationship between teachers' digital competence and attitudes towards artificial intelligence in education Teachers' digital competence; Artificial intelligence; Teacher attitudes; Higher education; Primary education; Secondary education With the recent integration of artificial intelligence (AI) in the educational field, understanding the variables that are related to teacher attitudes towards AI can be crucial for understanding their perspectives in the classroom. That is why the present study aimed to investigate whether Teacher Digital Competence is related to Teacher Attitudes towards AI, and if so, whether this relationship is moderated by the teacher's educational stage, age, sex, years of experience, and field of knowledge. A total of 445 Spanish teachers from primary, secondary, and higher education participated in this study, responding to the Teacher Digital Competence Scale and the Teacher Attitudes towards AI Scale. The results revealed that, regardless of educational stage, sex, age, years of experience or field of knowledge, higher teacher digital competence is associated with a more positive teacher attitude towards AI. Moreover, high levels of willingness to use AI but low levels of personal experience with AI were found. Based on these results, it may be interesting to implement future interventions based on AI to enhance key dimensions of teacher digital competence, such as Information Management, Content Creation, and Problem-Solving. This could improve Teacher Digital Competence and subsequently enhance teachers' perception of using artificial intelligence in the educational context.
147	Mapping the use of artificial intelligence in medical education: a scoping review Artificial intelligence (AI); Medical education; Curriculum development; Ethical training; Undergraduate medical education (UME); Experiential learning IntroductionThe integration of artificial intelligence (AI) in healthcare has transformed clinical practices and medical education, with technologies like diagnostic algorithms and clinical decision support increasingly incorporated into curricula. However, there is still a gap in preparing future physicians to use these technologies effectively and ethically.ObjectiveThis scoping review maps the integration of artificial intelligence (AI) in undergraduate medical education (UME), focusing on curriculum development, student competency enhancement, and institutional barriers to AI adoption.Materials and methodsA comprehensive search in PubMed, Scopus, and BIREME included articles from 2019 onwards, limited to English and Spanish publications on AI in UME. Exclusions applied to studies focused on postgraduate education or non-medical fields. Data were analyzed using thematic analysis to identify patterns in AI curriculum development and implementation.ResultsA total of 34 studies were reviewed, representing diverse regions and methodologies, including cross-sectional studies, narrative reviews, and intervention studies. Findings revealed a lack of standardized AI curriculum frameworks and notable global discrepancies. Key elements such as ethical training, collaborative learning, and digital competence were identified as essential, with an emphasis on transversal skills that support AI as a tool rather than a standalone subject.ConclusionsThis review underscores the need for a standardized, adaptable AI curriculum in UME that prioritizes transversal skills, including digital competence and ethical awareness, to support AI's gradual integration. Embedding AI as a practical tool within interdisciplinary, patient-centered frameworks fosters a balanced approach to technology in healthcare. Further regional research is recommended to develop frameworks that align with cultural and educational needs, ensuring AI integration in UME promotes both technical and ethical competencies.
148	Mapping the global evidence around the use of ChatGPT in higher education: A systematic scoping review ChatGPT; Artificial intelligence; Higher education; Uses & impact; Teaching assistant; Personalised tutor; Co-researcher; Systematic scoping review The recent development of AI Chatbot - specifically ChatGPT - has gained dramatic attention from users as evident by ongoing discussion among the education fraternity. We argue that prior to making any conclusion, it is important to understand how ChatGPT is being used in higher education across the globe. This paper makes a significant contribution by systematically reviewing the global literature on the use of ChatGPT in higher education using PRISMA guidelines. We included 69 studies in the analysis based on inclusion and exclusion criteria. We presented the scope of published literature in three aspects: (i) contextual, (ii) methodological, and (iii) disciplinary. Most of the studies have been carried out in HICs (n = 53; 77%) representing the field of higher education (n = 37; 54%) without specifying the discipline, while only a few studies were based on empirical data (n = 19; 27%). The findings based on included studies reveal that ChatGPT serves as a convenient tool to assist teachers, students, and researchers in various tasks. While the specific uses vary, the underlying motivation remains consistent: seeking personal benefits and reducing academic burdens. Teachers use it for personal and professional learning and resource generation while students use it as personal tutors for various learning purposes. However, concerns related to accuracy, reliability, academic integrity, and potential negative effects on cognitive and social development were consistently highlighted in many studies. To address these concerns, we have proposed a comprehensive framework for universities along with directions for future research in higher education as an optimal response.
149	Development and validation of an artificial intelligence anxiety scale: an initial application in predicting motivated learning behavior Artificial intelligence; assessment; artificial intelligence anxiety; motivated learning behavior; scale development While increasing productivity and economic growth, the application of artificial intelligence (AI) may ultimately require millions of people around the world to change careers or improve their skills. These disruptive effects contribute to the general public anxiety toward AI development. Despite the rising levels of AI anxiety (AIA) in recent decades, no AI anxiety scale (AIAS) has been developed. Given the limited utility of existing self-report instruments in measuring AIA, the aim of this paper is to develop a standardized tool to measure this phenomenon. Specifically, this paper introduces and defines the construct of AIA, develops a generic AIAS, and discusses the theoretical and practical applications of the instrument. The procedures used to conceptualize the survey, create the measurement items, collect data, and validate the multi-item scale are described. By analyzing data obtained from a sample of 301 respondents, the reliability, criterion-related validity, content validity, discriminant validity, convergent validity, and nomological validity of the constructs and relationships are fully examined. Overall, this empirically validated instrument advances scholarly knowledge regarding AIA and its associated behaviors.
150	Twelve tips for addressing ethical concerns in the implementation of artificial intelligence in medical education Artificial intelligence; ethics; ethical concerns; medical education; medical educators Artificial Intelligence (AI) holds immense potential for revolutionizing medical education and healthcare. Despite its proven benefits, the full integration of AI faces hurdles, with ethical concerns standing out as a key obstacle. Thus, educators should be equipped to address the ethical issues that arise and ensure the seamless integration and sustainability of AI-based interventions. This article presents twelve essential tips for addressing the major ethical concerns in the use of AI in medical education. These include emphasizing transparency, addressing bias, validating content, prioritizing data protection, obtaining informed consent, fostering collaboration, training educators, empowering students, regularly monitoring, establishing accountability, adhering to standard guidelines, and forming an ethics committee to address the issues that arise in the implementation of AI. By adhering to these tips, medical educators and other stakeholders can foster a responsible and ethical integration of AI in medical education, ensuring its long-term success and positive impact. In the ever-evolving landscape of medical education, the integration of Artificial Intelligence (AI) stands out as a revolutionary innovation with the potential to reshape learning methodologies and advance healthcare practices.However, this transformative journey is impeded by ethical concerns that demand careful attention.This reflects a delicate balance that educators must strike between embracing innovation and ensuring responsible implementation.The twelve provided tips serve as a practical guide, highlighting the complexities involved in incorporating AI ethically.By following these guidelines, educators contribute to shaping a healthcare workforce that is not only technologically proficient but also ethically grounded.
151	Exploring the Effects of Artificial Intelligence Application on EFL Students' Academic Engagement and Emotional Experiences: A Mixed-Methods Study academic engagement; artificial intelligence; EFL students; emotions As artificial intelligence (AI) gains prominence, its integration into second language (L2) /foreign language (FL) instruction has become a significant trend. Despite the considerable promise of AI for L2/FL learning, more research is still needed on its effects on student academic engagement in literature classes and the corresponding emotional experiences. This study, therefore, aimed to examine the effects of AI use on English as a foreign language (EFL) learners' academic engagement, and the emotional experience was also qualitatively explored. Students were allocated to the experimental group (N = 48), who received instruction integrated with AI, and the control group (N = 48), who received traditional instruction without AI assistance. Quantitative data were collected using an FL engagement scale, supplemented by individual semi-structured interviews in the qualitative phase. The results indicated that integrating AI into EFL instruction has a positive effect on students' cognitive, emotional and social engagement. Moreover, the learners' emotional experiences were found to be abundant and dynamic, exerting influence on their academic engagement. This study provides valuable insights for language educators and researchers regarding integrating AI into EFL instruction.
152	Integration of artificial intelligence performance prediction and learning analytics to improve student learning in online engineering course Artificial intelligence in education (AIEd); Academic performance prediction; AI prediction models; Collaborative learning; Online higher education As a cutting-edge field of artificial intelligence in education (AIEd) that depends on advanced computing technologies, AI performance prediction model is widely used to identify at-risk students that tend to fail, establish student-centered learning pathways, and optimize instructional design and development. A majority of the existing AI prediction models focus on the development and optimization of the accuracy of AI algorithms rather than applying AI models to provide student with in-time and continuous feedback and improve the students' learning quality. To fill this gap, this research integrated an AI performance prediction model with learning analytics approaches with a goal to improve student learning effects in a collaborative learning context. Quasi-experimental research was conducted in an online engineering course to examine the differences of students' collaborative learning effect with and without the support of the integrated approach. Results showed that the integrated approach increased student engagement, improved collaborative learning performances, and strengthen student satisfactions about learning. This research made contributions to proposing an integrated approach of AI models and learning analytics (LA) feedback and providing paradigmatic implications for future development of AI-driven learning analytics.
153	Two Decades of Artificial Intelligence in Education: Contributors, Collaborations, Research Topics, Challenges, and Future Directions Artificial intelligence in education; Structural topic modeling; Bibliometric analysis; Research topics; Research evolution With the increasing use of Artificial Intelligence (AI) technologies in education, the number of published studies in the field has increased. However, no large-scale reviews have been conducted to comprehensively investigate the various aspects of this field. Based on 4,519 publications from 2000 to 2019, we attempt to fill this gap and identify trends and topics related to AI applications in education (AIEd) using topic-based bibliometrics. Results of the review reveal an increasing interest in using AI for educational purposes from the academic community The main research topics include intelligent tutoring systems for special education; natural language processing for language education; educational robots for AI education; educational data mining for performance prediction; discourse analysis in computer-supported collaborative learning; neural networks for teaching evaluation; affective computing for learner emotion detection; and recommender systems for personalized learning. We also discuss the challenges and future directions of AIEd.
154	From Excitement to Anxiety: Exploring English as a Foreign Language Learners' Emotional Experiences in the Artificial Intelligence-Powered Classrooms artificial intelligence; EFL students; emotion regulation strategies; emotions The use of artificial intelligence (AI) technologies in second/foreign language education has recently gained a bulk of attention. However, the emotional experiences of English as a foreign language (EFL) learners in AI-mediated classes have been ignored. To fill this gap, the present qualitative study examined 34 Chinese EFL students' perceptions of AI-induced emotions and regulation strategies. A semi-structured interview and a narrative frame were used to collect the data. The gathered data were thematically analysed through the latest version of MAXQDA software (v. 2023). The findings revealed that Chinese EFL students had mostly experienced positive emotions of 'motivation', 'excitement', 'engagement' and 'confidence'. On the negative side, they reported experiencing 'frustration', 'anxiety' and 'stress' more frequently in their classes. Furthermore, the study indicated that the participants had used six strategies, namely 'seeking help from others', 'shifting attention', 'cognitive change', 'persistent practice', 'staying positive' and 'suppression' to regulate their AI-induced emotions. The findings are discussed and implications are provided for EFL students and educators to understand the emotional aspect of AI injection into L2 education.
155	Modeling English teachers' behavioral intention to use artificial intelligence in middle schools English teacher; Foreign language learning; Behavioral intention; Artificial intelligence; Middle school Artificial intelligence (AI) provides new opportunities for K-12 English as foreign language (EFL) teachers to improve their teaching. To address the emerging trend of integrating AI into teaching, this study investigated EFL teachers' perceptions, knowledge, and behavioral intention to use AI to support teaching and learning of English in middle schools. This study combined relevant aspects of the Unified Theory of Acceptance and Use of Technology (UTAUT) and Technological Pedagogical and Content Knowledge (TPACK) as the theoretical basis. A survey was conducted in an AI education demonstration district in China. This survey adopted a 5-point Likert scale which was developed from previous research and the interview records of EFL teachers. A total of 470 valid responses were collected. The reliability and validity of the scale were satisfied with eight constructs: Performance Expectancy (PE), Effort Expectancy (EE), Social Influence (SI), Facilitating Conditions (FC), AI language technological knowledge (AIL-TK), AI technological pedagogical knowledge (AI-TPK), AI-TPACK, and Behavioral Intention (BI). The results showed that the EFL teachers were positive with regard to the measured factors. PE, SI, AIL-TK, and AI-TPACK had significant positive predictive power on BI; and EE, FC, AI-TPK had indirect effects on BI. The complex interrelations were mapped out to provide educators and policymakers with a theoretically grounded scheme to foster teachers' BI to use AI in teaching.
156	The Effects of Using AI Tools on Critical Thinking in English Literature Classes Among EFL Learners: An Intervention Study AI tools; critical thinking; educational technology; EFL learners; English literature classes; intervention study Artificial intelligence (AI)-driven learning has become an irreversible trend in foreign language education. Scholars are increasingly focusing on this field, yet few have examined its impact within English literature classes. To fill this gap, we designed an 8-week intervention study with mixed methods and recruited 90 students, with 42 in the experimental group and 48 in the control group, matched for average age, English proficiency and gender ratio. Critical thinking levels were measured before and after the intervention using a standardised assessment tool. In the experimental group, students used AI tools (ChatGPT-3.5, Bodoudou, SummarizBot, etc.) to generate and answer text-related questions, and participate in interactive quizzes and AI-assisted debates during classes, while the control group followed traditional methods without AI tools. The findings revealed a statistically significant improvement in the critical thinking skills of the experimental group compared to the control group, as measured by pre and postintervention assessments (p < 0.05). This suggests that AI tools can effectively enhance critical thinking abilities in English literature classes. This study not only contributes to the emerging discourse on AI in education but also offers practical implications for integrating AI technologies to support and enrich the learning experiences of EFL students in literature classes. The findings have the potential to guide educators and policymakers in designing AI-driven educational strategies that are culturally responsive and pedagogically effective.
157	Effectiveness of AI-assisted game-based learning on science learning outcomes, intrinsic motivation, cognitive load, and learning behavior Games; Artificial intelligence; Secondary education; Intrinsic motivation; learning behavior This study aimed to investigate the effectiveness of using AI-assisted game-based learning on science learning outcomes, intrinsic motivation, cognitive load, and learning behavior. A total of 202 seventh graders were recruited and randomly assigned to the following three groups: (1) Game only (N = 70), (2) GameGPT (N = 63), and (3) GameGPT_examples (N = 69). The experimental groups received game-based learning with the assistance of ChatGPT with or without examples, while the control group received only game-based learning. The results showed that students in the GameGPT_examples group significantly outperformed those in the Game only group. Students in the GameGPT and GameGPT_examples groups reported significantly higher perceived competence than those in the Game only group. Furthermore, students in the Game only group reported a greater mental burden than those in the GameGPT_examples and GameGPT groups. The findings from learning behavioral analytics and interviews suggest that AI-assisted game-based learning can enhance students' intrinsic motivation, reduce cognitive load, and promote effective learning behavior in science learning. This study has important implications for the design and implementation of AI in game-based learning environments that aim to improve students' learning outcomes and motivation.
158	Artificial intelligence self-efficacy: Scale development and validation Artificial intelligence; Scale development; Artificial intelligence self-efficacy; Motivated learning behavior; Adoption With the development of artificial intelligence (AI) applications, it has become critical for scholars, educators and practitioners to understand an individual's perceived self-efficacy regarding the use of AI technologies/products. Understanding users' subsequent behaviors toward the advancement of AI technology is also critical. Despite the growing focus on AI, a suitable scale for measuring AI self-efficacy (AISE) has yet to be developed. Current scales for measuring AISE (i.e., technology self-efficacy scales) are considered inapplicable because they neglect to evaluate perceptions of specific AI characteristics (e.g., AI-based configuration or anthropomorphic design). Given the limitations of existing self-evaluation and diagnostic instruments, the aim of this research is to investigate the construct of AISE, and develop and validate an AISE scale (AISES) for measuring an individual's perceived self-efficacy in regard to the use of AI technologies/products, in accordance with established exploratory and confirmatory scale development procedures. Specifically, a literature review is employed to generate initial items. An exploratory factor analysis is then performed for item purification purposes. At this stage, potential elements of AISE are extracted. Subsequently, factor extraction and confirmatory factor analysis are used to verify the construct structure of AISE. An analysis of 314 responses indicates that the AISE construct contains four factors: assistance, anthropomorphic interaction, comfort with AI, and technological skills. The scale is comprised of 22 items, and is found to have good fit, reliability, convergent validity, discriminant validity, content validity, and criterion-related validity. Moreover, nomological validity is built by the positive correlation between the AISE construct and motivated learning behaviors. This paper is the pioneer in developing and validating a scale to measure AISE. The findings extend existing knowledge of AISE and can help scholars further develop AISE theories. Our findings will also help educators and practitioners assess individuals' AISE and explore related behaviors.
159	Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach AI education; AI literacy; AI literacy questionnaire (AILQ); artificial intelligence; questionnaire validation Artificial intelligence (AI) literacy is at the top of the agenda for education today in developing learners' AI knowledge, skills, attitudes and values in the 21st century. However, there are few validated research instruments for educators to examine how secondary students develop and perceive their learning outcomes. After reviewing the literature on AI literacy questionnaires, we categorized the identified competencies in four dimensions: (1) affective learning (intrinsic motivation and self-efficacy/confidence), (2) behavioural learning (behavioural commitment and collaboration), (3) cognitive learning (know and understand; apply, evaluate and create) and (4) ethical learning. Then, a 32-item self-reported questionnaire on AI literacy (AILQ) was developed and validated to measure students' literacy development in the four dimensions. The design and validation of AILQ were examined through theoretical review, expert judgement, interview, pilot study and first- and second-order confirmatory factor analysis. This article reports the findings of a pilot study using a preliminary version of the AILQ among 363 secondary school students in Hong Kong to analyse the psychometric properties of the instrument. Results indicated a four-factor structure of the AILQ and revealed good reliability and validity. The AILQ is recommended as a reliable measurement scale for assessing how secondary students foster their AI literacy and inform better instructional design based on the proposed affective, behavioural, cognitive and ethical (ABCE) learning framework.
160	Human and artificial intelligence collaboration for socially shared regulation in learning  Artificial intelligence (AI) has generated a plethora of new opportunities, potential and challenges for understanding and supporting learning. In this paper, we position human and AI collaboration for socially shared regulation (SSRL) in learning. Particularly, this paper reflects on the intersection of human and AI collaboration in SSRL research, which presents an exciting prospect for advancing our understanding and support of learning regulation. Our aim is to operationalize this human-AI collaboration by introducing a novel trigger concept and a hybrid human-AI shared regulation in learning (HASRL) model. Through empirical examples that present AI affordances for SSRL research, we demonstrate how humans and AI can synergistically work together to improve learning regulation. We argue that the integration of human and AI strengths via hybrid intelligence is critical to unlocking a new era in learning sciences research. Our proposed frameworks present an opportunity for empirical evidence and innovative designs that articulate the potential for human-AI collaboration in facilitating effective SSRL in teaching and learning.
161	A systematic review of conversational AI in language education: focusing on the collaboration with human teachers Conversational AI; language learning; intelligence amplification; systematic review Despite the increasing use of conversational artificial intelligence (AI) in language learning, few studies explored how to develop collaborative partnership between AIs and humans. This systematic review examines empirical evidence of human-computer collaboration from 24 studies conducted in an AI-integrated language learning environment and published between 2015 and 2021. The roles of conversational AIs and teachers in each language learning phase with challenges of and suggestions for conversational AI-integrated language learning were identified. Although limited evidence for collaboration between conversational AIs and human teachers was found, future language education should integrate conversational AIs to promote intelligence amplification and decrease human teachers' workload through classroom orchestration. The study concludes with guidelines and recommendations for teachers and AI researchers.
162	Exploring the Impact of Artificial Intelligence in Teaching and Learning of Science: A Systematic Review of Empirical Research AI; Artificial intelligence; Science education; Engineering students; STEM learning; Science learning The use of Artificial Intelligence (AI) in education is transforming various dimensions of the education system, such as instructional practices, assessment strategies, and administrative processes. It also plays an active role in the progression of science education. This systematic review attempts to render an inherent understanding of the evidence-based interaction between AI and science education. Specifically, this study offers a consolidated analysis of AI's impact on students' learning outcomes, contexts of its adoption, students' and teachers' perceptions about its use, and the challenges of its use within science education. The present study followed the PRISMA guidelines to review empirical papers published from 2014 to 2023. In total, 74 records met the eligibility for this systematic study. Previous research provides evidence of AI integration into a variety of fields in physical and natural sciences in many countries across the globe. The results revealed that AI-powered tools are integrated into science education to achieve various pedagogical benefits, including enhancing the learning environment, creating quizzes, assessing students' work, and predicting their academic performance. The findings from this paper have implications for teachers, educational administrators, and policymakers.
163	A systematic review of AI literacy scales  With the opportunities and challenges stemming from the artificial intelligence developments and its integration into society, AI literacy becomes a key concern. Utilizing quality AI literacy instruments is crucial for understanding and promoting AI literacy development. This systematic review assessed the quality of AI literacy scales using the COSMIN tool aiming to aid researchers in choosing instruments for AI literacy assessment. This review identified 22 studies validating 16 scales targeting various populations including general population, higher education students, secondary education students, and teachers. Overall, the scales demonstrated good structural validity and internal consistency. On the other hand, only a few have been tested for content validity, reliability, construct validity, and responsiveness. None of the scales have been tested for cross-cultural validity and measurement error. Most studies did not report any interpretability indicators and almost none had raw data available. There are 3 performance-based scale available, compared to 13 self-report scales.
164	Exploring Iranian english as a foreign language teachers' acceptance of ChatGPT in english language teaching: Extending the technology acceptance model ChatGPT; Artificial intelligence; English Language Teaching; Technology acceptance model; Iranian EFL teachers This study explores the factors influencing the acceptance of ChatGPT, an artificial intelligence chatbot, for English Language Teaching (ELT) among Iranian EFL (English as a Foreign Language) teachers. The research framework is grounded in the Technology Acceptance Model (TAM), augmented with external factors pertaining to system characteristics and individual factors. A survey questionnaire was administered to 234 Iranian EFL teachers to collect data for analysis. Quantitative methods were employed to analyze the gathered data. The findings substantiated 13 of the 14 hypothesized relationships, unveiling significant associations among multiple variables. These relationships encompassed perceived ease of use (PEOU) and perceived usefulness (PU), PEOU and behavioral intention to use (BI), PU and BI, perceived system quality (PSQ) and PU, PSQ and PEOU, online course design (OCD) and PU, PSQ and PEOU, perceived enjoyment (PE) and PEOU, PE and PU, PE and BI, perceived self-efficacy (PSE) and PU, PSE and PEOU, and subjective norm (SN) and PU, SN and PEOU. However, no statistically significant correlation emerged between OCD and PEOU. The implications of these findings are discussed, and suggestions for future research are presented.
165	Learning with ChatGPT 3.5 as a more knowledgeable other: an autoethnographic study ChatGPT (ChatGPT 3; 5); MKO (more knowledgeable other); Autoethnography; Higher education; Sociocultural theory; Human-computer interaction ChatGPT, an artificial intelligence language model introduced in November 2022, is potentially applicable in many contexts, including higher education. Although academics are already using it to draft papers or develop search queries for systematic reviews, its use as a tool aiding the learning process has not been examined. To address this research gap, I conducted an autoethnographic study examining my experience using ChatGPT as a more knowledgeable other that scaffolded my learning about a particular topic-the technical aspects of how ChatGPT works. Overall, ChatGPT provided me with enough content to form a general idea of its technical aspects, and I experienced its feedback as motivating and relevant. However, the answers were somewhat superficial, the text it generated was not always consistent or logical and sometimes contradictory. The instantaneous replies to my questions contributed to an experience of a 'flow'. Being 'in the zone' also meant I overestimated my knowledge and understanding, as I could not detect the contradictory responses it provided 'on the spot'. I conclude that caution is advised when ChatGPT is used as a learning aid, as we learn more about its capabilities and limitations and how humans tend to perceive and interact with these technologies.
166	Artificial intelligence in medical education - perception among medical students Artificial intelligence; Medical curriculum; Healthcare; Medical ethics; Medical education Background As Artificial Intelligence (AI) becomes pervasive in healthcare, including applications like robotic surgery and image analysis, the World Medical Association emphasises integrating AI education into medical curricula. This study evaluates medical students' perceptions of 'AI in medicine', their preferences for AI training in education, and their grasp of AI's ethical implications in healthcare. Materials & methods A cross-sectional study was conducted among 325 medical students in Kerala using a pre-validated, semi structured questionnaire. The survey collected demographic data, any past educational experience about AI, participants' self-evaluation of their knowledge and evaluated self-perceived understanding of applications of AI in medicine. Participants responded to twelve Likert-scale questions targeting perceptions and ethical aspects and their opinions on suggested topics on AI to be included in their curriculum. Results & discussion AI was viewed as an assistive technology for reducing medical errors by 57.2% students and 54.2% believed AI could enhance medical decision accuracy. About 49% agreed that AI could potentially improve accessibility to healthcare. Concerns about AI replacing physicians were reported by 37.6% and 69.2% feared a reduction in the humanistic aspect of medicine. Students were worried about challenges to trust (52.9%), patient-physician relationships (54.5%) and breach of professional confidentiality (53.5%). Only 3.7% felttotally competent in informing patients about features and risks associated with AI applications. Strong demand for structured AI training was expressed, particularly on reducing medical errors (76.9%) and ethical issues (79.4%). Conclusion This study highlights medical students' demand for structured AI training in undergraduate curricula, emphasising its importance in addressing evolving healthcare needs and ethical considerations. Despite widespread ethical concerns, the majority perceive AI as an assistive technology in healthcare. These findings provide valuable insights for curriculum development and defining learning outcomes in AI education for medical students.
167	Proposing a conceptual model for the adoption of artificial intelligence by teachers in STEM education Artificial intelligence; STEM education; UTAUT 2; GETAMEL; teacher adoption This study explores the adoption of Artificial Intelligence (AI) in STEM education by proposing a new conceptual model that integrates UTAUT 2 and GETAMEL frameworks. Data collected from 582 science teachers in Turkey were analyzed using Structural Equation Modeling. The results demonstrated that the proposed model outperformed the original GETAMEL and UTAUT 2 models in predicting teachers' intentions to adopt AI in STEM education. Key factors influencing adoption included subjective norm, experience, perceived enjoyment, anxiety, and self-efficacy, which significantly impacted perceived usefulness and perceived ease of use. These factors, in turn, positively influenced attitudes and intentions toward using AI-powered tools. Additionally, price value, facilitating conditions, and habit were identified as significant predictors of intention. The mediating roles of perceived ease of use, perceived usefulness, and attitude were confirmed in explaining adoption intentions. This model offers valuable insights for promoting effective AI integration in STEM education, aiding policymakers, educators, and researchers in understanding the factors driving technology adoption. It highlights actionable strategies for enhancing the acceptance and utilization of AI-powered tools in educational settings.
168	AI-Mediated Communication in EFL Classrooms: The Role of Technical and Pedagogical Stimuli and the Mediating Effects of AI Literacy and Enjoyment AI literacy; AI-enhanced EFL learning; foreign language enjoyment; Stimulus-Organism-Response theory; teacher support; technical support; willingness to communicate This study leverages the Stimulus-Organism-Response (S-O-R) framework to investigate the effects of teacher and technical support (TCHS) on learners' willingness to communicate (WTC) in artificial intelligence (AI)-enhanced English as a foreign language (EFL) contexts, considering the mediating effects of learners' artificial intelligence literacy (AIL) and foreign language enjoyment (FLE). A quantitative survey encompassing 637 non-English major university students across four institutions was conducted. Structural equation modelling (SEM) results demonstrated that teacher support (TEAS) exerts a direct influence on learners' WTC, whereas TCHS does not. The study also revealed that AIL and FLE significantly mediate the relationship between teacher and TCHS and learners' WTC. The findings underscore the pivotal role of cognitive and affective factors, emphasising the substantial impact of TEAS and the value of nurturing learners' AIL and enjoyment of foreign languages. This research offers strategic implications for educational practitioners and policymakers, advocating for the integration of innovative educational technologies and fostering sustainable growth in artificial intelligence in education.
169	Trends, Research Issues and Applications of Artificial Intelligence in Language Education Artificial Intelligence; Language Education; Bibliometric Analysis; Automated Writing Evaluation; Intelligent Tutoring System Artificial Intelligence (AI) plays an increasingly important role in language education; however, the trends, research issues, and applications of AI in language learning remain largely under-investigated. Accordingly, the present paper, using bibliometric analysis, investigates these issues via a review of 516 papers published between 2000 and 2019, focusing on how AI was integrated into language education. Findings revealed that the frequency of studies on AI-enhanced language education increased over the period. The USA and Arizona State University were the most active country and institution, respectively. The 10 most popular topics were: (1) automated writing evaluation; (2) intelligent tutoring systems (ITS) for reading and writing; (3) automated error detection; (4) computer-mediated communication; (5) personalized systems for language learning; (6) natural language and vocabulary learning; (7) web resources and web-based systems for language learning; (8) ITS for writing in English for specific purposes; (9) intelligent tutoring and assessment systems for pronunciation and speech training; and (10) affective states and emotions. The results also indicated that AI was frequently used to assist students in learning writing, reading, vocabulary, grammar, speaking, and listening. Natural language processing, automated speech recognition, and learner profiling were commonly applied to develop automated writing evaluation, personalized learning, and intelligent tutoring systems.
170	Using artificial intelligence to foster students' writing feedback literacy, engagement, and outcome: a case of Wordtune application Artificial intelligence; writing feedback literacy; writing engagement; Wordtune App; writing outcome Technology and artificial intelligence (AI) advancements are increasingly impacting second language (L2) learning, particularly in writing skills development. Motivated students seeking writing feedback can benefit from AI implementation, with writing feedback literacy being crucial for effective use. Engaged students with specific writing goals benefit from ongoing practice and learning to attain high-quality outcomes, whether from formal or informal settings such as AI application. AI's integration into L2 education underscores the need to comprehend its role in improving L2 writing engagement, writing feedback literacy, and writing outcome. A mixed-method study was conducted, which involved 46 students at the upper-intermediate level. The student cohort was divided into two groups for the purpose of the study. One group was designated the control group, while the other was the experimental group, each comprising 23 students. By using Wordtune, an AI-based application, the experimental group was able to significantly improve their writing outcomes, engagement, and feedback literacy when compared to the control group. Furthermore, the Wordtune application received positive feedback from students interviewed about its ability to improve their writing outcomes, engagement, and feedback literacy. These findings will contribute to our understanding of AI in L2 learning and inform instructional considerations for Wordtune's application.
171	Teachers' AI digital competencies and twenty-first century skills in the post-pandemic world AI education; AI literacy; Digital competency; Teacher; Twenty-first century skills The pandemic has catalyzed a significant shift to online/blended teaching and learning where teachers apply emerging technologies to enhance their students' learning outcomes. Artificial intelligence (AI) technology has gained its popularity in online learning environments during the pandemic to assist students' learning. However, many of these AI tools are new to teachers. They may not have rich technical knowledge to use AI educational applications to facilitate their teaching, not to mention developing students' AI digital capabilities. As such, there is a growing need for teachers to equip themselves with adequate digital competencies so as to use and teach AI in their teaching environments. There are few existing frameworks informing teachers of necessary AI competencies. This study first explores the opportunities and challenges of employing AI systems and how they can enhance teaching, learning and assessment. Then, aligning with generic digital competency frameworks, the DigCompEdu framework and P21's framework for twenty-first century learning were adapted and revised to accommodate AI technologies. Recommendations are proposed to support educators and researchers to promote AI education in their classrooms and academia.
172	Improving EFL learners' speaking skills and willingness to communicate via artificial intelligence-mediated interactions AI-Mediated interaction; Chatbots; Speaking skills; WTC; EFL learner It is widely acknowledged that technology, particularly artificial intelligence (AI), presents innovative opportunities for improving English language learning skills. However, little is known about the impact of AI-mediated activities on learners' speaking skills. This study, therefore, aimed to examine the impact of an artificial intelligence platform on English as a foreign language (EFL) learners' speaking skills, including speaking fluency and coherence, lexicon, grammatical range and accuracy, and pronunciation, and willingness to communicate (WTC). EFL learners' attitudes and perceptions towards AI-mediated speaking activities were also qualitatively explored. Thirty-three EFL learners were randomly assigned to an experimental group (AI group) and 32 EFL learners were placed in a control group (face-to-face group). The participants in the AI group engaged in AI-mediated interactive speaking activities using Andy English Chatbot, whilst the face-to-face group engaged in conventional peer-interaction speaking activities. Moreover, IELTS speaking skill tests and a WTC scale were applied to collect the quantitative data followed by an individual semi-structured interview in the qualitative phase. The results indicated that AImediated interactive speaking activities were more effective in improving EFL learners' speaking skills and WTC. Moreover, the learners had positive attitudes and perceptions towards the AImediated speaking instruction. The study provides valuable insights for language educators and researchers regarding technology-mediated instruction in language classrooms.
173	Supporting students' self-regulated learning in online learning using artificial intelligence applications Self-regulated learning; Artificial intelligence; Online learning; Student perception Self-regulated learning (SRL) is crucial for helping students attain high academic performance and achieve their learning objectives in the online learning context. However, learners often face challenges in properly applying SRL in online learning environments. Recent developments in artificial intelligence (AI) applications have shown promise in supporting learners' self-regulation in online learning by measuring and augmenting SRL, but research in this area is still in its early stages. The purpose of this study is to explore students' perceptions of the use of AI applications to support SRL and to identify the pedagogical and psychological aspects that they perceive as necessary for effective utilization of those AI applications. To explore this, a speed dating method using storyboards was employed as an exploratory design method. The study involved the development of 10 AI application storyboards to identify the phases and areas of SRL, and semi-structured interviews were conducted with 16 university students from various majors. The results indicated that learners perceived AI applications as useful for supporting metacognitive, cognitive, and behavioral regulation across different SRL areas, but not for regulating motivation. Next, regarding the use of AI applications to support SRL, learners requested consideration of three pedagogical and psychological aspects: learner identity, learner activeness, and learner position. The findings of this study offer practical implications for the design of AI applications in online learning, with the aim of supporting students' SRL.
174	Embracing the future of Artificial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education  The present discussion examines the transformative impact of Artificial Intelligence (AI) in educational settings, focusing on the necessity for AI literacy, prompt engineering proficiency, and enhanced critical thinking skills. The introduction of AI into education marks a significant departure from conventional teaching methods, offering personalized learning and support for diverse educational requirements, including students with special needs. However, this integration presents challenges, including the need for comprehensive educator training and curriculum adaptation to align with societal structures. AI literacy is identified as crucial, encompassing an understanding of AI technologies and their broader societal impacts. Prompt engineering is highlighted as a key skill for eliciting specific responses from AI systems, thereby enriching educational experiences and promoting critical thinking. There is detailed analysis of strategies for embedding these skills within educational curricula and pedagogical practices. This is discussed through a case-study based on a Swiss university and a narrative literature review, followed by practical suggestions of how to implement AI in the classroom.
175	Artificial intelligence in online higher education: A systematic review of empirical research from 2011 to 2020 Artificial Intelligence in Education; Systematic review; Online higher education; Online learning; Empirical research As online learning has been widely adopted in higher education in recent years, artificial intelligence (AI) has brought new ways for improving instruction and learning in online higher education. However, there is a lack of literature reviews that focuses on the functions, effects, and implications of applying AI in the online higher education context. In addition, what AI algorithms are commonly used and how they influence online higher education remain unclear. To fill these gaps, this systematic review provides an overview of empirical research on the applications of AI in online higher education. Specifically, this literature review examines the functions of AI in empirical researches, the algorithms used in empirical researches and the effects and implications generated by empirical research. According to the screening criteria, out of the 434 initially identified articles for the period between 2011 and 2020, 32 articles are included for the final synthesis. Results find that: (1) the functions of AI applications in online higher education include prediction of learning status, performance or satisfaction, resource recommendation, automatic assessment, and improvement of learning experience; (2) traditional AI technologies are commonly adopted while more advanced techniques (e.g., genetic algorithm, deep learning) are rarely used yet; and (3) effects generated by AI applications include a high quality of AI-enabled prediction with multiple input variables, a high quality of AI-enabled recommendations based on student characteristics, an improvement of students' academic performance, and an improvement of online engagement and participation. This systematic review proposes the following theoretical, technological, and practical implications: (1) the integration of educational and learning theories into AI-enabled online learning; (2) the adoption of advanced AI technologies to collect and analyze real-time process data; and (3) the implementation of more empirical research to test actual effects of AI applications in online higher education.
176	The future of grading programming assignments in education: The role of ChatGPT in automating the assessment and feedback process Improving classroom teaching; 21st century abilities; Adult learning; ChatGPT This research evaluated ChatGPT's potential as a tool for grading programming tasks, exploring its capability to understand and assess code quality. The study took place over a 15-week Python programming course with 67 students of the Cognitive Science program. Nine different assignments were assessed by both a teacher and the ChatGPT system, and the grading differences were recorded. The teacher's grades were higher than those generated by ChatGPT. Despite this, there was a strong positive correlation between these grades, suggesting consistency in grading. Nonetheless, the repeatability of ChatGPT's evaluations was excellent, and the observed differences in successive evaluations during grading iterations were negligible. The study concludes that ChatGPT could be a beneficial tool for grading programming assignments, providing several advantages such as time efficiency, quality assessment, unbiased grading, enforcement of coding standards, and the ability to generate feedback. However, the system has limitations such as cost, potential hallucinations, lack of absolute agreement reproducible results, and the occasional need for teacher intervention. The study suggests that the artificial intelligence model could complement or even substitute human grading but requires careful usage and potential verification by a human teacher.
177	On the relationship between EFL students' attitudes toward artificial intelligence, teachers' immediacy and teacher-student rapport, and their willingness to communicate Artificial intelligence; Teachers' immediacy; Teacher -student rapport; Willingness to communicate This research explores the intricate interplay among EFL students' attitudes towards artificial intelligence (AI), Teachers' Immediacy (TI), Teacher-Student Rapport (TSR), and their willingness to communicate (WTC). It delves into EFL students' perceptions of AI's role in enhancing critical thinking and investigates how teachers' immediacy and rapport influence students' WTC development. By integrating multiple domains including EFL education, AI technology, and interpersonal communication, the study offers a comprehensive understanding of how these factors intersect to shape students' willingness to communicate. The research fills a gap in existing literature by investigating EFL students' attitudes toward AI in language learning alongside variables like teacher immediacy and teacher-student rapport. It aims to unveil the nuanced relationships between students' attitudes toward AI, teacher immediacy, teacher-student rapport, and their resultant impact on students' WTC. To address these inquiries, the research employed four questionnaires, drawing on previous studies discussing EFL students' attitudes, contradictions, and perceptions in the context of AI integration. Insights from psychology, language acquisition, and educational technology converge to shed light on the complex dynamics shaping students' willingness to communicate in the AI era. The investigation contributes to the existing body of knowledge by providing a nuanced understanding of the factors influencing EFL students' WTC in the context of AI, with a specific emphasis on the significance of teachers' immediacy and rapport. The findings hold practical implications for educators and policymakers by highlighting the potential of AI technologies to enhance language learning outcomes and stressing the importance of fostering positive teacher-student relationships in promoting students' willingness to communicate effectively in the digital era.
178	Medical, dental, and nursing students' attitudes and knowledge towards artificial intelligence: a systematic review and meta-analysis Artificial intelligence; AI; Medical students; Dental students; Nursing students; Meta-analysis; Systematic review Background Nowadays, Artificial intelligence (AI) is one of the most popular topics that can be integrated into healthcare activities. Currently, AI is used in specialized fields such as radiology, pathology, and ophthalmology. Despite the advantages of AI, the fear of human labor being replaced by this technology makes some students reluctant to choose specific fields. This meta-analysis aims to investigate the knowledge and attitude of medical, dental, and nursing students and experts in this field about AI and its application. Method This study was designed based on PRISMA guidelines. PubMed, Scopus, and Google Scholar databases were searched with relevant keywords. After study selection according to inclusion criteria, data of knowledge and attitude were extracted for meta-analysis. Result Twenty-two studies included 8491 participants were included in this meta-analysis. The pooled analysis revealed a proportion of 0.44 (95%CI = [0.34, 0.54], P < 0.01, I-2 = 98.95%) for knowledge. Moreover, the proportion of attitude was 0.65 (95%CI = [0.55, 0.75], P < 0.01, I-2 = 99.47%). The studies did not show any publication bias with a symmetrical funnel plot. Conclusion Average levels of knowledge indicate the necessity of including relevant educational programs in the student's academic curriculum. The positive attitude of students promises the acceptance of AI technology. However, dealing with ethics education in AI and the aspects of human-AI cooperation are discussed. Future longitudinal studies could follow students to provide more data to guide how AI can be incorporated into education.
179	The impact of artificial intelligence on learner-instructor interaction in online learning Artificial intelligence; Boundary; Learner-instructor interaction; Online learning; Speed dating Artificial intelligence (AI) systems offer effective support for online learning and teaching, including personalizing learning for students, automating instructors' routine tasks, and powering adaptive assessments. However, while the opportunities for AI are promising, the impact of AI systems on the culture of, norms in, and expectations about interactions between students and instructors are still elusive. In online learning, learner-instructor interaction (inter alia, communication, support, and presence) has a profound impact on students' satisfaction and learning outcomes. Thus, identifying how students and instructors perceive the impact of AI systems on their interaction is important to identify any gaps, challenges, or barriers preventing AI systems from achieving their intended potential and risking the safety of these interactions. To address this need for forward-looking decisions, we used Speed Dating with storyboards to analyze the authentic voices of 12 students and 11 instructors on diverse use cases of possible AI systems in online learning. Findings show that participants envision adopting AI systems in online learning can enable personalized learner-instructor interaction at scale but at the risk of violating social boundaries. Although AI systems have been positively recognized for improving the quantity and quality of communication, for providing just-in-time, personalized support for large-scale settings, and for improving the feeling of connection, there were concerns about responsibility, agency, and surveillance issues. These findings have implications for the design of AI systems to ensure explainability, human-in-the-loop, and careful data collection and presentation. Overall, contributions of this study include the design of AI system storyboards which are technically feasible and positively support learner-instructor interaction, capturing students' and instructors' concerns of AI systems through Speed Dating, and suggesting practical implications for maximizing the positive impact of AI systems while minimizing the negative ones.
180	Artificial intelligence in education research during 2013-2023: A review based on bibliometric analysis Artificial intelligence (AI); AI in education (AIED); Machine learning (ML); Bibliometric analysis; Citespace software Research on Artificial Intelligence in Education (AIED) has rapidly progressed in recent years, and understanding the research trends and development is essential for technological innovations and implementations in education. Using a bibliometric analysis of 6843 publications from Web of Science and Scopus, we found that China, US, India, Spain, and Germany led the research profuctivity. AIED research is concerned more with higher education compared to K-12 education. Fifteen research trends emerged from the analysis, such as Educational Robots and Large Data Mining. Research has primarily leveraged technologies of machine learning, decision trees, deep learning, speech recognition, and computer vision in AIED. The major implementations of AI include educational robots, automated grading, recommender systems, learning analytics, and intelligent tutoring systems. Among the implementations, a majority of AIED research was conducted in seven major subject domains, chief among them being science, technology, engineering and mathematics (STEM) and language disciplines, with a focus on computer science and English education.
181	Digital proficiency: assessing knowledge, attitudes, and skills in digital transformation, health literacy, and artificial intelligence among university nursing students Digital transformation; Digital health literacy; Artificial intelligence; Knowledge; Attitude; Skills; University nursing students; Perception; Technology Background Implementing digital transformation and artificial intelligence (AI) in education and practice necessitates understanding nursing students' attitudes and behaviors as end-users toward current and future digital and AI applications. Purpose This study aimed to assess the perceived knowledge, attitudes, and skills of nursing students regarding digital transformation, as well as their digital health literacy (DHL) and attitudes toward AI. Furthermore, we investigated the potential correlations among these variables. Methods A descriptive correlational design was employed in a Saudi nursing college utilizing a convenience sample of 266 nursing students. A structured questionnaire consisting of six sections was used, covering personal information, knowledge, skills and attitudes toward digital transformation, digital skills, DHL, and attitudes toward AI. Descriptive statistics and Pearson correlation were employed for data analysis. Results Nursing students exhibited good knowledge of and positive attitudes toward digital transformation services. They possessed strong digital skills, and their DHL and positive attitude toward AI were commendable. Overall, the findings indicated significant positive correlations between knowledge of digital transformation services and all the digital variables measured (p = < 0.05). Senior students reported greater digital knowledge and a positive attitude toward AI. Conclusion The study recommends an innovative undergraduate curriculum that integrates opportunities for hands-on experience with digital healthcare technologies to enhance their digital literacy and skills.
182	Artificial intelligence and sustainable development Artificial intelligence; Robotics; Deep learning; Sustainable development; Sustainable development goals; Management education Artificial intelligence (AI) is rapidly opening up a new frontier in the fields of business, corporate practices, and governmental policy. The intelligence of machines and robotics with deep learning capabilities have created profound disrupting and enabling impacts on business, governments, and society. They are also influencing the larger trends in global sustainability. As the AI revolution transforms our world, it could herald a utopian future where humanity co-exists harmoniously with machines, or portend a dystopian world filled with conflict, poverty and suffering. More immediately, would AI accelerate our progress on the United Nations (UN) Sustainable Development Goals (SDGs) or bring us further down the path toward greater economic uncertainty, environmental collapse, and social upheaval? What are some of the implications for business leadership and the education of future business leaders? This article aims to address these questions by analyzing the impacts of AI in three case studies. It draws some preliminary inferences for management education and the business of leading corporations in the midst of rapid technological and social change. This study combines the perspectives of business strategy and public policy to analyze the impacts of AI on sustainable development with a specific focus on the advancement of the SDGs. It also draws some lessons on managerial learning and leadership development for global sustainability.
183	Trends in artificial intelligence-supported e-learning: a systematic review and co-citation network analysis (1998-2019) Artificial intelligence (AI); trend analysis; literature review; e-learning; co-citation network analysis Artificial intelligence (AI) has been widely explored across the world over the past decades. A particularly emerging topic is the application of AI in e-learning (AIeL) to improve the effectiveness of teaching and learning in precision education. This study aims to systematically review publication patterns for AIeL research with a focus on leading journals, countries, disciplines, and applications. In addition, a co-citation network analysis was conducted to explore the invisible relationships among the core papers of AIeL to reveal directions for future research. The analysis is based on a total of 86 core AIeL papers accompanied by 1149 citations in follow-up studies obtained from the Web of Science. It was found that a majority of AIeL studies focused on the development and applications of intelligent tutoring systems, followed by using AI to facilitate assessment and evaluation in e-learning contexts. For field researchers, the visualized network diagram serves as a map to explore the invisible relationships among the core AIeL research, providing a structural understanding of AI-supported research in e-learning contexts. A further investigation of the follow-up studies behind the highly co-cited links revealed the extended research directions from the AIeL mainstreams, such as adaptive learning-based evaluation environments. Implications are discussed.
184	Artificial intelligence teaching assistant adoption in university education: Key drivers through the ability, motivation and opportunity framework AI adoption intention; Attitude toward AI; Hedonic Motivation; Compatibility; FsQCA; ANN Artificial intelligence (AI) is reshaping university education by offering personalized teaching assistance tailored to each student's cognitive needs. Despite its global rise, AI's adoption in higher education in developing nations like Bangladesh is sparse. This study, gathering 363 responses from Bangladeshi universities, employed PLS-SEM, ANN, and fsQCA to identify key antecedents influencing students' intentions to use AI teaching aids. Findings highlight that interactivity, positive attitudes towards AI, hedonic motivation, perceived benefits, and compatibility significantly drive students' adoption intentions. In contrast, facilitating conditions, social identity, and self-efficacy showed no significant effect. This research provides a roadmap for integrating AI in teaching, emphasizing the need for stakeholder engagement to foster AI adoption in environments lacking personalized instruction. The multi-method analytical approach not only bolsters the study's predictive accuracy but also sets a precedent for future AI adoption research in education. The results are particularly relevant for developing countries, offering strategies to overcome educational constraints and improve learning outcomes.
185	ChatGPT Goes to Law School  How well can AI models write law school exams without human assistance? To find out, we used the widely publicized AI model ChatGPT to generate answers to the final exams for four classes at the University of Minnesota Law School. We then blindly graded these exams as part of our regular grading processes for each class. Over ninety-five multiple-choice questions and twelve essay questions, ChatGPT performed on average at the level of a C+ student, achieving a low but passing grade in all four courses. After detailing these results, we discuss their implications for legal education and lawyering. We also provide example prompts and advice on how ChatGPT can assist with legal writing.
186	Roles and research foci of artificial intelligence in language education: an integrated bibliographic analysis and systematic review approach Artificial intelligence; language learning; literature review; research trends This study explores the roles and research foci of AILEd (Artificial Intelligence in Language Education). The AILEd studies published from 1990 to 2020 in the WOS (Web of Science) database were included in the present study. Based on the well-recognized Technology-based Learning Review model, several dimensions, such as research methods, research sample groups, adopted technology, language skills, the role of AI in language education, and learning outcomes, were taken into account. The review results show that the main application domains of AILEd research were writing, reading, and vocabulary acquisition. In terms of applied technology and algorithms, AI in language education mostly adopted ITS (Intelligent Tutoring System) and NLP (Natural Language Processing). Besides, several commonly used AI algorithms were Statistical Learning, Data Mining, Machine Learning, and Natural Language Parsing. It was also found that some research focused on learning anxiety, willingness to communicate, knowledge acquisition, and classroom interaction. However, higher order thinking, complex problem solving, critical thinking ability, and collaborative learning tendencies were rarely considered in AILEd studies. Accordingly, several suggestions are provided to researchers, teachers, and decision makers for applying or studying AI applications in language education in the future.
187	Revolutionizing L2 speaking proficiency, willingness to communicate, and perceptions through artificial intelligence: a case of Speeko application Artificial intelligence; speaking proficiency; willingness to communicate; learners' perception; Speeko application The emergence of artificial intelligence (AI) and AI-based applications has become increasingly significant due to its transformative potential in various fields including language learning. These applications have the potential to enhance second language (L2) learners' speaking proficiency, willingness to communicate (WTC), and perception, leading to improved learning outcomes by providing personalized and interactive language practice. Using the Speeko application, this study examines the influence of AI on L2 speaking proficiency, WTC, and perceptions. The study employed a mixed-method approach in which 66 participants were randomly assigned to experimental or control groups. A Speeko application was used in the experimental group, while traditional teaching methods were used in the control group. As part of the study, data were collected through a speaking test and WTC questionnaire administered at pre-test and post-test intervals, as well as a semi-structured interview. According to the results, the experimental group had significantly higher L2 speaking proficiency, WTC, and better perceptions than the control group. Based on the findings, the incorporation of AI-based applications in language learning has the potential to enhance language learning outcomes.
188	Beyond ChatGPT: A conceptual framework and systematic review of speech-recognition chatbots for language learning Chatbot; Large language model; Automatic speech recognition; Affordance; Computer-assisted language learning The diversification of chatbot technology, such as the emergence of large language models and their incorporation into various technologies, necessitates a conceptual framework for a comprehensive understanding of different chatbot types and their possibilities for educational use. However, despite the fact that chatbots with different characteristics can provide learners with different interaction experiences, previous research has drawn on a loose conceptualization of chatbots, ignoring the common or unique design features of different chatbots and the educational affordances that are provided accordingly. In response to this concern, this review aims to further our understanding of different types of speech-recognition chatbots for language learning and the affordances provided by the chatbots. Based on an analysis of 37 empirical studies on uses of chatbots ranging from those with predefined dialogue systems to those utilizing artificial intelligence technology, this review proposes a conceptual framework that comprises three key components of a chatbot system: goal-orientation, embodiment, and multimodality. Using this framework as an analytical tool, eight chatbot types are identified and defined. Additionally, a total of 12 affordances are derived from the presence and absence of each component of the framework. Analysis of the studies through the framework also offers specific insights into how future chatbot research and development should be pursued in terms of goalorientation, embodiment, and multimodality. Finally, we discuss the potential of the framework as a relevant model for understanding chatbots in adjacent disciplines and types other than speech-recognition chatbots, including ChatGPT and other large language models.
189	Understanding K-12 teachers' technological pedagogical content knowledge readiness and attitudes toward artificial intelligence education AI education; K-12 teachers; TPACK; Attitudes; Teacher professional development Artificial intelligence (AI) education is increasingly being recognized as essential at the K-12 level. For better understanding teachers' preparedness for AI education and effectively developing relevant teacher training programs, teachers' technological pedagogical content knowledge (TPACK) readiness and attitudes toward AI teaching must be determined. However, limited research has been conducted on this topic. To address this research gap, we recruited 1,664 K-12 teachers to obtain a comprehensive view of teachers' readiness for and attitudes toward teaching AI in K-12 classrooms. These teachers differed in terms of their gender, teaching subject, teaching grade, teaching experience, and experience in teaching AI. The findings of this study indicated that a substantial gap exists in the AI-related content and technological knowledge of the recruited teachers. Moreover, intriguing relationships were found between the teachers' pedagogical knowledge, content knowledge, and attitudes toward teaching AI. The effects of demographic factors on the teachers' TPACK and attitudes were also examined. On the basis of the findings of this study, recommendations were formulated for developing effective teacher professional development programs in the field of AI education.
190	AI and the future of humanity: ChatGPT-4, philosophy and education - Critical responses  
191	To resist it or to embrace it? Examining ChatGPT's potential to support teacher feedback in EFL writing EFL writing; Automated writing evaluation; Teacher feedback; ChatGPT; Human-machine collaboration ChatGPT, the newest pre-trained large language model, has recently attracted unprecedented worldwide attention. Its exceptional performance in understanding human language and completing a variety of tasks in a conversational way has led to heated discussions about its implications for and use in education. This exploratory study represents one of the first attempts to examine the possible role of ChatGPT in facilitating the teaching and learning of writing English as a Foreign Language (EFL). We examined ChatGPT's potential to support EFL teachers' feedback on students' writing. To reach this goal, we first investigated ChatGPT's performance in generating feedback on EFL students' argumentative writing. Fifty English argumentative essays composed by Chinese undergraduate students were collected and used as feedback targets. ChatGPT and five Chinese EFL teachers offered feedback on the content, organisation, and language aspects of the essays. We compared ChatGPT- and teacher-generated feedback in terms of their amount and type. The results showed that ChatGPT produced a significantly larger amount of feedback than teachers and that compared with teacher feedback, which mainly focused on content-related and language-related issues, ChatGPT distributed its attention relatively equally among the three feedback foci (i.e., content, organisation, and language). Our results also indicated that ChatGPT and teachers displayed tendencies towards using different feedback types when evaluating different aspects of students' writing. Additionally, we examined EFL teachers' perceptions of using ChatGPT-generated feedback to support their own feedback. The five teachers reported both positive and negative perceptions of the features of ChatGPT feedback and the relation between ChatGPT and teacher feedback. To foster EFL students' writing skills, we suggest that teachers collaborate with ChatGPT in generating feedback on student writing.
192	Teacher support and student motivation to learn with Artificial Intelligence (AI) based chatbot AI in education; motivation; self-determination theory; teacher support; student expertise; chatbots As Artificial Intelligence (AI) advances technologically, it will inevitably bring many changes to classroom practices. However, research on AI in education reflects a weak connection to pedagogical perspectives or instructional approaches, particularly in K-12 education. AI technologies may benefit motivated and advanced students. Understanding the teacher's role of student motivation in mediating and supporting learning with AI technologies in the classroom is needed. This study used self-determination theory as the undergirding framework to investigate how teacher support moderates the effects of student expertise on needs satisfactions and intrinsic motivation to learn with AI technologies. This experimental study involved 123 Grade 10 students, and used chatbots as AI-based technologies in the experiment. The analyses revealed that intrinsic motivation and competence to learn with the chatbot depended on both teacher support and student expertise (i.e. self-regulated learning and digital literacy), and the teacher support better satisfied the need for relatedness, and it less satisfied the need for autonomy. The findings refined our understanding about the application of self-determination theory and expand the pedagogical and design considerations of AI application and instructional practices.
193	Medical students' AI literacy and attitudes towards AI: a cross-sectional two-center study using pre-validated assessment instruments Artificial intelligence; AI literacy; Attitudes towards AI; Confirmatory factor analysis; Medical students; Questionnaire Background Artificial intelligence (AI) is becoming increasingly important in healthcare. It is therefore crucial that today's medical students have certain basic AI skills that enable them to use AI applications successfully. These basic skills are often referred to as "AI literacy". Previous research projects that aimed to investigate medical students' AI literacy and attitudes towards AI have not used reliable and validated assessment instruments. Methods We used two validated self-assessment scales to measure AI literacy (31 Likert-type items) and attitudes towards AI (5 Likert-type items) at two German medical schools. The scales were distributed to the medical students through an online questionnaire. The final sample consisted of a total of 377 medical students. We conducted a confirmatory factor analysis and calculated the internal consistency of the scales to check whether the scales were sufficiently reliable to be used in our sample. In addition, we calculated t-tests to determine group differences and Pearson's and Kendall's correlation coefficients to examine associations between individual variables. Results The model fit and internal consistency of the scales were satisfactory. Within the concept of AI literacy, we found that medical students at both medical schools rated their technical understanding of AI significantly lower (M-MS1 = 2.85 and M-MS2 = 2.50) than their ability to critically appraise (M-MS1 = 4.99 and M MS2 = 4.83) or practically use AI (M-MS1 = 4.52 and M-MS2 = 4.32), which reveals a discrepancy of skills. In addition, female medical students rated their overall AI literacy significantly lower than male medical students, t(217.96) = -3.65, p <.001. Students in both samples seemed to be more accepting of AI than fearful of the technology, t(745.42) = 11.72, p <.001. Furthermore, we discovered a strong positive correlation between AI literacy and positive attitudes towards AI and a weak negative correlation between AI literacy and negative attitudes. Finally, we found that prior AI education and interest in AI is positively correlated with medical students' AI literacy. Conclusions Courses to increase the AI literacy of medical students should focus more on technical aspects. There also appears to be a correlation between AI literacy and attitudes towards AI, which should be considered when planning AI courses.
194	Role of AI chatbots in education: systematic literature review Systematic literature review; Artificial intelligence; AI chatbots; Chatbots in education AI chatbots shook the world not long ago with their potential to revolutionize education systems in a myriad of ways. AI chatbots can provide immediate support by answering questions, offering explanations, and providing additional resources. Chatbots can also act as virtual teaching assistants, supporting educators through various means. In this paper, we try to understand the full benefits of AI chatbots in education, their opportunities, challenges, potential limitations, concerns, and prospects of using AI chatbots in educational settings. We conducted an extensive search across various academic databases, and after applying specific predefined criteria, we selected a final set of 67 relevant studies for review. The research findings emphasize the numerous benefits of integrating AI chatbots in education, as seen from both students' and educators' perspectives. We found that students primarily gain from AI-powered chatbots in three key areas: homework and study assistance, a personalized learning experience, and the development of various skills. For educators, the main advantages are the time-saving assistance and improved pedagogy. However, our research also emphasizes significant challenges and critical factors that educators need to handle diligently. These include concerns related to AI applications such as reliability, accuracy, and ethical considerations.
195	Would ChatGPT-facilitated programming mode impact college students' programming behaviors, performances, and perceptions? An empirical study ChatGPT; Programming learning; Behavioral analysis; Perception; College student ChatGPT, an AI-based chatbot with automatic code generation abilities, has shown its promise in improving the quality of programming education by providing learners with opportunities to better understand the principles of programming. However, limited empirical studies have explored the impact of ChatGPT on learners' programming processes. This study employed a quasi-experimental design to explore the possible impact of ChatGPT-facilitated programming mode on college students' programming behaviors, performances, and perceptions. 82 college students were randomly divided into two classes. One class employed ChatGPT-facilitated programming (CFP) practice and the other class utilized self-directed programming (SDP) mode. Mixed methods were utilized to collect multidimensional data. Data analysis uncovered some intriguing results. Firstly, students in the CFP mode had more frequent behaviors of debugging and receiving error messages, as well as pasting console messages on the website and reading feedback. At the same time, students in the CFP mode had more frequent behaviors of copying and pasting codes from ChatGPT and debugging, as well as pasting codes to ChatGPT and reading feedback from ChatGPT. Secondly, CFP practice would improve college students' programming performance, while the results indicated that there was no statistically significant difference between the students in CFP mode and the SDP mode. Thirdly, student interviews revealed three highly concerned themes from students' user experience about ChatGPT: the services offered by ChatGPT, the stages of ChatGPT usage, and experience with ChatGPT. Finally, college students' perceptions toward ChatGPT significantly changed after CFP practice, including its perceived usefulness, perceived ease of use, and intention to use. Based on these findings, the study proposes implications for future instructional design and the development of AI-powered tools like ChatGPT.
196	Learners' perceived AI presences in AI-supported language learning: a study of AI as a humanized agent from community of inquiry Artificial intelligence; language learning; community of inquiry; human-AI interaction This study investigated the application of an artificial intelligence (AI) coach for second language (L2) learning in a primary school involving 327 participants. In line with Community of Inquiry, learners were expected to perceive social, cognitive, and teaching presences when interacting with the AI coach, which was considered a humanized agent. To examine how learners' perceived AI presences were related to their language learning, this study drew on AI usage data, actual learning outcomes, and attitudinal data. Results from hierarchical regression analyses suggest that cognitive presence and learners' affection for AI's appearance were significant predictors of L2 enjoyment, which also positively predicted learning outcomes. The score of English shadowing (representing the quality of AI usage) positively predicted learning outcomes. Contrary to intuition, teaching presence was found to negatively predict learning outcomes. Based on cluster analysis and subsequent MANOVA results, this study indicates that the learners perceiving higher social and cognitive presences via interacting with AI and showing greater affection for AI's appearance tended to use the AI coach more frequently, demonstrate higher L2 enjoyment, and achieve higher learning outcomes. The present study contributes to the limited but increasing knowledge of human-AI interaction in educational settings and carries implications for future efforts on the use of AI for L2 learning.
197	Evaluating an Artificial Intelligence Literacy Programme for Developing University Students? Conceptual Understanding, Literacy, Empowerment and Ethical Awareness Application development; Artificial intelligence literacy; Conceptual framework; Ethical awareness; University students Emerging research is highlighting the importance of fostering artificial intelligence (AI) literacy among educated citizens of diverse academic backgrounds. However, what to include in such literacy programmes and how to teach literacy is still under-explored. To fill this gap, this study designed and evaluated an AI literacy programme based on a multi-dimensional conceptual framework, which developed participants' conceptual understanding, literacy, empowerment and ethical awareness. It emphasised conceptual building, highlighted project work in application development and initiated teaching ethics through application development. Thirty-six university students with diverse academic backgrounds joined and completed this programme, which included 7 hours on machine learning, 9 hours on deep learning and 14 hours on application development. Together with the project work, the results of the tests, surveys and reflective writings completed before and after these courses indicate that the programme successfully enhanced participants' conceptual understanding, literacy, empowerment and ethical awareness. The programme will be extended to include more participants, such as senior secondary school students and the general public. This study initiates a pathway to lower the barrier to entry for AI literacy and addresses a public need. It can guide and inspire future empirical and design research on fostering AI literacy among educated citizens of diverse backgrounds.
198	Acceptance of artificial intelligence among pre-service teachers: a multigroup analysis Artificial intelligence; Educational technology; Acceptance; Pre-service teachers Over the past few years, there has been a significant increase in the utilization of artificial intelligence (AI)-based educational applications in education. As pre-service teachers' attitudes towards educational technology that utilizes AI have a potential impact on the learning outcomes of their future students, it is essential to know more about pre-service teachers' acceptance of AI. The aims of this study are (1) to discover what factors determine pre-service teachers' intentions to utilize AI-based educational applications and (2) to determine whether gender differences exist within determinants that affect those behavioral intentions. A sample of 452 pre-service teachers (325 female) participated in a survey at one German university. Based on a prominent technology acceptance model, structural equation modeling, measurement invariance, and multigroup analysis were carried out. The results demonstrated that eight out of nine hypotheses were supported; perceived ease of use (& beta; = 0.297***) and perceived usefulness (& beta; = 0.501***) were identified as primary factors predicting pre-service teachers' intention to use AI. Furthermore, the latent mean differences results indicated that two constructs, AI anxiety (z = - 3.217**) and perceived enjoyment (z = 2.556*), were significantly different by gender. In addition, it is noteworthy that the paths from AI anxiety to perceived ease of use (p = 0.018*) and from perceived ease of use to perceived usefulness (p = 0.002**) are moderated by gender. This study confirms the determinants influencing the behavioral intention based on the Technology Acceptance Model 3 of German pre-service teachers to use AI-based applications in education. Furthermore, the results demonstrate how essential it is to address gender-specific aspects in teacher education because there is a high percentage of female pre-service teachers, in general. This study contributes to state of the art in AI-powered education and teacher education.
199	Factors Affecting the Adoption of AI-Based Applications in Higher Education: An Analysis of Teachers' Perspectives Using Structural Equation Modeling Artificial intelligence; Higher education; Anxiety; Self-efficacy; Technology acceptance model Owing to the rapid advancements in artificial intelligence (AI) technologies, there has been increasing concern about how to promote the use of AI technologies in school settings to enhance students' learning performance. Teachers' intention to adopt AI tools in their classes plays a crucial role in this regard. Therefore, it is important to explore factors affecting teachers' intention to incorporate AI technologies or applications into course designs in higher education. In this study, a structural equation modeling approach was employed to investigate teachers' continuance intention to teach with AI. In the proposed model, 10 hypotheses regarding anxiety (AN), self-efficacy (SE), attitude towards Al (ATU), perceived ease of use (PEU) and perceived usefulness (PU) were tested, and this study explored how these factors worked together to influence teachers' continuance intention. A total of 311 teachers in higher education participated in the study. Based on the SEM analytical results and the research model, the five endogenous constructs of PU, PEU, SN, and ATU explained 70.4% of the changes in BI. In this model, SN and PEU were the determining factors of BI. The total effect of ATU was 0.793, followed by SE, with a total effect of 0.554. As a result, the intentions of teachers to learn to use AI-based applications in their teaching can be predicted by ATU, SE, PEU, PU and AN. Among them, teachers' SE positively influenced teachers' PEU and ATU towards adopting AI-based applications, and also influenced PU through PEU. In addition, the relationship between teachers' SE and AN was negatively correlated, which indicated that enhancing teachers' SE could reduce their AN towards using AI-based applications in their teaching. Accordingly, implications and suggestions for researchers and school teachers are provided.
200	The opportunities and challenges of ChatGPT in education ChatGPT; AI; university; cheating; plagiarism The launch of OpenAI ChatGPT's language-generation model has raised alarms within many sectors, especially the academic sector. Several academicians have urged universities to develop new forms of assessment after the launch of ChatGPT, which solves academic questions in less than a few minutes. Academic cheating is not a new phenomenon, and the use of AI-generated text to cheat on assignments is a new type of cheating that poses unique challenges. This study used the Latent Dirichlet Allocation (LDA) method for topic modeling and the Valence Aware Dictionary for Sentiment Reasoning (VADER) method for sentiment analysis. After data preprocessing, 3870 tweets were still available out of the originally 10,000 tweets that were extracted for the study. The VADER sentiment analysis results revealed that 2013 tweets were categorized as "positive," with the remaining 804 and 1053 tweets categorized as "negative" and "neutral." The analysis's findings indicate that the majority of people have favorable things to say about ChatGPT. As a result, educational institutions can mitigate the disruptive effects of this technology and promote academic integrity by developing clear policies and guidelines and designing assessments that include limited AI-generated text.
201	Chatbots for future docs: exploring medical students' attitudes and knowledge towards artificial intelligence and medical chatbots Medical students; artificial intelligence; applications in education; human-computer interface; teaching; learning strategies; chatbot Artificial intelligence (AI) in medicine and digital assistance systems such as chatbots will play an increasingly important role in future doctor - patient communication. To benefit from the potential of this technical innovation and ensure optimal patient care, future physicians should be equipped with the appropriate skills. Accordingly, a suitable place for the management and adaptation of digital assistance systems must be found in the medical education curriculum. To determine the existing levels of knowledge of medical students about AI chatbots in particular in the healthcare setting, this study surveyed medical students of the University of Luebeck and the University Hospital of Tuebingen. Using standardized quantitative questionnaires and qualitative analysis of group discussions, the attitudes of medical students toward AI and chatbots in medicine were investigated. From this, relevant requirements for the future integration of AI into the medical curriculum could be identified. The aim was to establish a basic understanding of the opportunities, limitations, and risks, as well as potential areas of application of the technology. The participants (N = 12) were able to develop an understanding of how AI and chatbots will affect their future daily work. Although basic attitudes toward the use of AI were positive, the students also expressed concerns. There were high levels of agreement regarding the use of AI in administrative settings (83.3%) and research with health-related data (91.7%). However, participants expressed concerns that data protection may be insufficiently guaranteed (33.3%) and that they might be increasingly monitored at work in the future (58.3%). The evaluations indicated that future physicians want to engage more intensively with AI in medicine. In view of future developments, AI and data competencies should be taught in a structured way during the medical curriculum and integrated into curricular teaching.
202	To Use or Not to Use? A Mixed-Methods Study on the Determinants of EFL College Learners' Behavioral Intention to Use AI in the Distributed Learning Context artificial intelligence; AI; EFL college learner; behavioral intention; distributed learning Artificial intelligence (AI) offers new possibilities for English as a foreign language (EFL) learners to enhance their learning outcomes, provided that they have access to AI applications. However, little is written about the factors that influence their intention to use AI in distributed EFL learning contexts. This mixed-methods study, based on the technology acceptance model (TAM), examined the determinants of behavioral intention to use AI among 464 Chinese EFL college learners. As to quantitative data, a structural equation modelling (SEM) approach using IBM SPSS Amos (Version 24) produced some important findings. First, it was revealed that perceived ease of use significantly and positively predicts perceived usefulness and attitude toward AI. Second, attitude toward AI significantly and positively predicts behavioral intention to use AI. However, contrary to the TAM assumptions, perceived usefulness does not significantly predict either attitude toward AI or behavioral intention to use AI. Third, mediation analyses suggest that perceived ease of use has a significant and positive impact on students' behavioral intention to use AI through their attitude toward AI, rather than through perceived usefulness. As to qualitative data, semi-structured interviews with 15 learners, analyzed by the software MAXQDA 2022, provide a nuanced understanding of the statistical patterns. This study also discusses the theoretical and pedagogical implications and suggests directions for future research.
203	Understanding key drivers affecting students' use of artificial intelligence-based voice assistants Artificial intelligence; Voice assistant; Human-AI interaction; Technology acceptance; Drivers; Education Artificial intelligence (AI)-based voice assistants have become an essential part of our daily lives. Yet, little is known concerning what motivates students to use them in educational activities. Therefore, this research develops a theoretical model by extending the technology acceptance model (TAM) with subjective norm, enjoyment, facilitating conditions, trust, and security to examine students' use of AI-based voice assistants for instructional purposes. The developed model was then validated based on data collected from 300 university students using the PLS-SEM technique. The results supported the role of enjoyment, trust, and perceived ease of use (PEOU) in affecting the perceived usefulness (PU) of voice assistants. The empirical results also showed that facilitating conditions and trust in technology strongly influence the PEOU. Contrary to the extant literature, the results indicated that subjective norm, facilitating conditions, and security did not impact PU. Similarly, subjective norm and enjoyment did not affect PEOU. This research is believed to add a holistic understanding of the key drivers affecting students' use of voice assistants for educational purposes. It offers several theoretical contributions and practical implications on how to successfully employ these assistants.
204	Perceptions of STEM education and artificial intelligence: a Twitter (X) sentiment analysis Artificial intelligence; Educational technology; STEM teachers; Technology integration; Social media Background, context, and purpose of the studyArtificial intelligence (AI) is becoming increasingly prevalent in science, technology, engineering, and mathematics (STEM) education, holding promising potential for supporting the design and implementation of quality STEM education. However, there is a lack of data-based research studying the diverse perceptions of AI in STEM education as conveyed on social media, the factors that influence those perceptions, or the change in those perceptions over time among public audiences.Results, the main findingsThe purpose of this study was to examine public perceptions of AI in STEM education by analyzing X posts (Tweets) between 04/28/2020 and 04/27/2023. We used a machine learning-based sentiment analysis to analyze the public's perception of AI and the factors that influence it. Findings suggest a range of perceptions among X users regarding AI in STEM education, with most sentiments neutral and positive. However, some negative sentiments were also identified, suggesting that some users may be wary of AI's potential impact on STEM education.ConclusionsThis work will contribute to government, policymakers, and educators in making necessary decisions and improving overall public awareness of AI in STEM education. Additionally, the results of this study suggest that further research is needed to better understand public sentiment about AI in STEM education.
205	Do AI chatbots improve students learning outcomes? Evidence from a meta-analysis artificial intelligence chatbots; educational levels; intervention duration; learning outcomes; meta-analysis Artificial intelligence (AI) chatbots are gaining increasing popularity in education. Due to their increasing popularity, many empirical studies have been devoted to exploring the effects of AI chatbots on students' learning outcomes. The proliferation of experimental studies has highlighted the need to summarize and synthesize the inconsistent findings about the effects of AI chatbots on students' learning outcomes. However, few reviews focused on the meta-analysis of the effects of AI chatbots on students' learning outcomes. The present study performed a meta-analysis of 24 randomized studies utilizing Stata software (version 14). The main goal of the current study was to meta-analytically examine the effects of AI chatbots on students' learning outcomes and the moderating effects of educational levels and intervention duration. The results indicated that AI chatbots had a large effect on students' learning outcomes. Moreover, AI chatbots had a greater effect on students in higher education, compared to those in primary education and secondary education. In addition, short interventions were found to have a stronger effect on students' learning outcomes than long interventions. It could be explained by the argument that the novelty effects of AI chatbots could improve learning outcomes in short interventions, but it has worn off in the long interventions. Future designers and educators should make attempt to increase students' learning outcomes by equipping AI chatbots with human like avatars, gamification elements and emotional intelligence.
206	Enhancing student acceptance of artificial intelligence-driven hybrid learning in business education: Interaction between self-efficacy, playfulness, emotional engagement, and university support AI-Driven hybrid learning; Business education; Hybrid learning; Learning goal orientation; Self-efficacy; University support This study examines the factors influencing student acceptance of Artificial Intelligence (AI)driven hybrid learning within higher education, specifically focusing on business education. By expanding the traditional Technology Acceptance Model (TAM) and incorporating SelfDetermination Theory (SDT), this research explores the interplay between perceived playfulness, learning goal orientation, self-efficacy, and university support. The PLS-SEM and semistructured interviews were applied to data analysis from 279 Chinese university students majoring in international business. The findings reveal that self-efficacy, emotional engagement, and university support significantly enhance students' acceptance of AI-driven hybrid learning. University support, in particular, serves as a critical moderator, amplifying the effects of selfefficacy and acceptance attitudes. The study contributes to the evolving discourse on AI integration in management education, offering insights into optimizing AI-driven hybrid learning experiences and strategies in higher education settings. These findings have implications for curriculum design, institutional support mechanisms, and pedagogical approaches in business and management education, particularly in the context of advancing technological integration and meeting employers' evolving needs.
207	Application of ChatGPT-assisted problem-based learning teaching method in clinical medical education Problem-based learning; ChatGPT; Medical education IntroductionArtificial intelligence technology has a wide range of application prospects in the field of medical education. The aim of the study was to measure the effectiveness of ChatGPT-assisted problem-based learning (PBL) teaching for urology medical interns in comparison with traditional teaching.MethodsA cohort of urology interns was randomly assigned to two groups; one underwent ChatGPT-assisted PBL teaching, while the other received traditional teaching over a period of two weeks. Performance was assessed using theoretical knowledge exams and Mini-Clinical Evaluation Exercises. Students' acceptance and satisfaction with the AI-assisted method were evaluated through a survey.ResultsThe scores of the two groups of students who took exams three days after the course ended were significantly higher than their scores before the course. The scores of the PBL-ChatGPT assisted group were significantly higher than those of the traditional teaching group three days after the course ended. The PBL-ChatGPT group showed statistically significant improvements in medical interviewing skills, clinical judgment and overall clinical competence compared to the traditional teaching group. The students gave highly positive feedback on the PBL-ChatGPT teaching method.ConclusionThe study suggests that ChatGPT-assisted PBL teaching method can improve the results of theoretical knowledge assessment, and play an important role in improving clinical skills. However, further research is needed to examine the validity and reliability of the information provided by different chat AI systems, and its impact on a larger sample size.
208	Effects of artificial Intelligence-Enabled personalized recommendations on learners? learning engagement, motivation, and outcomes in a flipped classroom Data science applications in education; Distance education and online learning; Improving classroom teaching The flipped classroom approach is aimed at improving learning outcomes by promoting learning motivation and engagement. Recommendation systems can also be used to improve learning outcomes. With the rapid development of artificial intelligence (AI) technology, various systems have been developed to facilitate student learning. Accordingly, we applied AI-enabled personalized video recommendations to stimulate students' learning motivation and engagement during a systems programming course in a flipped classroom setting. We assigned students to control and experimental groups comprising 59 and 43 college students, respectively. The students in both groups received flipped classroom instruction, but only those in the experimental group received AI-enabled personalized video recommendations. We quantitatively measured students' engagement based on their learning profiles in a learning management system. The results revealed that the AI-enabled personalized video recommendations could significantly improve the learning performance and engagement of students with a moderate motivation level.
209	Adoption of artificial intelligence in higher education: a quantitative analysis using structural equation modelling AI; Attitude; Behavioural intention; Education; India Emergence of the use and application of Artificial Intelligence (AI) in higher education in India has opened new possibilities and challenges. Use of AI in will bring in effective change of governance in the entire internal architecture of Indian Institutes of higher education. The prospect of use of AI includes investigation of educational implications as to how teachers would enrich them, how students would learn, and how accurate and prompt decisions can be taken in the institutes of higher education. This is important since the workload has been multiplied due to massification of higher education. Such being the scenario, help of AI is highly essential. The question of adoption of AI in higher education is an important issue in this perspective. The purpose of this study is to explore how the stakeholders would be able to adopt it. For this, we have taken help of many adoption theories and models including 'Unified Theory of Acceptance and Use of Technology' (UTAUT) model. We have developed hypotheses and a conceptual model and got it validated through survey with the help of feedbacks from useable 329 respondents. It has been found that the model can help the authorities to facilitate adoption of AI in higher education.
210	Developing and Validating a Scale of Artificial Intelligence Anxiety Among Chinese EFL Teachers AI anxiety; Chinese EFL teacher; scale development As artificial intelligence (AI) technology continues to advance, its influences across various industries have grown, leading to increasing levels of anxiety, including that in education. Nonetheless, in terms of current knowledge, the literature lacks a valid scale to measure AI anxiety among EFL teachers, particularly university EFL teachers. Moreover, the underlying dimensions of this construct have yet to be clarified. Against these gaps, this study aims to develop and validate a scale to assess AI anxiety among university EFL teachers in China. We used qualitative interviews and quantitative surveys combined to identify the key dimensions of AI anxiety of university EFL teachers. In so doing, 251 Chinese EFL teachers completed a newly designed scale. The result of exploratory factor analyses indicated five dimensions and 21 items in the questionnaire. Five dimensions were identified: technical proficiency, job displacement, technological support, student experience and research development. Next, another 415 Chinese EFL teachers participated in validating the scale. The result of confirmatory factor analysis indicated that the scale demonstrated strong reliability, validity and an acceptable model fit. This new scale provides a useful tool for assessing AI anxiety in EFL teachers and highlights the unique challenges they face in adapting to AI, offering a basis for future research and targeted support.
211	Examining the roles of social presence and human-likeness on Iranian EFL learners' motivation using artificial intelligence technology: a case of CSIEC chatbot Chatbot; artificial intelligence; learner motivation; human-likeness; SEM Artificial Intelligence (AI) technology in the educational context, particularly chatbotics, has made significant changes in learning English. This mixed-methods study is intended to explore university students' attitudes toward the potential role of artificial intelligence (AI)-assisted mobile applications. Meanwhile, the role of social presence and human-likeness on learner motivation was examined through a chatbot lens. A total of 256 English as a foreign language (EFL) learners interacted with a chatbot known as Computer Simulation in Educational Communication (CSIEC). Participants' audio-recorded practices, transcriptions, three scales of social presence, learner motivation, and human-likeness, along with a semi-structured focus group interview, were used to collect data, Structural Equation Modeling (SEM) was used for data analysis. Moreover, thematic analysis was adopted to explore the participants' attitudes and perceptions toward using CSIES. The quantitative results indicated that learner motivation was significantly predicted by social presence and human-likeness. The thematic analysis of qualitative data reflected that the attributed descriptions to the CSIEC teacher enhanced learners' motivation, eagerness, and confidence to learn English. The findings of this study may be used to guide future research in using chatbots outside the classroom to serve as learning companions, and educators can utilize them to tailor assessment and feedback procedures.
212	AI in Medical Education: Global situation, effects and challenges Medical education; Artificial intelligence; Applications of AIMED; Effectiveness of AIMED; Challenges of AIMED PurposeArtificial Intelligence (AI) is transforming healthcare and shows considerable promise for the delivery of medical education. This systematic review provides a comprehensive analysis of the global situation, effects, and challenges associated with applying AI at the different stages of medical education.MethodsThis review followed the PRISMA guidelines, and retrieved studies published on Web of Science, PubMed, Scopus, and IEEE Xplore, from 1990 to 2022. After duplicates were removed (n = 1407) from the 6371 identified records, the full text of 179 records were screened. In total, 42 records were eligible.ResultsIt revealed three teaching stages where AI can be applied in medical education (n = 39), including teaching implementation (n = 24), teaching evaluation (n = 10), and teaching feedback (n = 5). Many studies explored the effectiveness of AI adoption with questionnaire survey and control experiment. The challenges are performance improvement, effectiveness verification, AI training data sample and AI algorithms.ConclusionsAI provides real-time feedback and accurate evaluation, and can be used to monitor teaching quality. A possible reason why AI has not yet been applied widely to practical teaching may be the disciplinary gap between developers and end-user, it is necessary to strengthen the theoretical guidance of medical education that synchronizes with the rapid development of AI. Medical educators are expected to maintain a balance between AI and teacher-led teaching, and medical students need to think independently and critically. It is also highly demanded for research teams with a wide range of disciplines to ensure the applicability of AI in medical education.
213	The mediating effects of needs satisfaction on the relationships between prior knowledge and self-regulated learning through artificial intelligence chatbot artificial intelligence; K-12 education; prior knowledge; self-determination theory; self-regulated learning The anthropomorphic characteristics of artificial intelligence (AI) can provide a positive environment for self-regulated learning (SRL). The factors affecting adolescents' SRL through AI technologies remain unclear. Limited AI and disciplinary knowledge may affect the students' motivations, as explained by self-determination theory (SDT). In this study, we examine the mediating effects of needs satisfaction in SDT on the relationship between students' previous technical (AI) and disciplinary (English) knowledge and SRL, using an AI conversational chatbot. Data were collected from 323 9th Grade students through a questionnaire and a test. The students completed an AI basic unit and then learned English with a conversational chatbot for 5 days. Confidence intervals were calculated to investigate the mediating effects. We found that students' previous knowledge of English but not their AI knowledge directly affected their SRL with the chatbot, and that satisfying the need for autonomy and competence mediated the relationships between both knowledge (AI and English) and SRL, but relatedness did not. The self-directed nature of SRL requires heavy cognitive learning and satisfying the need for autonomy and competence may more effectively engage young children in this type of learning. The findings also revealed that current chatbot technologies may not benefit students with relatively lower levels of English proficiency. We suggest that teachers can use conversational chatbots for knowledge consolidation purposes, but not in SRL explorations. Practitioner notesWhat is already known about this topicArtificial intelligence (AI) technologies can potentially support students' self-regulated learning (SRL) of disciplinary knowledge through chatbots.Needs satisfaction in Self-determination theory (SDT) can explain the directive process required for SRL.Technical and disciplinary knowledge would affect SRL with technologies. What this paper addsThis study examines the mediating effects of needs satisfaction in SDT on the relationship between students' previous AI (technical) and English (disciplinary) knowledge and SRL, using an AI conversational chatbot.Students' previous knowledge of English but not their AI knowledge directly affected their SRL with the chatbot.Autonomy and competence were mediators, but relatedness was not. Implications for practice and/or policyTeachers should use chatbots for knowledge consolidation rather than exploration.Teachers should support students' competence and autonomy, as these were found to be the factors that directly predicted SRL.School leaders and teacher educators should include the mediating effects of needs satisfaction in professional development programmes for digital education.
214	State of the art and practice in AI in education  Recent developments in Artificial Intelligence (AI) have generated great expectations for the future impact of AI in education and learning (AIED). Often these expectations have been based on misunderstanding current technical possibilities, lack of knowledge about state-of-the-art AI in education, and exceedingly narrow views on the functions of education in society. In this article, we provide a review of existing AI systems in education and their pedagogic and educational assumptions. We develop a typology of AIED systems and describe different ways of using AI in education and learning, show how these are grounded in different interpretations of what AI and education is or could be, and discuss some potential roadblocks on the AIED highway.
215	Metacognitive Awareness and EFL Learners' Perceptions and Experiences in Utilising ChatGPT for Writing Feedback AI assistance; ChatGPT; digital education; EFL writing; metacognitive awareness The present study explored EFL students' perceptions and experiences in utilising ChatGPT to seek feedback for writing. The present study also examined how levels of metacognitive awareness (MA) influenced these perceptions and experiences. Utilising a mixed-method research design, the study collected data from a total of 40 EFL undergraduates over a semester-long writing course. Data collection methods included self-report questionnaires and semi-structured interviews. Data analyses comprised both quantitative and qualitative approaches. Quantitatively, t-tests and Mann-Whitney U tests were used to compare group differences, while regression analyses were conducted to explore relationships between variables. Qualitatively, thematic analysis was employed to identify and interpret patterns within the data. Quantitative analysis revealed significant differences in writing experiences and perceptions, including motivation for writing, engagement, self-efficacy and collaborative writing tendency. Furthermore, a positive correlation was found between MA scores and students' perceptions and practices of using ChatGPT. Analysis of interview data highlighted a range of perceptions and experiences between the high and low MA students, with behaviours spanning from mere copying words from ChatGPT to effective use of ChatGPT for writing feedback. Key factors that influenced the effective use of ChatGPT for writing assistance included metacognitive awareness, critical thinking skills and cognitive efforts. The findings highlight implications for writing teachers and students in teaching and learning English as a foreign language.
216	To use or not to use ChatGPT in higher education? A study of students' acceptance and use of technology ChatGPT; higher education; technology acceptance ChatGPT is an AI tool that assisted in writing, learning, solving assessments and could do so in a conversational way. The purpose of the study was to develop a model that examined the predictors of adoption and use of ChatGPT among higher education students. The proposed model was based on a previous theory of technology adoption. Seven predictors were selected to build a model that predicted the behavioral intention and use behavior of ChatGPT. The partial-least squares method of structural equation modeling was used for data analysis. The model was found to be reliable and valid, and the results were based on a self-reported data of 534 students from a Polish state university. Nine out of ten proposed hypotheses were confirmed by the results. Habit was found to be the best predictor of behavioral intention, followed by performance expectancy and hedonic motivation. The dominant determinant of use behavior was behavioral intention, followed by personal innovativeness. The research highlighted the need for further examination of how AI tools could be adopted in learning and teaching.
217	Measuring EFL learners' use of ChatGPT in informal digital learning of English based on the technology acceptance model ChatGPT; informal digital learning of English; technology acceptance model; structural equation modeling; AI technology PurposeThis study aims to generate empirical insights into the extent to which ChatGPT, a highly capable AI chatbot building on OpenAI's GPT family, is perceived and leveraged by EFL learners beyond the classroom.Design/MethodologyThis quantitative cross-sectional investigation draws upon the technology acceptance model (TAM) as developed by (Davis, F. D. 1989. "Perceived Usefulness, Perceived Ease of use, and User Acceptance of Information Technology." Management Information System Quarterly 13 (3): 983-1003) to conceptualize EFL learners' attitudes, intentions, and actual behaviors of using ChatGPT in their informal digital learning of English. A total of 405 EFL learners answered the revised TAM questionnaire with scales including Perceived Ease of Use, Perceived Usefulness, Attitude, Behavioral Intention, and Actual Use.FindingsThe results of structural equation modeling analyses indicated that while Perceived Ease of Use fails to predict learners' Attitude directly, it can influence Attitude through the full mediator Perceived Usefulness. It was also found that learners who take positive attitudes toward the usefulness of ChatGPT tend to demonstrate a higher level of Behavioral Intention, which positively and strongly predicts their Actual Use of ChatGPT in English learning outside the classroom.Originality/valueThis study provides empirical evidence that supports the potential of ChatGPT as a powerful language-learning tool that EFL learners should utilize to participate in the ecological CALL creatively and productively.
218	A self-determination theory (SDT) design approach for inclusive and diverse artificial intelligence (AI) education AI education; K-12 education; Inclusion; Diversity; Self-determination theory; Motivation The introduction of artificial intelligence (AI) as a subject in K-12 education is a new and important global strategic initiative, but there is a serious lack of studies in relation to this initiative that address inclusion and diversity of education. Self-determination theory (SDT) can explain student engagement from the needs satisfaction perspective. Therefore, this project aimed to investigate how SDT-based needs support by teachers and student attributes (gender and achievement level) affect AI learning at secondary school level. It adopted a two-study design, with each study using a 2 x 2 between-subjects factorial design with student needs support from teachers as one factor and one of the student attributes as the other: gender in Study 1 and achievement level in Study 2. In both studies, there were two groups - SDT-based (teacher needs support) and control (without). The analyses revealed that in the SDT-based program, (1) the students had a more positive perception of AI learning and felt that their needs were satisfied, and (2) there were non-significant differences in AI learning between boys and girls and between high and low achievers. The findings suggest that a focus on needs satisfaction could engage boys and girls, and high and low achievers in AI learning. As they become more engaged, they are likely to gain more confidence, feel that the content is more relevant, and become intrinsically motivated to pursue further AI learning.
219	AI in teacher education: Unlocking new dimensions in teaching support, inclusive learning, and digital literacy artificial intelligence; digital literacy; inclusive learning; personalized teaching; student-teacher interaction; teacher education Background: AI can positively influence teaching by offering support for classroom management, creating inclusive learning environments, enhancing digital skills, personalizing teaching methods, and strengthening teacher-student relationships. Objectives: This quantitative research study investigates the opportunities, difficulties, and consequences of incorporating AI into teacher education. Methods: Data were collected through structured questionnaires from 202 college students and 68 staff members. The analysis was conducted using SPSS software. Results: The study provides a novel contribution by its thorough investigation of the diverse effects of AI on teacher education. It offers beneficial perspectives on the possible benefits and challenges, illuminating the far-reaching changes that AI could bring to the terrain of learning and instruction and teaching methods in the time yet to come. The research sought to assess the effect of AI adoption in teacher education across five main dimensions: (i) its influence on teaching support and classroom management, (ii) its role in creating inclusive and accessible learning environments, (iii) its contribution to improving teachers' digital literacy and computer skills, and enhancing access to digital teaching resources, (iv) its positive influence on identifying students' learning styles and facilitating the adoption of diverse teaching methods, and (v) its role in strengthening teacher-student relationships through improved interactions. Conclusion: The findings elucidate the promising opportunities that AI presents in the field of teacher education, along with the obstacles that require resolution for the effective fusion of AI educational settings.
220	Modeling students' perceptions of artificial intelligence assisted language learning Artificial intelligence; Language learning; UTAUT; Motivation; Middle school To address the emerging trend of language learning with Artificial Intelligence (AI), this study explored junior and senior high school students' behavioral intentions to use AI in second language (L2) learning, and the roles of related technological, social, and motivational factors. An eight-factor survey was constructed using a 5-point Likert scale. A total of 524 valid responses were collected, including 280 responses from junior high school students and 244 from senior high school students. The reliability and validity of the scale were satisfactory. The technological and social factors include effort expectancy, performance expectancy, social influence, facilitating conditions of AI-assisted language learning (AILL), which were hypothesized to predict students' behavioral intention to use AILL with reference to the Unified Theory of Acceptance and Use of Technology (UTAUT) model. The motivational factors derived from L2 Motivational Self System theory (i.e. learning experience with AI, cultural interest with AI, and instrumentality-promotion with AI) were hypothesized to be intermediate variables between the technological and social factors and behavioral intention based on the extended UTAUT (UTAUT2). Therefore, UTAUT and the L2 Self System were combined according to UTAUT2 to construct the proposed model in this study, named AILL-Motivation-UTAUT model. The results of the structural equation models of AILL-Motivation-UTAUT showed that performance expectancy, cultural interest, and instrumentality-promotion could predict students' behavioral intention to use AILL for both junior and senior high students; effort expectancy and social influence could predict behavioral intention to use AILL only for junior high students, learning experience with AI could predict behavioral intention to use AILL only for senior high students, while facilitating conditions could not predict behavioral intention to use AILL for either group. The predictive power (80% for senior high students and 74% for junior high students) of the AILL-Motivation-UTAUT model in this research is higher than or equal to that of UTAUT2 (74%). In addition, this study found that the technological and social factors perceived by students would predict the motivation in AILL. The model verified in this study may inform future studies on AI integration for English as foreign language learning.
221	The impact of ChatGPT on L2 writing and expected responses: Voice from doctoral students ChatGPT; L2 writing; Human-AI collaboration; Chatbot-assisted writing; Doctoral students Despite the growing popularity of ChatGPT and chatbot-assisted writing, research on the use of ChatGPT in second language (L2) writing classrooms remains insufficient. Using reflection papers and focus group interviews, the qualitative study examined doctoral students' views on the impact of using ChatGPT on L2 writing and their expected responses. Thematic analysis revealed that ChatGPT could support writers at the pre-writing, during-writing and post-writing stages and serve as a self-learning tool for writing and thinking development with its human and non-human features. Nonetheless, its generative nature also gave rise to concerns for learning loss, authorial voice, unintelligent texts, academic integrity as well as social and safety risks. Based on the benefits and drawbacks, the doctoral students expected the education sector to make concerted efforts for the effective, ethical and responsible use of ChatGPT in L2 writing. Suggestions are accordingly provided for future considerations in teaching and research to leverage ChatGPT for L2 writing.
222	Unleashing ChatGPT's Power: A Case Study on Optimizing Information Retrieval in Flipped Classrooms via Prompt Engineering Chat generative pretrained transformer (ChatGPT); flipped classrooms; information retrieval; prompt engineering This research project investigates the impact of prompt engineering, a key aspect of chat generative pretrained transformer (ChatGPT), on college students' information retrieval in flipped classrooms. In recent years, an increasing number of students have been using AI-based tools, such as ChatGPT rather than traditional research engines to learn and to complete course assignments. Despite this growing trend, previous research has largely overlooked the influence of prompt engineering on students' use of ChatGPT and effective strategies for improving the quality of information retrieval in learning settings. To address this research gap, this study examines the information quality obtained from ChatGPT in a flipped classroom by evaluating its effectiveness in task completion among 26 novice undergraduates from the same major and cohort. The experimental results provide evidence that proficient mastery of prompt engineering improves the quality of information obtained by students using ChatGPT. Consequently, by acquiring proficiency in prompt engineering, students can maximize the positive impact of ChatGPT, obtain high-quality information, and enhance their learning efficiency in flipped classrooms.
223	Large language models for generating medical examinations: systematic review Large language models; Generative pre-trained transformer; Multiple choice questions; Medical education; Artificial intelligence; Medical examination Background Writing multiple choice questions (MCQs) for the purpose of medical exams is challenging. It requires extensive medical knowledge, time and effort from medical educators. This systematic review focuses on the application of large language models (LLMs) in generating medical MCQs.Methods The authors searched for studies published up to November 2023. Search terms focused on LLMs generated MCQs for medical examinations. Non-English, out of year range and studies not focusing on AI generated multiple-choice questions were excluded. MEDLINE was used as a search database. Risk of bias was evaluated using a tailored QUADAS-2 tool.Results Overall, eight studies published between April 2023 and October 2023 were included. Six studies used Chat-GPT 3.5, while two employed GPT 4. Five studies showed that LLMs can produce competent questions valid for medical exams. Three studies used LLMs to write medical questions but did not evaluate the validity of the questions. One study conducted a comparative analysis of different models. One other study compared LLM-generated questions with those written by humans. All studies presented faulty questions that were deemed inappropriate for medical exams. Some questions required additional modifications in order to qualify.Conclusions LLMs can be used to write MCQs for medical examinations. However, their limitations cannot be ignored. Further study in this field is essential and more conclusive evidence is needed. Until then, LLMs may serve as a supplementary tool for writing medical examinations. 2 studies were at high risk of bias. The study followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines.
224	Revolutionizing healthcare: the role of artificial intelligence in clinical practice AI; Healthcare; Patient care; Quality of life; Clinicians; Decision-making; Personalized treatment plans IntroductionHealthcare systems are complex and challenging for all stakeholders, but artificial intelligence (AI) has transformed various fields, including healthcare, with the potential to improve patient care and quality of life. Rapid AI advancements can revolutionize healthcare by integrating it into clinical practice. Reporting AI's role in clinical practice is crucial for successful implementation by equipping healthcare providers with essential knowledge and tools.Research SignificanceThis review article provides a comprehensive and up-to-date overview of the current state of AI in clinical practice, including its potential applications in disease diagnosis, treatment recommendations, and patient engagement. It also discusses the associated challenges, covering ethical and legal considerations and the need for human expertise. By doing so, it enhances understanding of AI's significance in healthcare and supports healthcare organizations in effectively adopting AI technologies.Materials and MethodsThe current investigation analyzed the use of AI in the healthcare system with a comprehensive review of relevant indexed literature, such as PubMed/Medline, Scopus, and EMBASE, with no time constraints but limited to articles published in English. The focused question explores the impact of applying AI in healthcare settings and the potential outcomes of this application.ResultsIntegrating AI into healthcare holds excellent potential for improving disease diagnosis, treatment selection, and clinical laboratory testing. AI tools can leverage large datasets and identify patterns to surpass human performance in several healthcare aspects. AI offers increased accuracy, reduced costs, and time savings while minimizing human errors. It can revolutionize personalized medicine, optimize medication dosages, enhance population health management, establish guidelines, provide virtual health assistants, support mental health care, improve patient education, and influence patient-physician trust.ConclusionAI can be used to diagnose diseases, develop personalized treatment plans, and assist clinicians with decision-making. Rather than simply automating tasks, AI is about developing technologies that can enhance patient care across healthcare settings. However, challenges related to data privacy, bias, and the need for human expertise must be addressed for the responsible and effective implementation of AI in healthcare.
225	Performance of ChatGPT on Chinese national medical licensing examinations: a five-year examination evaluation study for physicians, pharmacists and nurses Medical education; Medical examination; Artificial intelligence; Natural language processing; ChatGPT BackgroundLarge language models like ChatGPT have revolutionized the field of natural language processing with their capability to comprehend and generate textual content, showing great potential to play a role in medical education. This study aimed to quantitatively evaluate and comprehensively analysis the performance of ChatGPT on three types of national medical examinations in China, including National Medical Licensing Examination (NMLE), National Pharmacist Licensing Examination (NPLE), and National Nurse Licensing Examination (NNLE).MethodsWe collected questions from Chinese NMLE, NPLE and NNLE from year 2017 to 2021. In NMLE and NPLE, each exam consists of 4 units, while in NNLE, each exam consists of 2 units. The questions with figures, tables or chemical structure were manually identified and excluded by clinician. We applied direct instruction strategy via multiple prompts to force ChatGPT to generate the clear answer with the capability to distinguish between single-choice and multiple-choice questions.ResultsChatGPT failed to pass the accuracy threshold of 0.6 in any of the three types of examinations over the five years. Specifically, in the NMLE, the highest recorded accuracy was 0.5467, which was attained in both 2018 and 2021. In the NPLE, the highest accuracy was 0.5599 in 2017. In the NNLE, the most impressive result was shown in 2017, with an accuracy of 0.5897, which is also the highest accuracy in our entire evaluation. ChatGPT's performance showed no significant difference in different units, but significant difference in different question types. ChatGPT performed well in a range of subject areas, including clinical epidemiology, human parasitology, and dermatology, as well as in various medical topics such as molecules, health management and prevention, diagnosis and screening.ConclusionsThese results indicate ChatGPT failed the NMLE, NPLE and NNLE in China, spanning from year 2017 to 2021. but show great potential of large language models in medical education. In the future high-quality medical data will be required to improve the performance.
226	ChatGPT as a CALL tool in language education: A study of hedonic motivation adoption models in English learning environments ChatGPT; Computer-assisted language learning (CALL); Hedonic motivation system adoption model (HMSAM); Structural equation modelling (SEM) The advancement of information technologies has led to increased attention to AI chatbots as valuable tools for computer-assisted language learning (CALL), drawing the attention of both academic scholars and industry practitioners. However, there remains limited understanding regarding the adoption of AI chatbots, specifically within the context of the English language. To address this existing research gap and examine the perception and motivation of usage of ChatGPT, this research employed the hedonic motivation system adoption model (HMSAM) to examine the adoption of ChatGPT. Employing structural equation modelling (SEM), a comprehensive investigation was conducted using data sourced from 189 valid responses obtained through an online survey administered to Chinese international students who are currently enrolled in British universities. The findings reveal that the research model effectively elucidates the elements influencing the adoption of ChatGPT in English learning. Notably, boredom, joy, focused immersion, and control emerged as significant mediating factors pertaining to the link between perceived ease of use and behavioural intention. These findings offer meaningful perspectives for upcoming researchers and practitioners in English language teaching and learning, contributing to promoting innovation in this domain.
227	Artificial intelligence in higher education: the state of the field Artificial Intelligence; AI; Systematic review; Higher education This systematic review provides unique findings with an up-to-date examination of artificial intelligence (AI) in higher education (HE) from 2016 to 2022. Using PRISMA principles and protocol, 138 articles were identified for a full examination. Using a priori, and grounded coding, the data from the 138 articles were extracted, analyzed, and coded. The findings of this study show that in 2021 and 2022, publications rose nearly two to three times the number of previous years. With this rapid rise in the number of AIEd HE publications, new trends have emerged. The findings show that research was conducted in six of the seven continents of the world. The trend has shifted from the US to China leading in the number of publications. Another new trend is in the researcher affiliation as prior studies showed a lack of researchers from departments of education. This has now changed to be the most dominant department. Undergraduate students were the most studied students at 72%. Similar to the findings of other studies, language learning was the most common subject domain. This included writing, reading, and vocabulary acquisition. In examination of who the AIEd was intended for 72% of the studies focused on students, 17% instructors, and 11% managers. In answering the overarching question of how AIEd was used in HE, grounded coding was used. Five usage codes emerged from the data: (1) Assessment/Evaluation, (2) Predicting, (3) AI Assistant, (4) Intelligent Tutoring System (ITS), and (5) Managing Student Learning. This systematic review revealed gaps in the literature to be used as a springboard for future researchers, including new tools, such as Chat GPT.
228	Exploring the impact of ChatGPT-generated feedback on technical writing skills of computing students: A blinded study AI-generated feedback; ChatGPT; Modern technologies; Writing skills; Computing students; Higher education This research investigates the impact of ChatGPT-generated feedback on the writing skills of first-year computing students at a Saudi University. Employing a qualitative research design, the study involved 111 male students, blinded to the switch from human to ChatGPT-generated feedback, ensuring unbiased reflections on their experiences. Over six weeks, students' reactions to feedback were meticulously analyzed, revealing nuanced emotional, psychological, and educational impacts. The findings, organized into four distinct themes - Emotional and Psychological Responses, Perceived Quality and Usefulness, Progress and Development, and Feedback Content and Delivery - offer rich insights into the multifaceted experiences of students. While some students responded to the feedback provided during weeks 4 and 5 (ChatGPT-generated feedback), perceiving it as a catalyst for learning and self-improvement, others expressed concerns about its consistency and personalization. The study highlights the potential of ChatGPT in education, while also illuminating the need for a balanced, adaptive, and personalized approach to feedback that aligns with diverse learning styles, emotional responses, and educational needs.
229	Implementation of an AI chatbot as an English conversation partner in EFL speaking classes artificial intelligence; English as a foreign language; voice chatbot; speaking tasks; second language learning chatbot With the growth of chatbots, concerns about implementing artificial intelligence (AI) chatbots in educational settings have consistently arisen, especially for the purpose of language learning. This study introduced a task-based voice chatbot called "Ellie", newly developed by the researchers, and examined the appropriateness of its task design and performance as an English conversation partner and students' perceptions on using it in EFL class. Korean EFL learners (N = 314) aged 10-15 years performed three speaking tasks with Ellie in their school classroom. The participants took 9.63 turns per session on average using the first 1,000-word band, indicating that the chatbot highly encouraged students to engage in conversation, which rarely occurs in general EFL classes in Korea. The high task success rates (88.3%) showed the design appropriateness of both L2 tasks and operational intents in terms of users' successful understanding and completeness of the given chatbot tasks. The participants' responses to the survey not only supported the positive potential of the chatbot in EFL settings but also revealed limitations to be resolved. Future suggestions for advancing and implementing AI chatbots in EFL classrooms are discussed.
230	Using chatbots to scaffold EFL students? argumentative writing Argumentative writing; Chatbots; Artificial intelligence; Argumate Research suggests that English as a foreign language (EFL) students' argumentative writing benefits from interactions with peers. However, finding an ideal partner to interact with can be difficult in practice, and chatbots have been suggested as a potential solution to this problem. Chatbots are a form of artificial intelligence (AI) designed to engage in turn-by-turn conversations with human users. In this paper, we propose a chatbot-assisted approach to the teaching and learning of argumentative writing. We describe Argumate, a novel chatbot system that we developed to scaffold students' argument construction, and we discuss the advantages and lim-itations of using this system to assist students in producing high-quality argumentative writing.
231	The impact of AI-assisted pair programming on student motivation, programming anxiety, collaborative learning, and programming performance: a comparative study with traditional pair programming and individual approaches AI-assisted pair programming; Intrinsic motivation; Programming anxiety; Collaborative learning; Programming performance Purpose This study investigates the impact of AI-assisted pair programming on undergraduate students' intrinsic motivation, programming anxiety, and performance, relative to both human-human pair programming and individual programming approaches. Methods A quasi-experimental design was conducted over two academic years (2023-2024) with 234 undergraduate students in a Java web application development course. Intact class sections were randomly assigned to AI-assisted pair programming (using GPT-3.5 Turbo in 2023 and Claude 3 Opus in 2024), human-human pair programming, or individual programming conditions. Data on intrinsic motivation, programming anxiety, collaborative perceptions, and programming performance were collected at three time points using validated instruments. Results Compared to individual programming, AI-assisted pair programming significantly increased intrinsic motivation (p < .001, d = 0.35) and reduced programming anxiety (p < .001), producing outcomes comparable to human-human pair programming. AI-assisted groups also outperformed both individual and human-human groups in programming tasks (p < .001). However, human-human pair programming fostered the highest perceptions of collaboration and social presence, surpassing both AI-assisted and individual conditions (p < .001). Mediation analysis revealed that perceived usefulness of the AI assistant significantly mediated the relationship between the programming approach and student outcomes, highlighting the importance of positive perceptions in leveraging AI tools for educational benefits. No significant differences emerged between the two AI models employed, indicating that both GPT-3.5 Turbo and Claude 3 Opus provided similar benefits. Conclusion While AI-assisted pair programming enhances motivation, reduces anxiety, and improves performance, it does not fully match the collaborative depth and social presence achieved through human-human pairing. These findings highlight the complementary strengths of AI and human interaction: AI support can bolster learning outcomes, yet human partners offer richer social engagement. As AI capabilities advance, educators should integrate such tools thoughtfully, ensuring that technology complements rather than replaces the interpersonal dynamics and skill development central to effective programming education.
232	Investigating AI-based academic support acceptance and its impact on students' performance in Malaysian and Pakistani higher education institutions Artificial intelligence; AI in Education; UTAUT; Higher education; Student achievement; Academic support The rapid advancement of artificial intelligence (AI) technologies has led to a transformation in higher education worldwide. AI tools provide academic support to students anywhere and anytime to enhance their knowledge and skills. Those facing difficulties have been relying on traditional support and guidance. However, this support has experienced difficulties, including availability and accessibility. This study examines the potential of AI-powered tools to address these challenges, aiming to make academic support more accessible, efficient, and effective. This study focuses on understanding the determinants of AI tools' acceptance and use for academic support among students, influencing student satisfaction and academic performance in Pakistan and Malaysia. The research on AI tool acceptance and use in the higher education Institutions (HEI) context is still new and less explored in Pakistani and Malaysian higher education institutions. A theoretical model based on the Unified Theory of Acceptance and Use of Technology (UTAUT) and other factors was employed to identify factors that affect AI tool adoption in higher education. The survey research design was employed, and the total sample size was 305 respondents, with 203 students from Quaid-e-Awam University of Science and Technology (QUEST), Pakistan, and 102 students from Universiti Teknologi Malaysia (UTM). A "Partial least squares structural equation modeling (PLS-SEM) Analysis" was employed to assess the research model and hypotheses using SmartPls 4.0. In Pakistan and Malaysia, students are more concerned about using AI tools to improve their academic performance. The findings indicated that performance and effort expectancy, information accuracy of AI tools, pedagogical fit to meet the student's expectations, and student interaction with tools were important factors in predicting the acceptance and use of AI tools among students of both countries in higher education, and the rising use of these AI tools has improved students' satisfaction levels and significantly impacted students learning outcomes in both countries. Additionally, student engagement and personal innovativeness have not significantly affected the use of AI tools among students in both countries. This study provides a comprehensive analysis of AI tool adoption in the unique contexts of Pakistan and Malaysia, contributing to the broader discourse on technology integration in higher education.
233	Supporting the Instructional Videos With Chatbot and Peer Feedback Mechanisms in Online Learning: The Effects on Learning Performance and Intrinsic Motivation video-based learning; chatbot; feedback; teacher education; intrinsic motivation; artificial intelligence; peer feedback; online learning This study investigated the effects of artificial intelligence (AI)-based chatbot and peer feedback mechanisms integrated into the instructional videos (IVs) as a feedback tool on learning performance and intrinsic motivation of pre-service teachers (PTs) in online learning. The participants were 144 PTs from a university in Turkey. A pretest-posttest quasi-experimental design was adopted in this study. Two experimental (EG-1: Immediately elaborated feedback with a chatbot for IVs; EG-2: Delayed peer feedback with comments for IVs) groups and a control group (teaching with IVs) were selected. To collect qualitative data, a survey consisting of open-ended questions was conducted in the experimental groups. The results showed that the learning performance and intrinsic motivation scores of chatbot-based and peer feedback groups were higher than the scores in the traditional learning group. The implications for AI-powered feedback mechanisms and directions for future studies were discussed in this study.
234	Using natural language processing to support peer-feedback in the age of artificial intelligence: A cross-disciplinary framework and a research agenda adaptivity; artificial intelligence; digital learning; large language models; learner support; natural language processing; peer-feedback Advancements in artificial intelligence are rapidly increasing. The new-generation large language models, such as ChatGPT and GPT-4, bear the potential to transform educational approaches, such as peer-feedback. To investigate peer-feedback at the intersection of natural language processing (NLP) and educational research, this paper suggests a cross-disciplinary framework that aims to facilitate the development of NLP- based adaptive measures for supporting peer-feedback processes in digital learning environments. To conceptualize this process, we introduce a peer-feedback process model, which describes learners' activities and textual products. Further, we introduce a terminological and procedural scheme that facilitates systematically deriving measures to foster the peer-feedback process and how NLP may enhance the adaptivity of such learning support. Building on prior research on education and NLP, we apply this scheme to all learner activities of the peer-feedback process model to exemplify a range of NLP- based adaptive support measures. We also discuss the current challenges and suggest directions for future cross-disciplinary research on the effectiveness and other dimensions of NLP-based adaptive support for peer-feedback. Building on our suggested framework, future research and collaborations at the intersection of education and NLP can innovate peer-feedback in digital learning environments.
235	Understanding EFL students ' use of self-made AI chatbots as personalized writing assistance tools: A mixed methods study Artificial intelligence; Chatbots; Retrieval augmented generation; EFL writing; Personalized learning This study aimed to explore English as a foreign language (EFL) students' use of self-made retrieval augmented generation (RAG) chatbots to enhance their learning to write. In the study, 69 Chinese undergraduate students participated in a workshop focused on creating chatbots, using Poe, that can assist with their writing processes. Multiple data sources were collected, including chatbots built by students, essays students wrote using their chatbots, students' responses to pre- and post-workshop questionnaires, and written reflections. The findings revealed that students developed chatbots for various purposes, such as assisting with idea generation, producing writing outlines, and identifying grammatical and spelling errors. Students made various requests, including assistance, customization, and translation, during their interactions with chatbots. Moreover, the use of self-made chatbots had a positive impact on students' writing motivation. It resulted in clearer writing goals, increased writing confidence, reinforced writing beliefs, and a more positive attitude towards writing. This study contributes to a deeper understanding of chatbots as pedagogical tools that enhance personalized language learning for students. By leveraging self-made chatbots, students can receive tailored support for their specific writing needs, leading to improved motivation.
236	Fostering Engagement in AI-Mediate Chinese EFL Classrooms: The Role of Classroom Climate, AI Literacy, and Resilience AI-assisted classrooms; AI literacy; classroom climate; engagement; resilience The rise of artificial intelligence (AI) has significantly impacted education, yet few scholars have explored AI-assisted classrooms, particularly in language education in China. Understanding the roles of classroom climate, AI literacy, and resilience is essential, as these factors foster positive learning environments and enhance student engagement. In this sense, this study, grounded in Social Cognitive Theory, employs structural equation modelling to investigate factors influencing classroom engagement in AI-assisted Chinese English as a Foreign Language (EFL) classrooms. It examines data from 606 university EFL learners to explore the interactions among these variables and the mediating role of resilience. The findings indicate that classroom climate, AI literacy, and resilience all significantly predict classroom engagement, highlighting the importance of both environmental and cognitive factors in fostering active student participation. Furthermore, resilience serves as a crucial mediator, linking classroom climate and AI literacy to engagement. This study provides some insights for educators and policymakers, emphasising the need to cultivate supportive classroom environments, promote AI literacy programs, and strengthen students' resilience to optimise engagement in AI-assisted educational settings.
237	Impacts of an AI-based chabot on college students' after-class review, academic performance, self-efficacy, learning attitude, and motivation Mobile application; Chatbot; Artificial intelligence; After-class review; Public health courses Review strategies after learning new knowledge are essential for students to consolidate the key points, understand the subject content, analyze aspects of the learning topics, and summarize the knowledge content of learning while mastering new knowledge. However, educators have found that students generally have difficulties seeking help when they encounter learning problems. This could significantly affect their after-class review performances. To cope with this problem, an after-class review approach with an AI (Artificial Intelligence)-based chatbot is proposed in this study to provide students with immediate and quality feedback during the learning process. Moreover, a quasi-experiment was conducted to explore students' learning motivation, attitude, and academic performance when using the AI-based chatbot. Participants were two classes of students from a university in Taiwan. One class with 18 students was the experimental group and the other with 20 students was the control group. The experimental group used the AI-based chatbot in the after-class review, while the control group used the conventional after-class review approach. Research results showed that the application of AI-based chatbots in the review process of public health courses could improve students' academic performance, self-efficacy, learning attitude, and motivation. In other words, chatbots could help students become more active in the learning process. It is noted that after students asked questions, providing them with sufficient feedback during the review process could make them feel recognized and help to establish a relaxing and friendly interaction, thereby improving their academic performance.
238	A meta systematic review of artificial intelligence in higher education: a call for increased ethics, collaboration, and rigour Artificial Intelligence; AIEd; AI; Evidence synthesis; Tertiary review; Research methods; Quality assessment; Intelligent tutoring systems; Adaptive systems; Prediction; Personalisation; Automatic assessment Although the field of Artificial Intelligence in Education (AIEd) has a substantial history as a research domain, never before has the rapid evolution of AI applications in education sparked such prominent public discourse. Given the already rapidly growing AIEd literature base in higher education, now is the time to ensure that the field has a solid research and conceptual grounding. This review of reviews is the first comprehensive meta review to explore the scope and nature of AIEd in higher education (AIHEd) research, by synthesising secondary research (e.g., systematic reviews), indexed in the Web of Science, Scopus, ERIC, EBSCOHost, IEEE Xplore, ScienceDirect and ACM Digital Library, or captured through snowballing in OpenAlex, ResearchGate and Google Scholar. Reviews were included if they synthesised applications of AI solely in formal higher or continuing education, were published in English between 2018 and July 2023, were journal articles or full conference papers, and if they had a method section 66 publications were included for data extraction and synthesis in EPPI Reviewer, which were predominantly systematic reviews (66.7%), published by authors from North America (27.3%), conducted in teams (89.4%) in mostly domestic-only collaborations (71.2%). Findings show that these reviews mostly focused on AIHEd generally (47.0%) or Profiling and Prediction (28.8%) as thematic foci, however key findings indicated a predominance of the use of Adaptive Systems and Personalisation in higher education. Research gaps identified suggest a need for greater ethical, methodological, and contextual considerations within future research, alongside interdisciplinary approaches to AIHEd application. Suggestions are provided to guide future primary and secondary research.
239	From Technology-Challenged Teachers to Empowered Digitalized Citizens: Exploring the Profiles and Antecedents of Teacher AI Literacy in the Chinese EFL Context Chinese EFL context; latent profile analysis; mixed-methodology; teacher AI literacy Artificial Intelligence (AI) literacy has come to the spotlight, empowering individuals to adeptly navigate the modern digitalised world. However, studies on teacher AI literacy in the English as a Foreign Language (EFL) context remain limited. This study aims to identify intraindividual differences in AI literacy and examine its associations with age and years of teaching experience among 782 English teachers. Given the absence of a reliable instrument to measure teacher AI literacy, we first constructed and validated a scale encompassing five sub-scales: AI Knowledge, AI Use, AI Assessment, AI Design, and AI Ethics. Subsequently, latent profile analysis (LPA) was conducted using Mplus 7.4, with the results revealing four distinct profiles: Poor AI literacy (C1: 12.1%), Moderate AI literacy (C2: 45.5%), Good AI literacy (C3: 28.4%), and Excellent AI literacy (C4: 14.1%). Multinomial logistic regression analyses indicated significant associations between teacher AI literacy and both age and years of teaching experience. Additionally, 32 respondents participated in semi-structured interviews. The qualitative data analysed with MAXQDA 2022 triangulated the quantitative results and offered deeper insights into teachers' perceptions of their AI literacy. This study provides both theoretical and practical implications for understanding teacher AI literacy in the Chinese EFL context.
240	A systematic review of the impact of artificial intelligence on educational outcomes in health professions education Artificial intelligence; Health professions; AI-based training and assessment; Learning theories and principles; Educational outcomes BackgroundArtificial intelligence (AI) has a variety of potential applications in health professions education and assessment; however, measurable educational impacts of AI-based educational strategies on learning outcomes have not been systematically evaluated.MethodsA systematic literature search was conducted using electronic databases (CINAHL Plus, EMBASE, Proquest, Pubmed, Cochrane Library, and Web of Science) to identify studies published until October 1st 2024, analyzing the impact of AI-based tools/interventions in health profession assessment and/or training on educational outcomes. The present analysis follows the PRISMA 2020 statement for systematic reviews and the structured approach to reporting in health care education for evidence synthesis.ResultsThe final analysis included twelve studies. All were single centers with sample sizes ranging from 4 to 180 participants. Three studies were randomized controlled trials, and seven had a quasi-experimental design. Two studies were observational. The studies had a heterogenous design. Confounding variables were not controlled. None of the studies provided learning objectives or descriptions of the competencies to be achieved. Three studies applied learning theories in the development of AI-powered educational strategies. One study reported the analysis of the authenticity of the learning environment. No study provided information on the impact of feedback activities on learning outcomes. All studies corresponded to Kirkpatrick's second level evaluating technical skills or quantifiable knowledge. No study evaluated more complex tasks, such as the behavior of learners in the workplace. There was insufficient information on training datasets and copyright issues.ConclusionsThe results of the analysis show that the current evidence regarding measurable educational outcomes of AI-powered interventions in health professions education is poor. Further studies with a rigorous methodological approach are needed. The present work also highlights that there is no straightforward guide for evaluating the quality of research in AI-based education and suggests a series of criteria that should be considered.Trial registrationMethods and inclusion criteria were defined in advance, specified in a protocol and registered in the OSF registries (https://osf.io/v5cgp/). Clinical Trial number: not applicable.
241	A systematic review of AI-based automated written feedback research artificial intelligence (AI); automated written feedback (AWF); systematic review; argument-based validity In recent years, automated written feedback (AWF) has gained popularity in language learning and teaching as a form of artificial intelligence (AI). The present study aimed at providing a comprehensive state-of-the-art review of AWF. Using Scopus as the main database, we identified 83 SSCI-indexed published articles on AWF (1993-2022). We investigated several main domains consisting of research contexts, AWF systems, feedback focus, ways of utilizing AWF, research design, foci of investigation, and results. Our results showed that although AWF was primarily studied in language and writing classes at the tertiary level, with a focus on English as the target language, the scope of AWF research has been steadily broadening to include diverse language environments and ecological settings. This heterogeneity was also demonstrated by the wide range of AWF systems employed (n = 31), ways of integrating AWF (n = 14), different types of AWF examined (n = 3), as well as varied research designs. In addition, three main foci of investigation were delineated: (1) the performance of AWF; (2) perceptions, uses, engagement with AWF, and influencing factors; and (3) the impact of AWF. We identified positive, negative, neutral, and mixed results in all three main foci of investigation. Overall, less positive results were found in validating AWF compared to results favoring the other two areas. Lastly, we grounded our findings within the argument-based validity framework and also examined the potential implications.
242	Learning design to support student-AI collaboration: perspectives of leading teachers for AI in education AI in education; Student-AI collaboration; Distributed cognition; Learning design Preparing students to collaborate with AI remains a challenging goal. As AI technologies are new to K-12 schools, there is a lack of studies that inform how to design learning when AI is introduced as a collaborative learning agent to classrooms. The present study, therefore, aimed to explore teachers' perspectives on what (1) curriculum design, (2) student-AI interaction, and (3) learning environments are required to design student-AI collaboration (SAC) in learning and (4) how SAC would evolve. Through in-depth interviews with 10 Korean leading teachers in AI in Education (AIED), the study found that teachers perceived capacity and subject-matter knowledge building as the optimal learning goals for SAC. SAC can be facilitated through interdisciplinary learning, authentic problem solving, and creative tasks in tandem with process-oriented assessment and collaboration performance assessment. While teachers expressed instruction on AI principles, data literacy, error analysis, AI ethics, and AI experiences in daily life were crucial support, AI needs to offer an instructional scaffolding and possess attributes as a learning mate to enhance student-AI interaction. In addition, teachers highlighted systematic AIED policy, flexible school system, the culture of collaborative learning, and a safe to fail environment are significant. Teachers further anticipated students would develop collaboration with AI through three stages: (1) learn about AI, (2) learn from AI, and (3) learn together. These findings can provide a more holistic understanding of the AIED and implications for the educational policies, educational AI design as well as instructional design that are aimed at enhancing SAC in learning.
243	Artificial intelligence in medical education: a cross-sectional needs assessment Artificial intelligence; Healthcare; Medical curriculum; Medical ethics; Medical students; Medicine Background As the information age wanes, enabling the prevalence of the artificial intelligence age; expectations, responsibilities, and job definitions need to be redefined for those who provide services in healthcare. This study examined the perceptions of future physicians on the possible influences of artificial intelligence on medicine, and to determine the needs that might be helpful for curriculum restructuring. Methods A cross-sectional multi-centre study was conducted among medical students country-wide, where 3018 medical students participated. The instrument of the study was an online survey that was designed and distributed via a web-based service. Results Most of the medical students perceived artificial intelligence as an assistive technology that could facilitate physicians' access to information (85.8%) and patients to healthcare (76.7%), and reduce errors (70.5%). However, half of the participants were worried about the possible reduction in the services of physicians, which could lead to unemployment (44.9%). Furthermore, it was agreed that using artificial intelligence in medicine could devalue the medical profession (58.6%), damage trust (45.5%), and negatively affect patient-physician relationships (42.7%). Moreover, nearly half of the participants affirmed that they could protect their professional confidentiality when using artificial intelligence applications (44.7%); whereas, 16.1% argued that artificial intelligence in medicine might cause violations of professional confidentiality. Of all the participants, only 6.0% stated that they were competent enough to inform patients about the features and risks of artificial intelligence. They further expressed that their educational gaps regarding their need for "knowledge and skills related to artificial intelligence applications" (96.2%), "applications for reducing medical errors" (95.8%), and "training to prevent and solve ethical problems that might arise as a result of using artificial intelligence applications" (93.8%). Conclusions The participants expressed a need for an update on the medical curriculum, according to necessities in transforming healthcare driven by artificial intelligence. The update should revolve around equipping future physicians with the knowledge and skills to effectively use artificial intelligence applications and ensure that professional values and rights are protected.
244	Ethical principles for artificial intelligence in education Artificial Intelligence; AIED; Ethics; Policies; Privacy The advancement of artificial intelligence in education (AIED) has the potential to transform the educational landscape and influence the role of all involved stakeholders. In recent years, the applications of AIED have been gradually adopted to progress our understanding of students' learning and enhance learning performance and experience. However, the adoption of AIED has led to increasing ethical risks and concerns regarding several aspects such as personal data and learner autonomy. Despite the recent announcement of guidelines for ethical and trustworthy AIED, the debate revolves around the key principles underpinning ethical AIED. This paper aims to explore whether there is a global consensus on ethical AIED by mapping and analyzing international organizations' current policies and guidelines. In this paper, we first introduce the opportunities offered by AI in education and potential ethical issues. Then, thematic analysis was conducted to conceptualize and establish a set of ethical principles by examining and synthesizing relevant ethical policies and guidelines for AIED. We discuss each principle and associated implications for relevant educational stakeholders, including students, teachers, technology developers, policymakers, and institutional decision-makers. The proposed set of ethical principles is expected to serve as a framework to inform and guide educational stakeholders in the development and deployment of ethical and trustworthy AIED as well as catalyze future development of related impact studies in the field.
245	Teachers' trust in AI-powered educational technology and a professional development program to improve it  Evidence from various domains underlines the critical role that human factors, and especially trust, play in adopting technology by practitioners. In the case of Artificial Intelligence (AI) powered tools, the issue is even more complex due to practitioners' AI-specific misconceptions, myths and fears (e.g., mass unemployment and privacy violations). In recent years, AI has been incorporated increasingly into K-12 education. However, little research has been conducted on the trust and attitudes of K-12 teachers towards the use and adoption of AI-powered Educational Technology (AI-EdTech). This paper sheds light on teachers' trust in AI-EdTech and presents effective professional development strategies to increase teachers' trust and willingness to apply AI-EdTech in their classrooms. Our experiments with K-12 science teachers were conducted around their interactions with a specific AI-powered assessment tool (termed AI-Grader) using both synthetic and real data. The results indicate that presenting teachers with some explanations of (i) how AI makes decisions, particularly compared to the human experts, and (ii) how AI can complement and give additional strengths to teachers, rather than replacing them, can reduce teachers' concerns and improve their trust in AI-EdTech. The contribution of this research is threefold. First, it emphasizes the importance of increasing teachers' theoretical and practical knowledge about AI in educational settings to gain their trust in AI-EdTech in K-12 education. Second, it presents a teacher professional development program (PDP), as well as the discourse analysis of teachers who completed it. Third, based on the results observed, it presents clear suggestions for future PDPs aiming to improve teachers' trust in AI-EdTech.
246	Understanding the impact of knowledge management factors on the sustainable use of AI-based chatbots for educational purposes using a hybrid SEM-ANN approach Artificial intelligence; chatbots; conversational agents; sustainability; education; artificial neural network Artificial intelligence (AI)-based chatbots have received considerable attention during the last few years. However, little is known concerning what affects their use for educational purposes. This research, therefore, develops a theoretical model based on extracting constructs from the expectation confirmation model (ECM) (expectation confirmation, perceived usefulness, and satisfaction), combined with the knowledge management (KM) factors (knowledge sharing, knowledge acquisition, and knowledge application) to understand the sustainable use of chatbots. The developed model was then tested based on data collected through an online survey from 448 university students who used chatbots for learning purposes. Contrary to the prior literature that mainly relied on structural equation modeling (SEM) techniques, the empirical data were analyzed using a hybrid SEM-artificial neural network (SEM-ANN) approach. The hypotheses testing results reinforced all the suggested hypotheses in the developed model. The sensitivity analysis results revealed that knowledge application has the most considerable effect on the sustainable use of chatbots with 96.9% normalized importance, followed by perceived usefulness (70.7%), knowledge acquisition (69.3%), satisfaction (61%), and knowledge sharing (19.6%). Deriving from these results, the study highlighted a number of practical implications that benefit developers, designers, service providers, and instructors.
247	Examining Chinese preservice mathematics teachers' adoption of AI chatbots for learning: Unpacking perspectives through the UTAUT2 model AI chatbots; ChatGPT; Preservice mathematics teacher; Ernie bot; Behavioral intention Integrating AI Chatbots into teaching and learning activities is a growing trend, and understanding the readiness of preservice mathematics teachers to use AI Chatbots is crucial for successful implementation in educational settings. This study examines the factors influencing the adoption of AI Chatbots by preservice mathematics teachers in China, employing the UTAUT2 model and Structural Equation Modeling (SEM) to analyze data from 322 participants. This study's findings reveal that preservice mathematics teachers have unique characteristics where performance expectancy (PE) is the single factor that significantly influences their behavioral intention (BI) to use AI Chatbots. This underscores the importance of fostering a high-performance expectancy, which, in turn, influences their likelihood to utilize AI Chatbots with enthusiasm, thereby translating into positive usage behavior. These insights bear significant implications for educators, highlighting the need to underscore the practical benefits of AI Chatbots and conduct workshops on effective utilization strategies to enhance teaching and learning performance in mathematics, thereby fostering personalized and engaging learning experiences.
248	AI literacy in K-12: a systematic literature review Secondary education; Teaching; learning strategies; Twenty-first century skills; Cultural and social implications The successful irruption of AI-based technology in our daily lives has led to a growing educational, social, and political interest in training citizens in AI. Education systems now need to train students at the K-12 level to live in a society where they must interact with AI. Thus, AI literacy is a pedagogical and cognitive challenge at the K-12 level. This study aimed to understand how AI is being integrated into K-12 education worldwide. We conducted a search process following the systematic literature review method using Scopus. 179 documents were reviewed, and two broad groups of AI literacy approaches were identified, namely learning experience and theoretical perspective. The first group covered experiences in learning technical, conceptual and applied skills in a particular domain of interest. The second group revealed that significant efforts are being made to design models that frame AI literacy proposals. There were hardly any experiences that assessed whether students understood AI concepts after the learning experience. Little attention has been paid to the undesirable consequences of an indiscriminate and insufficiently thought-out application of AI. A competency framework is required to guide the didactic proposals designed by educational institutions and define a curriculum reflecting the sequence and academic continuity, which should be modular, personalized and adjusted to the conditions of the schools. Finally, AI literacy can be leveraged to enhance the learning of disciplinary core subjects by integrating AI into the teaching process of those subjects, provided the curriculum is co-designed with teachers.
249	Leading teachers' perspective on teacher-AI collaboration in education AI in education; Teacher-AI collaboration; teaching with AI; teacher in the loop Moving beyond the direct support all alone by a human teacher or an Artificial Intelligence (AI) system, optimizing the complementary strengths of the two has aroused great expectations and educational innovation potential. Yet, the conceptual guidance of how best to structure and implement teacher-AI collaboration (TAC) while ensuring teachers' instructional roles to support students learning remains limited. This study, therefore, aims what (1) curriculum, (2) teacher-AI interaction, (3) learning environment would be required as well as how TAC would evolve by reflecting teachers' views. Through in-depth interviews with 20 Chinese leading teachers in AI in Education (AIED), the study found that teachers aimed to improve students' subject-matter knowledge and build their capacity as the desired goals for TAC and these can be carried out by data-driven problem-based learning and case-based reasoning in tandem with growth-focused and reflective assessment. While teachers highlighted that developing teachers' data literacy and collegiality with AI are essential, they expected AI to be equipped with Technological Pedagogical and Content Knowledge (TPACK) knowledge and conflict resolution skills. In addition, teachers expressed that Internet of Things (IoT)-based classrooms, systematic AIED curriculum, school-based continuing professional development, research-practice-policy partnerships as well as creating a continuous learning and AI-ready culture are significant. Furthermore, teachers envision TAC would develop into three stages: (1) teachers as passive AI recipients, (2) teachers as active AI users (3) teachers-AI as constructive partners. These findings build a more holistic and in-depth understanding of the AIED and offer implications for the educational AI design and teachers' education.
250	Can AI Empower L2 Education? Exploring Its Influence on the Behavioural, Cognitive and Emotional Engagement of EFL Teachers and Language Learners AI empowerment; EFL teachers; L2 education; language learners Artificial intelligence (AI) is transforming L2 education, yet its specific impacts on English as a foreign language (EFL) teachers and language learners' engagement remain understudied. To address this deficiency, this study, grounded in Fredricks, Blumenfeld, and Paris's (Review of Educational Research, 74, 109) three-dimensional engagement model, explored the impacts of AI on the behavioural, cognitive and emotional engagement of EFL teachers and language learners through semi-structured interviews with 24 EFL teachers and 38 college language learners, followed by a thematic analysis with MAXQDA to uncover the effectiveness of AI. The study found that behavioural engagement showcased the integration of AI tools, highlighting increased frequency of use and their practical applications in enhancing language acquisition tasks. Cognitive engagement was marked by the recognition of AI capacity to augment teaching strategies and learning processes, although it also surfaced concerns about the potential overreliance on technology. Emotional engagement reflected a complex interplay of attitudes, with most informants viewing AI positively but acknowledging concerns about job displacement, and its impacts on emotions of students and teachers as well as the relations between them. The study concluded that while AI held promise for L2 education, the integration must consider its limitations and ethical implications. The research provided valuable insights for educators, learners, technology developers and policymakers, encouraging innovative practices and informed decision-making in L2 education.
251	'Where's the line? It's an absurd line': towards a framework for acceptable uses of AI in assessment Academic integrity; artificial intelligence; assessment design; higher education As higher education grapples with ensuring assessment validity in an increasingly AI-populated time, institutions and educators are working to establish appropriate boundaries for AI use. However, little is known about how students and teachers conceptualize and experience these boundaries in practice. This study investigates how students and teachers navigate the line between acceptable and unacceptable AI use in assessment, drawing on a thematic analysis of qualitative interviews with 19 students and 12 staff at a large Australian university informed by social boundary theory. The titular metaphor of 'drawing a line' emerged organically from both students and staff in our interviews, revealing ongoing struggles to understand and articulate what counts as appropriate. We found that students frequently construct their own individually unique and often complex ethical frameworks for AI use. Teachers, meanwhile, report significant emotional burden and professional uncertainty as they attempt to understand and communicate what is appropriate to their students. Our analysis suggests that assessment policies for AI ought to move beyond simple prohibitions or permissions and begin to address three critical dimensions: the feasibility of enforcement, the preservation of authentic learning, and the emotional wellbeing of teachers and students.
252	Academic communication with AI-powered language tools in higher education: From a post-humanist perspective Artificial intelligence (AI); AI-Powered language tools; Post-humanism; Academic communication; Higher education; AI chatbot AI -powered language tools (AILTs) are commonly used by university students, yet there is a limited understanding of how students utilise and perceive these tools in everyday academic communication practice. Employing a post -humanist lens and based on over 1700 open-ended comments from a nationwide student survey, this qualitative study examined students' lived AILT experiences to explicate the impact of AILTs on academic communication in higher education learning and assessment. Thematic analysis of the data shows that students' academic writing is realised by assemblages of distributed spatial and personal linguistic repertoires, underscoring AILT's role in enhancing students' communicative performance and personal language development. AILTs are also conducive to transforming the academic writing process into an additional learning space. Students have developed a new identity as spatially advised learners, enabling them to assert their agency in terms of language development and subjectcontent knowledge while also holding critical perspectives on the limitations of AI. Furthermore, the findings point to divergent and eclectic student viewpoints on the ethical concerns of AILTs in assessment in the absence of university instructions. The study discusses implications for university policymaking and pedagogy in developing teaching and assessment methods that match students' stances and needs in AI -mediated academic communication.
253	Systematic review of research on artificial intelligence applications in higher education - where are the educators? Artificial intelligence; Higher education; Machine learning; Intelligent tutoring systems; Systematic review According to various international reports, Artificial Intelligence in Education (AIEd) is one of the currently emerging fields in educational technology. Whilst it has been around for about 30 years, it is still unclear for educators how to make pedagogical advantage of it on a broader scale, and how it can actually impact meaningfully on teaching and learning in higher education. This paper seeks to provide an overview of research on AI applications in higher education through a systematic review. Out of 2656 initially identified publications for the period between 2007 and 2018, 146 articles were included for final synthesis, according to explicit inclusion and exclusion criteria. The descriptive results show that most of the disciplines involved in AIEd papers come from Computer Science and STEM, and that quantitative methods were the most frequently used in empirical studies. The synthesis of results presents four areas of AIEd applications in academic support services, and institutional and administrative services: 1. profiling and prediction, 2. assessment and evaluation, 3. adaptive systems and personalisation, and 4. intelligent tutoring systems. The conclusions reflect on the almost lack of critical reflection of challenges and risks of AIEd, the weak connection to theoretical pedagogical perspectives, and the need for further exploration of ethical and educational approaches in the application of AIEd in higher education.
254	A review of AI teaching and learning from 2000 to 2020 AI teaching and learning; AI literacy; Pedagogy; Teaching tools; Systematic review In recent years, with the popularity of AI technologies in our everyday life, researchers have begun to discuss an emerging term "AI literacy". However, there is a lack of review to understand how AI teaching and learning (AITL) research looks like over the past two decades to provide the research basis for AI literacy education. To summarize the empirical findings from the literature, this systematic literature review conducts a thematic and content analysis of 49 publications from 2000 to 2020 to pave the way for recent AI literacy education. The related pedagogical models, teaching tools and challenges identified help set the stage for today's AI literacy. The results show that AITL focused more on computer science education at the university level before 2021. Teaching AI had not become popular in K-12 classrooms at that time due to a lack of age-appropriate teaching tools for scaffolding support. However, the pedagogies learnt from the review are valuable for educators to reflect how they should develop students' AI literacy today. Educators have adopted collaborative project-based learning approaches, featuring activities like software development, problem-solving, tinkering with robots, and using game elements. However, most of the activities require programming prerequisites and are not ready to scaffold students' AI understandings. With suitable teaching tools and pedagogical support in recent years, teaching AI shifts from technology-oriented to interdisciplinary design. Moreover, global initiatives have started to include AI literacy in the latest educational standards and strategic initiatives. These findings provide a research foundation to inform educators and researchers the growth of AI literacy education that can help them to design pedagogical strategies and curricula that use suitable technologies to better prepare students to become responsible educated citizens for today's growing AI economy.
255	Artificial intelligence in EFL speaking: Impact on enjoyment, anxiety, and willingness to communicate Positive psychology; AI -Speaking assistant; Foreign language enjoyment; Foreign language anxiety; Willingness to communicate Drawing on Positive Psychology, this quasi-experimental study investigated the influence of an AI-speaking assistant, Lora, on Chinese EFL students' foreign language enjoyment (FLE), foreign language anxiety (FLA), and willingness to communicate (WTC) in English. To this end, 131 Chinese EFL university students participated in this study and were placed into the experimental group (EG, n = 65) and control group (CG, n = 66) respectively. Both groups completed pre- and post-intervention surveys before and after a six-week intervention. Results showed significant enhancements in FLE and WTC, accompanied by a noteworthy reduction in FLA among the EG. In contrast, the CG exhibited no significant changes in those variables. These findings highlight the positive role of AI-speaking assistants in enhancing EFL students' FLE and WTC while mitigating FLA. The study concludes with implications for teachers and teacher educators, calling for the integration of AI-driven technologies, the creation of diverse language-learning opportunities, and the application of AI features to foster a supportive classroom environment. Such efforts aim to increase students' language enjoyment, confidence, and English communication willingness, aligning with the principles of Positive Psychology.
256	Fostering students' AI literacy development through educational games: AI knowledge, affective and cognitive engagement AI literacy; gamification; pedagogy; secondary education Background: As the significance of artificial intelligence (AI) continues to increase, there is a need for effective scaffolding and support for novice learners. Educators have encountered challenges in effectively scaffolding novice learners AI concepts, and providing appropriate motivational support. Research evidence has shown the potential of game-based approaches to fostering secondary school students' AI literacy and motivation to learn AI. Objectives: This study developed an online platform TreasureIsland to gamify ebooks and investigated whether and how students playing with it can effectively enhance their AI literacy. This study aims to contribute an empirical and theoretical basis for AI literacy education and promote the use of gamification that would be broadly applied in other schools. Methods: A quasi-experiment was conducted to evaluate the effects of the proposed gamified approach, which included a control group using an ebook with playful resources. To triangulate the quantitative results obtained from the pre and post-test, focus group interviews were also conducted. Results: The platform was effective in improving students' motivation, self-efficacy, career interest, and understanding of AI concepts and ethics, but did not enhance their confidence of using AI, and high cognition of applying, evaluating and creating AI. TreasureIsland players demonstrated significant improvement in all affective and cognitive domains, except for the ability to apply, evaluate, and create AI. Interviews revealed that the gamified approach could promote students' AI literacy by adhering to guidelines, including (1) creating a competitive and motivating learning environment through game mechanics, (2) providing scaffolding modules and feedback, and (3) visualising complex AI concepts via simulations. Feedback collected from the study suggested adding pedagogical elements such as flipped classrooms and project-based learning in future research to improve the instructional design, and enable students to reach a higher level of cognition. Conclusions: This study concludes that the use of gamification can provide affective and cognitive support and an enjoyable experience for fostering learners' AI literacy. It helps instructional designers and teachers enrich the pedagogical knowledge related to gamified platform and AI literacy.
257	How implementing an AI chatbot impacts Korean as a foreign language learners' willingness to communicate in Korean Willingness to communicate; AI chatbot; Korean as a foreign language; Second language learning chatbot This study examined the influence of artificial intelligence (AI) chatbots on the willingness to communicate (WTC) of Korean as a foreign language learners. In total, 65 students participated in a semester-long study. Classes were randomly assigned to an experimental group (n = 20) or a control group (n = 45). As part of their language learning, the experimental group engaged in communicative activities with an AI chatbot eight times in class, while the control group engaged in conventional communicative activities. Data collection involved administering the WTC questionnaire. Additionally, the experimental group voluntarily participated in semi-structured interviews. An independent sample t-test revealed no statistically significant difference in WTC levels between the two groups at the beginning of the semester (t(63) = -0.016, p = .987). However, the ANCOVA conducted after eight intervention sessions demonstrated significant improvements in WTC, reduced anxiety levels, and enhanced communication confidence among students in the experimental group (F(1, 62) = 393.740, p = .000). Analyses of the interviews revealed that students experienced decreased anxiety, enhancing their WTC in Korean. These findings suggested that chatbot-mediated interactions created a learner-friendly learning environment wherein learners displayed higher-level engagement and, consequently, an enhanced WTC in Korean.
258	ChatGPT in the higher education: A systematic literature review and research challenges ChatGPT; Higher education; Usage; Adoption; Intention; Acceptance and applications ChatGPT has gained significant attention in the higher education sector as it can be applied across a wide range of topics. Despite ChatGPT's versatility in offering support across various educational disciplines, it is still in its early stages and requires further exploration to be fully utilized effectively in education. This systematic literature review aims to explore the trends, adoption measures, diverse applications, and current limitations of ChatGPT research in higher education. This review systematically analyzed 57 research articles published between 2023 and 2024. This study identified trends in ChatGPT in higher education by providing temporal views, geographical locations, and research methods used. Furthermore, this study explored users' intention to adopt and use ChatGPT in higher education by focusing on post-adoption, intention to use, and acceptance stages. Considering the extensive advantages ChatGPT brings to the academic community, this review explores its diverse applications in educational settings for academic staff, students, researchers, and non-academic users. Finally, this study outlined the current limitations in ChatGPT research within higher education and proposed future research directions, aiming for continuous improvement in the field. This study can benefit higher education by providing valuable insights into the effective utilization of ChatGPT.
259	Can ChatGPT effectively complement teacher assessment of undergraduate students' academic writing? ChatGPT; teacher assessment; academic writing The integration of ChatGPT as a supplementary tool for writing instruction has gained traction. However, uncertainties persist regarding how ChatGPT complements teacher assessment and the overall effectiveness of this combined approach. To address this, we conducted a mixed-methods investigation involving 46 undergraduate students from a research university in southern China, engaging them in a Chinese academic writing task. The intraclass correlation coefficient results revealed ChatGPT's efficiency in scoring students' writing, showing moderate to good consistency with teacher evaluations. A paired sample t-test unveiled significant differences in feedback quantity and types between ChatGPT and teacher assessments. Drawing from both interview data and quantitative findings, the study uncovers three ways in which ChatGPT complements teacher assessment, benefiting students with various writing proficiency levels: (1) fostering deeper comprehension of teacher assessments among students, (2) encouraging students to make judgments regarding feedback, and (3) promoting independent thinking about revisions. This study contributes to a more comprehensive understanding of the role of ChatGPT within the context of a combined assessment approach. It underscores that certain inherent weaknesses in ChatGPT's functioning can paradoxically lead to favorable outcomes. By shedding light on the synergy between ChatGPT and teacher assessments, this research seeks to inform and enhance writing instruction in higher education.
260	Exploratory study on the potential of ChatGPT as a rater of second language writing Automated writing evaluation; ChatGPT; Many-faceted Rasch model; Rater evaluation In recent years, various strategies have been employed to integrate ChatGPT into the field of second language (L2) teaching and learning. In line with such efforts, this study investigates the potential of ChatGPT as an automated writing evaluation (AWE) tool for L2 assessment, given the lack of systematic and quantitative investigation into human ratings and GPT-based scoring chatbot's ratings. We took an innovative approach by utilising ChatGPT's new feature called 'My GPTs', which is a customised chatbot builder based on GPT-4. The dataset for assessment consisted of 50 English essays written by Korean secondary-level EFL students, which were rated by the developed GPT-based scoring chatbot and two in-service English teachers. The intraclass correlation coefficient results suggested a strong similarity between human rater and ChatGPT scores. However, those based on the multifaceted Rasch model further revealed that ChatGPT showed a slightly greater deviation from the model than its human counterparts. This study demonstrates the potential of ChatGPT in AWE, providing an accessible and supplementary tool to L2 teachers' ratings.
261	Investigating student acceptance of an academic advising chatbot in higher education institutions Academic advising; Conversational Agent; Higher Education Institution; Artificial Intelligence; Technology Acceptance The study explores factors affecting university students' behavioural intentions in adopting an academic advising chatbot. The study focuses on functional, socio-emotional, and relational factors affecting students' acceptance of an AI-driven academic advising chatbot. The research is based on a conceptual model derived from several constructs of traditional technology acceptance models, TAM, UTAUT, the latest AI-driven self-service technologies models, the Service Robot Acceptance (sRAM) model, and the intrinsic motivation Self Determination Theory (SDT) model. The proposed conceptual model has been tailored to an educational context. A questionnaire Survey of Non-purposive sampling technique was applied to collect data points from 207 university students from two major universities in the UAE. Subsequently, PLS-SEM causal modelling was applied for hypothesis testing. The results revealed that the functional elements, perceived ease of use and social influence significantly affect behavioural intention for chatbots' acceptance. However, perceived usefulness, autonomy, and trust did not show significant evidence of influence on the acceptance of an advising chatbot. The study reviews chatbot literature and presents recommendations for educational institutions to implement AI-driven chatbots effectively for academic advising. It is one of the first studies that assesses and examines factors that impact the willingness of higher education students to accept AI-driven academic advising chatbots. This study presents several theoretical contributions and practical implications for successful deployment of service-oriented chatbots for academic advising in the educational sector.
262	The impact of a virtual teaching assistant (chatbot) on students' learning in Ghanaian higher education Zero-coding chatbot; Virtual teaching assistants; Student-instructor interaction; Ghanaian higher education; Artificial intelligence Chatbot usage is evolving rapidly in various fields, including higher education. The present study's purpose is to discuss the effect of a virtual teaching assistant (chatbot) that automatically responds to a student's question. A pretest-posttest design was implemented, with the 68 participating undergraduate students being randomly allocated to scenarios representing a 2 x 2 design (experimental and control cohorts). Data was garnered utilizing an academic achievement test and focus groups, which allowed more in depth analysis of the students' experience with the chatbot. The results of the study demonstrated that the students who interacted with the chatbot performed better academically comparing to those who interacted with the course instructor. Besides, the focus group data garnered from the experimental cohort illustrated that they were confident about the chatbot's integration into the course. The present study essentially focused on the learning of the experimental cohort and their view regarding interaction with the chatbot. This study contributes the emerging artificial intelligence (AI) chatbot literature to improve student academic performance. To our knowledge, this is the first study in Ghana to integrate a chatbot to engage undergraduate students. This study provides critical information on the use and development of virtual teaching assistants using a zero-coding technique, which is the most suitable approach for organizations with limited financial and human resources.
263	Teaching EFL students to write with ChatGPT: Students' motivation to learn, cognitive load, and satisfaction with the learning process ChatGPT; Cognitive load; English as a foreign language (EFL); Prompt engineering; Student motivation; Student perceptions This mixed methods study explores EFL students' experiences and perceptions as they learn to write a composition with ChatGPT's support in a classroom instructional context. Students' perceptions are explored in terms of their motivation to learn about ChatGPT, cognitive load and satisfaction with the learning process. In a workshop format, twenty-one Hong Kong secondary school students were introduced to ChatGPT, learned prompt engineering skills, and attempted a 500-word English language writing task with ChatGPT's support. Data collected included a pre-workshop motivation questionnaire, think-aloud protocols during the writing task, and a post-workshop questionnaire on motivation, cognitive load, and satisfaction. Results revealed no significant difference in students' motivation before and after the workshop, but mean motivation scores increased slightly. Students reported high cognitive load during the writing task, especially during prompt engineering. However, students expressed high satisfaction with the workshop overall. Findings indicate ChatGPT's potential to engage EFL students in the writing classroom, but its use can impose heavy cognitive demands. To ensure that ChatGPT use supports EFL writing without overwhelming students, educators should consider an iterative design process for activities and instructional materials and carefully scaffolding instruction, especially for prompt engineering.
264	Comparing the effects of ChatGPT and automated writing evaluation on students' writing and ideal L2 writing self ChatGPT; automated writing evaluation (AWE) systems; ideal L2 writing self; feedback The affordances of ChatGPT in language learning and teaching have gained increasing traction. While studies began to investigate the potential of ChatGPT as a feedback provider, little attention was given to ChatGPT's potential impact on students' writing performance and the ideal L2 writing self vis-& agrave;-vis the established automated writing evaluation systems (AWE). To address these gaps, a sequential explanatory mixed methods design was adopted. One hundred and fifty second-year university students from three writing classes in a Chinese public university were recruited and randomly divided into a ChatGPT group, an AWE group, and a control group. After an eleven-week intervention, the ANCOVA results showed that while the ChatGPT group scored significantly higher than the AWE group and the control group in post-writing performance as measured by their writing score, in terms of students' ideal L2 writing self, the ChatGPT group performed significantly lower than the AWE group with a medium effect size. Qualitative analysis of students' reflection papers revealed students' (over)reliance on the tool and the accompanying loss of creativity and agency. Pedagogical implications as well as directions for future research are also discussed.
265	Collaborating with ChatGPT in argumentative writing classrooms Argumentative writing; ChatGPT; Chatbots Composing high-quality argumentative writing requires consideration of the dialogical, structural, and linguistic aspects of argumentation. However, finding an ideal peer student to practice argumentation skills can be challenging, and providing feedback on lower-level language concerns and complex issues related to content and organization can be time-consuming for teachers. In this article, we suggest the integration of ChatGPT, a chatbot released by OpenAI in 2022, into argumentative writing classrooms as a promising solution. The article explores the possibilities of ChatGPT in assisting students with tasks such as outline preparation, content revision, proofreading, and post-writing reflection. We also acknowledge the limitations of ChatGPT and offer suggestions for future considerations in teaching and research.
266	ChatGPT adoption and anxiety: a cross-country analysis utilising the unified theory of acceptance and use of technology (UTAUT) ChatGPT; UTAUT; higher education; structural equation modelling (SEM); anxiety The public release of ChatGPT in November 2022 brought excitement and concerns regarding students' use of language models in higher education. However, little research has empirically investigated students' intention to adopt ChatGPT. This study developed a theoretical model based on the Unified Theory of Acceptance and Use of Technology (UTAUT) with an additional construct- anxiety, to investigate university students' adoption intention of ChatGPT in two higher education contexts- the UK and Nepal. 239 and 226 questionnaires were deemed sufficient for data analysis for Nepal and the UK, respectively. We utilised the structural equation modelling technique to test the hypotheses. Our results reveal that performance expectancy, effort expectancy and social influence significantly impacted the adoption intention of ChatGPT for both countries. However, anxiety's impact varied between Nepal and the UK. Integrating UTAUT with a cross-country comparative approach provides insights into how ChatGPT's reception diverges between different higher education contexts. Our results also have implications for technology companies aiming to expand language models' availability worldwide.
267	The impact of educational chatbot on student learning experience Educational chatbot; Learning experience; Virtual tutor; Conversational agent; E-learning; Chatbot's usability Artificial Intelligence (AI) technologies have increasingly become vital in our everyday lives. Education is one of the most visible domains in which these technologies are being used. Conversational Agents (CAs) are among the most prominent AI systems for assisting teaching and learning processes. Their integration into an e-learning system can provide replies suited to each learner's specific needs, allowing them to study at their own pace. In this paper, based on recent advancements in Natural Language Processing (NLP) and deep learning techniques, we present an experimental implementation of an educational chatbot intended to instruct secondary school learners Logo, an educational programming language. The related chatbot was implemented and evaluated in Moroccan public schools with the support of teachers from the Regional Center for Education and Training Professions of Souss Massa. The experiments included 109 students grouped into three separate classes. One is a control class group that uses a traditional approach, while the other two are experimental groups that employ digital content and the chatbot-based method. Preliminary findings indicate that employing chatbots can greatly enhance student learning experiences by allowing them to study at their own speed with less stress, saving them time, and keeping them motivated. Furthermore, integrating these AI systems into a smart classroom will not only create a supportive environment by encouraging good interactions with students, it will also allow learners to be more engaged and achieve better academic objectives.
268	Empowering ChatGPT with guidance mechanism in blended learning: effect of self-regulated learning, higher-order thinking skills, and knowledge construction Higher education; Blended learning; Self-regulated learning; ChatGPT; Higher-order thinking skills; Knowledge construction In the evolving landscape of higher education, challenges such as the COVID-19 pandemic have underscored the necessity for innovative teaching methodologies. These challenges have catalyzed the integration of technology into education, particularly in blended learning environments, to bolster self-regulated learning (SRL) and higher-order thinking skills (HOTS). However, increased autonomy in blended learning can lead to learning disruptions if issues are not promptly addressed. In this context, OpenAI's ChatGPT, known for its extensive knowledge base and immediate feedback capability, emerges as a significant educational resource. Nonetheless, there are concerns that students might become excessively dependent on such tools, potentially hindering their development of HOTS. To address these concerns, this study introduces the Guidance-based ChatGPT-assisted Learning Aid (GCLA). This approach modifies the use of ChatGPT in educational settings by encouraging students to attempt problem-solving independently before seeking ChatGPT assistance. When engaged, the GCLA provides guidance through hints rather than direct answers, fostering an environment conducive to the development of SRL and HOTS. A randomized controlled trial (RCT) was employed to examine the impact of the GCLA compared to traditional ChatGPT use in a foundational chemistry course within a blended learning setting. This study involved 61 undergraduate students from a university in Taiwan. The findings reveal that the GCLA enhances SRL, HOTS, and knowledge construction compared to traditional ChatGPT use. These results directly align with the research objective to improve learning outcomes through providing guidance rather than answers by ChatGPT. In conclusion, the introduction of the GCLA has not only facilitated more effective learning experiences in blended learning environments but also ensured that students engage more actively in their educational journey. The implications of this study highlight the potential of ChatGPT-based tools in enhancing the quality of higher education, particularly in fostering essential skills such as self-regulation and HOTS. Furthermore, this research offers insights regarding the more effective use of ChatGPT in education.
269	Promoting Self-Regulation Progress and Knowledge Construction in Blended Learning via ChatGPT-Based Learning Aid blended learning; self-regulation progress; chatbot generalized pre-trained transformer (ChatGPT); knowledge construction This study combines ChatGPT, Apple's Shortcuts, and LINE to create the ChatGPT-based Intelligent Learning Aid (CILA), aiming to enhance self-regulation progress and knowledge construction in blended learning. CILA offers real-time, convergent information to learners' inquiries, as opposed to traditional Google search engine that provide divergent information. By addressing questions promptly, CILA minimizes interruptions during the performance phase of self-regulation progress. The tool records learners' questions and answers, aiding self-reflection in self-regulation progress. We evaluated self-regulation progress using motivation, engagement, and self-efficacy as indicators. Findings show that CILA's intervention effectively improves self-regulation progress and knowledge construction, offering benefits over divergent information in blended learning contexts with respect to amotivation, intrinsic motivation, and behavioral engagement. This research highlights the potential of incorporating large language models like ChatGPT in educational settings to support teachers and students.
270	Pedagogical AI conversational agents in higher education: a conceptual framework and survey of the state of the art Pedagogy; Education; Higher education; Conversational agents; Chatbots; Human computer interaction; Artificial intelligence The ever-changing global educational landscape, coupled with the advancement of Web3, is seeing rapid changes in the ways pedagogical artificially intelligent conversational agents are being developed and used to advance teaching and learning in higher education. Given the rapidly evolving research landscape, there is a need to establish what the current state of the art is in terms of the pedagogical applications and technological functions of these conversational agents and to identify the key existing research gaps, and future research directions, in the field. A literature survey of the state of the art of pedagogical AI conversational agents in higher education was conducted. The resulting literature sample (n = 92) was analysed using thematic template analysis, the results of which were used to develop a conceptual framework of pedagogical conversational agents in higher education. Furthermore, a survey of the state of the art was then presented as a function of the framework. The conceptual framework proposes that pedagogical AI conversational agents can primarily be considered in terms of their pedagogical applications and their pedagogical purposes, which include pastoral, instructional and cognitive, and are further considered in terms of mode of study and intent. The technological functions of the agents are also considered in terms of embodiment (embodied/disembodied) and functional type and features. This research proposes that there are numerous opportunities for future research, such as, the use of conversational agents for enhancing assessment, reflective practice and to support more effective administration and management practice. In terms of technological functions, future research would benefit from focusing on enhancing the level of personalisation and media richness of interaction that can be achieved by AI conversational agents.
271	Exploring intention of undergraduate students to embrace chatbots: from the vantage point of Lesotho Artificial intelligence; Chatbots; Diffusion theory of innovation; Undergraduate students The increasing prevalence of Fourth Industrial Revolution (4IR) technologies has led to a surge in the popularity of AI application tools, particularly chatbots, in various fields, including education. This research explores the factors influencing undergraduate students' inclination to embrace AI application tools, specifically chatbots, for educational purposes. Using an expanded diffusion theory of innovation framework, the study investigates the relationship between relative advantages, compatibility, trialability, perceived trust, perceived usefulness, perceived ease of use, and behavioral intention. Using a 7-point scale, a questionnaire was given to 842 undergraduate students to collect data. The analysis, conducted using SmartPLS 4.0.9.2 software with a covariance-based structural equation model, produced significant findings. The study confirms hypotheses related to the relative advantages, compatibility, trialability, perceived usefulness, and perceived trust associated with chatbots. Notably, students who perceive the benefits of chatbots show a strong intention to use them for academic purposes. The perception of compatibility between students and chatbots positively influences adoption intention, highlighting the importance of compatibility. Additionally, students who have the opportunity to trial chatbots are more likely to use them, emphasizing the significance of trialability. Interestingly, the study did not establish direct relationships between perceived usefulness, perceived ease of use, and behavioral intention. This suggests the presence of other influential factors or dynamics in the adoption of chatbots for educational purposes. These findings offer practical insights for students and contribute to the theoretical understanding of the diffusion theory of innovation. Future research can further explore these insights to unravel the complexities of chatbot adoption and facilitate the broader adoption of AI tools in educational settings.
272	A Study on ChatGPT-4 as an Innovative Approach to Enhancing English as a Foreign Language Writing Learning ChatGPT-4; English language; students' acceptance; writing The field of computer-assisted language learning has recently brought about a notable change in English as a Foreign Language (EFL) writing. Starting from October 2022, students across different academic fields have increasingly depended on ChatGPT-4 as a helpful resource for addressing particular challenges in EFL writing. This study aimed to investigate the use and acceptance of ChatGPT-4 in students' EFL writing. To this end, an experiment was conducted with 76 undergraduate students from a private school in Algeria. The participants were randomly allocated into two groups: experimental group (n = 37) and control group (n = 39). Additionally, a questionnaire was administered. The results showed that the experimental group (EG) outperformed the control group (CG). Besides, the findings revealed that students in the EG in post-test outperformed their pre-test scores. The findings also revealed substantial improvements in the EG's views of perceived usefulness, perceived ease of use, attitudes, and behavioral intention. According to the results, ChatGPT-4 helped boost students' EFL writing skills, which ultimately led to their acceptance. Students appear particularly interested in ChatGPT-4 because of its potential usefulness in putting what they learn about EFL writing into practice. Some suggestions and recommendations were provided.
273	ChatGPT for L2 learning: Current status and implications Evidence -based applied linguistics (EBAL); Technology -based learning model; Second language (L2) learning Despite a recent proliferation of studies on ChatGPT for second language (L2) learning, there is still a lack of systematic and updated review of its current status. To narrow the gap, this study collected data from 44 selected studies on ChatGPT for L2 learning in terms of six dimensions of the revised technology -based learning model, including ChatGPT, participants, objectives, theories, methodology, and outcomes. The results showed that (1) The most prevalent ChatGPT 's roles included content generation, feedback and teaching support. Context control and output customization were the two main prompt patterns. (2) Most studies focused on investigating English - as -a -foreign -language (EFL) college learners with small sample sizes. (3) Learner perceptions (general attitudes, satisfaction, motivation, and engagement) along with writing skills were the major objectives. (4) Social (sociocultural and constructivism), linguistic (input hypothesis, informal digital learning), and cognitive (self-determination theory, autonomy) theories were frequently adopted. (5) Most studies used qualitative, quantitative and mixed methods, with a particular eye on questionnaire surveys, interviews, log data and written texts. (6) Benefits and challenges were summarized from the selected studies. Implications were discussed for future research.
274	An investigation of teachers' perceptions of using ChatGPT as a supporting tool for teaching and learning in the digital era assessment and feedback; ChatGPT; lesson planning; teaching and learning; TPACK Background: The widespread use of information and communication technology (ICT) has led to significant changes in societal aspects, resulting in the emergence of a "knowledge society." However, students and teachers have faced challenges in adapting to this digitalization. In the United Arab Emirates (UAE), transitioning to a knowledge-based economy is a primary national agenda goal, aligning with Sustainable Development Goal 4 (SDG4) of ensuring high-quality education.Objectives: This research investigates teachers' perceptions of using ChatGPT as a digital supporting tool for teaching and learning practices. This includes lesson planning, teaching and learning activities, assessment and feedback and the challenges and benefits explored.Methods: This study employs an explanatory sequential mixed-methods design involving quantitative and qualitative data collection methods. An online survey was used with closed-ended items to collect quantitative data, while semi-structured interviews were conducted to collect qualitative data. The study participants are middle and high school teachers (n1 = 40) from different Dubai and Abu Dhabi private schools.Results and Conclusions: The most noticeable result is that teachers feel the benefits of using ChatGPT in lesson planning, teaching and learning and less in assessment and feedback. Some challenges and benefits were highlighted in each area and recommendations were suggested. However, teachers' biggest challenge was the bias and accuracy of information received and the lack of human interaction.TakeawaysThe findings provide valuable insights into the potential of ChatGPT in education and inform future research in this area. Specifically, the study provided insights into the effectiveness of ChatGPT in enhancing students' learning outcomes, engagement and motivation, as well as its impact on teaching practices and paedagogical beliefs.
275	An artificial intelligence-driven learning analytics method to examine the collaborative problem-solving process from the complex adaptive systems perspective Collaborative problem solving; Computer-supported collaborative learning; Complex adaptive systems theory; Collaborative pattern; Learning analytics; AI-driven learning analytics Collaborative problem solving (CPS) enables student groups to complete learning tasks, construct knowledge, and solve problems. Previous research has argued the importance of examining the complexity of CPS, including its multimodality, dynamics, and synergy from the complex adaptive systems perspective. However, there is limited empirical research examining the adaptive and temporal characteristics of CPS, which may have led to an oversimplified representation of the real complexity of the CPS process. To expand our understanding of the nature of CPS in online interaction settings, the present research collected multimodal process and performance data (i.e., speech, computer screen recordings, concept map data) and proposed a three-layered analytical framework that integrated AI algorithms with learning analytics to analyze the regularity of groups' collaboration patterns. The results surfaced three types of collaborative patterns in groups, namely the behaviour-oriented collaborative pattern (Type 1) associated with medium-level performance, the communication-behaviour-synergistic collaborative pattern (Type 2) associated with high-level performance, and the communication-oriented collaborative pattern (Type 3) associated with low-level performance. This research further highlighted the multimodal, dynamic, and synergistic characteristics of groups' collaborative patterns to explain the emergence of an adaptive, self-organizing system during the CPS process. According to the empirical research results, theoretical, pedagogical, and analytical implications were discussed to guide the future research and practice of CPS.
276	Exploring EFL university teachers' beliefs in integrating ChatGPT and other large language models in language education: a study in China Teachers' beliefs; ChatGPT; technology integration; univeristy EFL teachers; technology support Nowadays, the prevalence of ChatGPT and other Large Language Models (LLMs) has posed significant challenges into the education field, particularly in English education. In response, this study aimed to investigate the beliefs of 95 EFL university teachers from Chinese universities regarding the integration of LLMs in language education, as well as the relationships between their beliefs and other factors. The study yielded several findings: (1) According to the quantitative and qualitative results, we revealed several concerns among Chinese EFL university teachers regarding LLMs integration, such as neglection of traditional learning resources, academic integrity, and excessive reliance. (2) Previous experiences with LLMs, frequency of LLMs use, and self-evaluation on stages of LLMs integration all played vital roles in shaping university teachers' beliefs in integrating LLMs in language education. (3) No significant correlation was observed between university teachers' beliefs in integrating LLMs in language education and the availability of IT personnel. (4) No significant correlation was observed between university teachers' beliefs in integrating LLMs in language education their evaluation on IT infrastructure. This research has provided some insights into university teachers' beliefs in ChatGPT and other LLMs to promote effective policies and strategies in the digital era.
277	Interplay of academic emotion regulation, academic mindfulness, L2 learning experience, academic motivation, and learner autonomy in intelligent computer-assisted language learning: A study of EFL learners Academic emotion regulation; Academic mindfulness; Academic motivation; Learner autonomy; Intelligent computer-assisted language learning; L2 learning experience; EFL learners In the evolving landscape of second language (L2) education, Intelligent Computer-Assisted Language Learning (ICALL) stands out as a transformative force with the emergence of Artificial Intelligence (AI). Despite its growing prominence, integrating cognitive and affective constructs such as academic emotion regulation and mindfulness remains underexplored in ICALL environments. This study addresses this gap by examining their interplay with L2 learning experience, academic motivation, and learner autonomy among Iranian English as a Foreign Language (EFL) learners. Drawing on data from 398 intermediate EFL learners, this research utilized a comprehensive array of validated instruments, including the Academic Emotional Regulation Questionnaire, the Langer Mindfulness Scale, the L2 Learning Experience Scale, the Academic Motivation Scale, and the Learner Autonomy Questionnaire. Structural equation modeling (SEM) revealed significant correlations, indicating that academic emotion regulation positively influences L2 learning experience, academic motivation, and learner autonomy within ICALL settings. Furthermore, academic mindfulness emerged as a robust predictor of these educational outcomes in ICALL environments. These findings underscore the pivotal role of ICALL in L2 education and offer practical insights for teachers, curriculum developers, and policymakers to enhance teaching and learning practices.
278	Impact of AI assistance on student agency AI in education; Student agency; Peer feedback; Educational technology AI-powered learning technologies are increasingly being used to automate and scaffold learning activities (e.g., personalised reminders for completing tasks, automated real-time feedback for improving writing, or recommendations for when and what to study). While the prevailing view is that these technologies generally have a positive effect on student learning, their impact on students' agency and ability to self-regulate their learning is under-explored. Do students learn from the regular, detailed and personalised feedback provided by AI systems, and will they continue to exhibit similar behaviour in the absence of assistance? Or do they instead continue to rely on AI assistance without learning from it? To contribute to filling this research gap, we conducted a randomised controlled experiment that explored the impact of AI assistance on student agency in the context of peer feedback. With 1625 students across 10 courses, an experiment was conducted using peer review. During the initial four-week period, students were guided by AI features that utilised techniques such as rule-based suggestion detection, semantic similarity, and comparison with previous comments made by the reviewer to enhance their submissions if the feedback provided was deemed insufficiently detailed or general in nature. Over the following four weeks, students were divided into four different groups: control (AI) received prompts, (NR) received no prompts, (SR) received self-monitoring checklists in place of AI prompts, and (SAI) had access to both AI prompts and self-monitoring checklists. Results of the experiment suggest that students tended to rely on rather than learn from AI assistance. If AI assistance was removed, self-regulated strategies could help fill the gap but were not as effective as AI assistance. Results also showed that hybrid human-AI approaches that complement AI assistance with self-regulated strategies (SAI) were not more effective than AI assistance on its own. We conclude by discussing the broader benefits, challenges and implications of relying on AI assistance in relation to student agency in a world where we learn, live and work with AI.
279	Exploring AI chatbot affordances in the EFL classroom: young learners' experiences and perspectives chatbots; conversational agents; artificial intelligence; affordances; learner motivation; EFL learners; Dialogflow Professionals within the field of language learning have predicted that chatbots would provide new opportunities for the teaching and learning of language. Despite the assumed benefits of utilizing chatbots in language classrooms, such as providing interactional chances or helping to create an anxiety-free atmosphere, little is known about learners' actual use of chatbots during language classes or how chatbots affect their motivation to learn a language. To address these gaps, this exploratory study aimed to create an inventory of affordances that chatbots provide in the primary English as a foreign language (EFL) classroom and to explore how the affordances affect psychological aspects in language learners, particularly regarding their motivation to learn English through chatbots. Thirty-six Korean primary school learners participated in a 16-week EFL course that utilized customized chatbots. These chatbots were created using Google's Dialogflow. After the course, individual in-depth interviews were conducted regarding the participants' experiences and perceptions of the chatbots. Student-chatbot interaction logs produced during the course were also collected to supplement the interview data. Qualitative analysis of the interview transcripts and interaction logs revealed the presence of pedagogical, technological, and social affordances. Depending on the learner, the chatbot affordances were perceived differently; thus, each affordance acted as either an opportunity or a constraint for English language learning. In addition, this study specifically discussed how these chatbot affordances might have affected psychological states in language learners. Future recommendations regarding the use of chatbots in language classrooms were suggested from both pedagogical and technological perspectives.
280	Promoting students' learning achievement and self-efficacy: A mobile chatbot approach for nursing training chatbot; COVID-19 pandemic; mobile learning; nursing education; professional training; vaccine administration The aims of nursing training include not only mastering skills but also fostering the competence to make decisions for problem solving. In prenatal education, cultivating nurses' knowledge and competence of vaccine administration is a crucial issue for protecting pregnant women and newborns from infection. Therefore, obstetric vaccination knowledge has become a basic and essential training program for nursing students. However, most of these training programs are given via the lecture-based teaching approach with skills practice, providing students with few opportunities to think deeply about the relevant issues owing to the lack of interaction and context. This could have a negative impact on their learning effectiveness and clinical judgment. To address this problem, a mobile chatbot-based learning approach is proposed in this study to enable students to learn and think deeply in the contexts of handling obstetric vaccine cases via interacting with the chatbot. In order to verify the effectiveness of the proposed approach, an experiment was implemented. Two classes of 36 students from a university in northern Taiwan were recruited as participants. One class was the experimental group learning with the proposed approach, while the other class was the control group learning with the conventional approach (ie, giving lectures to explain the instructional content and training cases). The results indicate that applying a mobile chatbot for learning can enhance nursing students' learning achievement and self-efficacy. In addition, based on the analysis of the interview results, students generally believed that learning through the mobile chatbot was able to promote their self-efficacy as well as their learning engagement and performance. Practitioner notes What is already known about this topic Issues relevant to AI technology in education have been extensively discussed and explored around the world. Among the various AI systems, the potential of chatbots has been highlighted by researchers owing to the user-friendly interface developed using the natural language processing (NLP) technology. Few studies using AI chatbots in professional training have been conducted. What this paper adds In this study, a mobile chatbot was used in a nursing training program to enhance students' learning achievement and self-efficacy for handling vaccine cases. The mobile chatbot significantly improved the students' learning achievement and self-efficacy in comparison with the conventional learning approach in the vaccine training program. From the interview results, it was found that the students generally believed that the mobile chatbot was able to promote their self-efficacy as well as learning engagement and performances in the vaccine training program. Implications for practice and/or policy Mobile chatbots have great potential for professional training owing to their convenient and user-friendly features. It would be worth applying mobile chatbots as well as other NLP-based applications to other professional training programs in the future.
281	How AI-Enhanced Social-Emotional Learning Framework Transforms EFL Students' Engagement and Emotional Well-Being AI-enhanced social-emotional learning; EFL students' engagement; emotional well-being; personalising learning; supportive learning environment This study explores the transformative role of AI-enhanced social-emotional learning (SEL) frameworks in improving the engagement and emotional well-being of English as a foreign language (EFL) students in China. A survey was conducted among 816 undergraduate and postgraduate students from universities across five provinces, utilising convenience sampling. The research focused on how AI tools integrated into English learning contribute to student engagement and emotional stability. Data were analysed using SPSS for descriptive and regression analyses and AMOS for structural equation modelling. The findings highlight that AI-enhanced SEL significantly boosts student engagement and emotional well-being. By providing tailored learning experiences based on students' emotional and cognitive needs, AI systems facilitate better emotional regulation, increased focus and improved academic performance. The results suggest that AI-enhanced SEL frameworks offer personalised support that not only enhances learning outcomes but also creates a more emotionally supportive environment, contributing to students' overall academic success and well-being.
282	Design and implementation of an AI-enabled visual report tool as formative assessment to promote learning achievement and self-regulated learning: An experimental study AI; formative assessment; visualization techniques Formative assessment is essential for improving teaching and learning, and AI and visualization techniques provide great potential for its design and delivery. Using NLP, cognitive diagnostic and visualization techniques designed to analyse and present students' monthly exam data, we developed an AI-enabled visual report tool comprising six modules and conducted an empirical study of its effectiveness in a high school biology classroom. A total of 125 students in a ninth-grade biology course were assigned to a treatment group (n = 63) receiving AI-enabled visual reports as the intervention and a control group (n = 62) receiving overall oral feedback from the teacher. We present the main statistical results of the within-subjects design and the between-subjects design respectively, to better capture the main findings. Repeated measures ANOVA revealed a significant interaction effect of intervention and time on learning achievement, and the paired-sample Wilcoxon test indicated that the treatment group had experienced increasing learning anxiety (Cohen's d = 0.203, p = 0.046) and self-efficacy (Cohen's d = 1.793, p = 0.000) over time. Moreover, we conducted a series of non-parametric tests to compare the effects of AI-enabled visual reports and teacher feedback, but found no significant differences except for an increased self-efficacy (Cohen's d = 0.312, p = 0.046). Additionally, we had the students in the treatment group rate their favourable modules in the AI-enabled visual report and provide evaluative feedback. The study results provide important insights into the design and implementation of effective formative assessment supported by artificial AI and visualization techniques.
283	AI-Based Adaptive Feedback in Simulations for Teacher Education: An Experimental Replication in the Field adaptivity; artificial intelligence; feedback; learning analytics; natural language processing; personalisation; simulation-based learning BackgroundArtificial intelligence, particularly natural language processing (NLP), enables automating the formative assessment of written task solutions to provide adaptive feedback automatically. A laboratory study found that, compared with static feedback (an expert solution), adaptive feedback automated through artificial neural networks enhanced preservice teachers' diagnostic reasoning in a digital case-based simulation. However, the effectiveness of the simulation with the different feedback types and the generalizability to field settings remained unclear.ObjectivesWe tested the generalizability of the previous findings and the effectiveness of a single simulation session with either feedback type in an experimental field study.MethodsIn regular online courses, 332 preservice teachers at five German universities participated in one of three randomly assigned groups: (1) a simulation group with NLP-based adaptive feedback, (2) a simulation group with static feedback and (3) a no-simulation control group. We analysed the effect of the simulation with the two feedback types on participants' judgement accuracy and justification quality.Results and ConclusionsCompared with static feedback, adaptive feedback significantly enhanced justification quality but not judgement accuracy. Only the simulation with adaptive feedback significantly benefited learners' justification quality over the no-simulation control group, while no significant differences in judgement accuracy were found. Our field experiment replicated the findings of the laboratory study. Only a simulation session with adaptive feedback, unlike static feedback, seems to enhance learners' justification quality but not judgement accuracy. Under field conditions, learners require adaptive support in simulations and can benefit from NLP-based adaptive feedback using artificial neural networks.Results and ConclusionsCompared with static feedback, adaptive feedback significantly enhanced justification quality but not judgement accuracy. Only the simulation with adaptive feedback significantly benefited learners' justification quality over the no-simulation control group, while no significant differences in judgement accuracy were found. Our field experiment replicated the findings of the laboratory study. Only a simulation session with adaptive feedback, unlike static feedback, seems to enhance learners' justification quality but not judgement accuracy. Under field conditions, learners require adaptive support in simulations and can benefit from NLP-based adaptive feedback using artificial neural networks.
284	Teachers' attitudes towards chatbots in education: a technology acceptance model approach considering the effect of social language, bot proactiveness, and users' characteristics Chatbot; education; teachers; TAM; proactiveness; social language; digital skills The appearance of Artificial Intelligence implementations, such as text-based virtual assistants (chatbots) in education is relatively new. These implementations can be useful for helping teachers and students to solve both educational questions and routine tasks. This paper examines the factors that explain teachers' acceptance of chatbots through the dimensions of the Technology Acceptance Model (perceived usefulness and perceived ease of use), its conversational design (use of social language and proactiveness), and the teachers' age and digital skills. The data collection process included a pre-test and an online survey with four different types of chatbots. We analyse 225 responses of primary and secondary education teachers. The results show that the perceived easiness and perceived usefulness leads to greater acceptance of chatbots. As for the chatbots' features, formal language by a chatbot leads to a higher intention of using them. These results can help in chatbot design and communication decisions, improving the acceptance of the educational community.
285	A comparative study on sustainable development of online education platforms at home and abroad since the twenty-first century based on big data analysis Online education Platforms; Intelligent environment; Sustainability; Big data; Bibliometric analysis The sustainable development of Internet education platforms has not been a research focus due to the continuous renewal of artificial intelligence, big data, and policies across different countries and regions. To address this gap, this paper utilizes bibliometric analysis and visualization tools to analyze the development of online education platforms in China and abroad based on CNKI and WOS databases. The study reveals that the development of online education platforms in China and abroad is divided into four stages: a stepwise upward trend and a rising trend abroad. The online platform for education research is disciplined and has rich achievements. Chinese research hotspots focus on technology model, use, and commercialization, while foreign studies concentrate on sustainability and user impact. Future research hotspots in China may include effectiveness, user experience, feedback, and willingness to pay. The study highlights the importance of understanding cultural, geographical, and policy influences on the sustainable development of Internet education platforms to inform future Research and development in the field.
286	Chatbots for learning: A review of educational chatbots for the Facebook Messenger Chatbot; Messenger; Facebook; Mobile learning; Quality evaluation With the exponential growth in the mobile device market over the last decade, chatbots are becoming an increasingly popular option to interact with users, and their popularity and adoption are rapidly spreading. These mobile devices change the way we communicate and allow ever-present learning in various environments. This study examined educational chatbots for Facebook Messenger to support learning. The independent web directory was screened to assess chatbots for this study resulting in the identification of 89 unique chatbots. Each chatbot was classified by language, subject matter and developer's platform. Finally, we evaluated 47 educational chatbots using the Facebook Messenger platform based on the analytic hierarchy process against the quality attributes of teaching, humanity, affect, and accessibility. We found that educational chatbots on the Facebook Messenger platform vary from the basic level of sending personalized messages to recommending learning content. Results show that chatbots which are part of the instant messaging application are still in its early stages to become artificial intelligence teaching assistants. The findings provide tips for teachers to integrate chatbots into classroom practice and advice what types of chatbots they can try out.
287	A review of opportunities and challenges of chatbots in education Chatbot; artificial intelligence; chatbot in education; systematic review; trend analysis This study explores the trends of chatbots in education studies by conducting a literature review to analyze relevant papers published in the Social Science Citation Index (SSCI) journals by searching the Web of Science (WoS) database. From the analysis results, it was found that the United States, Taiwan and Hong Kong are the top three contributing countries or regions. In addition, most studies adopted quantitative methods in their research design, such as ANOVA (Analysis of variance), descriptive statistics, t test, and correlation analysis. ANCOVA (Analysis of covariance) was the most frequently adopted approach for comparing the performances or perceptions of different groups of students. From the analysis results, the greatest proportion of studies adopted guided learning, followed by no learning activities. It was determined that the studies related to chatbots in education are still in an early stage since there are few empirical studies investigating the use of effective learning designs or learning strategies with chatbots. This implies much room for conducting relevant research to drive innovative teaching in terms of improving the learning process and learning outcomes. Finally, we highlight the research gaps and suggest several directions for future research based on the findings in the present study.
288	Driving the dual learning process of management knowledge: A social cognitive theory perspective Management learning; Social cognitive theory; Learning cycle theory; Knowledge types Recent research has demonstrated a sustained interest in the effectiveness of learning management knowledge. A dual learning process is proposed in this study to explain how learners acquire management knowledge. Furthermore, this study examines the influences that encourage learners to engage in the dual learning process based on Social Cognitive Theory (SCT). The study surveyed 262 business school students in seven classes enrolled in the Principles of Business course, using structural equation modeling to validate relationships among the dual learning process, driving factors, and knowledge learning. Empirical results suggest that environmental factors, including ChatGPT-assisted learning and teacher support - as well as individual factors, such as self-efficacy - help strengthen learners' experience in the dual learning process. This research attempts to integrate the social cognitive theory, learning cycle theory, and knowledge types perspective to provide a holistic theoretical foundation and interpretations for effective learning in management knowledge.
289	Trends and development in technology-enhanced adaptive/personalized learning: A systematic review of journal publications from 2007 to 2017 Adaptive/personalized learning; Application in subject areas; Pedagogical issues; Teaching and learning strategies In this study, the trends and developments of technology-enhanced adaptive/personalized learning have been studied by reviewing the related journal articles in the recent decade (i.e., from 2007 to 2017). To be specific, we investigated many research issues such as the parameters of adaptive/personalized learning, learning supports, learning outcomes, subjects, participants, hardware, and so on. Furthermore, this study reveals that personalized/adaptive learning has always been an attractive topic in this field, and personalized data sources, for example, students' preferences, learning achievements, profiles, and learning logs have become the main parameters for supporting personalized/adaptive learning. In addition, we found that the majority of the studies on personalized/adaptive learning still only supported traditional computers or devices, while only a few studies have been conducted on wearable devices, smartphones and tablet computers. In other words, personalized/adaptive learning has a significant number of potential applications on the above smart devices with the rapid development of artificial intelligence, virtual reality, cloud computing and wearable computing. Through the in-depth analysis of the trends and developments in the various dimensions of personalized/adaptive learning, the future research directions, issues and challenges are discussed in our paper.
290	Integrating AIGC into product design ideation teaching: An empirical study on self-efficacy and learning outcomes AIGC in product design; Design education; Design ideation teaching; Teaching/Learning strategies; Learning outcomes enhancement Background: The emergence of artificial intelligence-generated content (AIGC) in the realm of education, notably in product design, signifies a watershed moment, heralding significant enhancements over conventional pedagogies by potentially catalyzing unparalleled innovation. Aims: This investigation assesses the ramifications of assimilating AIGC into product design instruction, focusing on its advantages, constraints, and consequent influence on students' design cognition across a spectrum of proficiency levels. Sample: The study encompassed 119 scholars with a focus on product or industrial design, delineated into three distinct echelons of proficiency. Methods: Utilizing Technology-mediated Learning Theory, an empirical field study was initiated to explore AIGC's impact on self-efficacy, ideation volume, innovation, diversity, and the aggregate quality of outcomes, taking into account the divergence in pedagogical strategies and student competency tiers. Results: AIGC notably augmented students' self-efficacy, ideation, novelty, and variety, albeit with a potential diminution in ideational quality. Disparities in self-efficacy, volume of ideas, and their caliber were discernibly evident across varying tiers of competency. Conclusions: AIGC markedly fosters innovation within product design pedagogy, demonstrating its ascendancy over traditional instructional methods in catalyzing scholastic innovation. However, orthodox teaching methodologies retain their critical role in the cultivation of problem-solving acumen. Personalized support, particularly for those demonstrating lower self-efficacy, is paramount in amplifying their creative ideation through bespoke pedagogical strategies, thus maximizing the utility of AIGC integration.
291	Intelligent tutoring systems: a systematic review of characteristics, applications, and evaluation methods Adaptive learning; artificial intelligent tutoring; intelligent learning; intelligent tutoring system; ITS With the rapid growth of technology, computer learning has become increasingly integrated with artificial intelligence techniques in order to develop more personalized educational systems. These systems are known as Intelligent Tutoring systems (ITSs). This paper focused on the variant characteristics of ITSs developed across different educational fields. The original studies from 2007 to 2017 were extracted from the PubMed, ProQuest, Scopus, Google scholar, Embase, Cochrane, and Web of Science databases. Finally, 53 papers were included in the study based on inclusion criteria. The educational fields in the ITSs were mainly computer sciences (37.73%). Action-condition rule-based reasoning, data mining, and Bayesian network with 33.96%, 22.64%, and 20.75% frequency respectively, were the most frequent artificial intelligent techniques applied in the ITSs. These techniques enable ITSs to deliver adaptive guidance and instruction, evaluate learners, define and update the learner's model, and classify or cluster learners. Specifically, the performance of the system, learner's performance, and experiences were used for evaluation of ITSs. Most ITSs were designed for web user interfaces. Although these systems could facilitate reasoning in the learning process, these systems have rarely been applied in experimental courses including problem-solving, decision-making in physics, chemistry, and clinical fields. Due to the important role of a cell phone in facilitating personalized learning and given the low rate of using mobile-based ITSs, this study has recommended the development and evaluation of mobile-based ITSs.
292	Incorporating AIGC into design ideation: A study on self-efficacy and learning experience acceptance under higher-order thinking Higher-order thinking; Self-efficacy; Design ideation; Technology acceptance model; Learning experience The concept of higher-order thinking skills (HOTS) is universally acknowledged as a key component for the development of exceptional talents in the 21st century. Addressing the challenge of how to accurately and effectively nurture these skills in students has emerged as a pivotal topic in educational discourse. This research delves into the practical use of artificial intelligencegenerated content (AIGC) in the realm of design thinking pedagogy, investigating its potential impact in bolstering students' HOTS. The research aims to discern the differences in student selfefficacy and receptivity to learning experiences between AIGC and conventional teaching methodologies, particularly across various student competency levels. An empirical study involving 119 students was conducted, offering both quantitative and qualitative insights into their self-efficacy and receptiveness to learning experiences, highlighting notable distinctions among diverse student groups. The findings suggest a significant edge of AIGC in enhancing student self-efficacy, with consistent results across different skill levels. However, variations in learning experience receptivity were observed among students of different abilities. An extensive analysis and discussion of these data underscore the necessity for educators to intricately understand and address the unique needs and challenges of students when devising and implementing AIGC-based teaching strategies. This approach ensures a more targeted and effective support for the learning and development of students with varying capabilities. The study offers empirical evidence and theoretical direction for the application of AIGC in educational settings, empowering educators to more precisely cater to the diverse learning needs and developmental trajectories of their students.
293	Medical education trends for future physicians in the era of advanced technology and artificial intelligence: an integrative review Undergraduate medical education; Technology; Humanities; Integration; Societies; Self-directed learning Background: Medical education must adapt to different health care contexts, including digitalized health care systems and a digital generation of students in a hyper-connected world. The aims of this study are to identify and synthesize the values that medical educators need to implement in the curricula and to introduce representative educational programs. Methods: An integrative review was conducted to combine data from various research designs. We searched for articles on PubMed, Scopus, Web of Science, and EBSCO ERIC between 2011 and 2017. Key search terms were "undergraduate medical education," "future," "twenty-first century," "millennium," "curriculum," "teaching," "learning," and "assessment." We screened and extracted them according to inclusion and exclusion criteria from titles and abstracts. All authors read the full texts and discussed them to reach a consensus about the themes and subthemes. Data appraisal was performed using a modified Hawker's evaluation form. Results: Among the 7616 abstracts initially identified, 28 full-text articles were selected to reflect medical education trends and suggest suitable educational programs. The integrative themes and subthemes of future medical education are as follows: 1) a humanistic approach to patient safety that involves encouraging humanistic doctors and facilitating collaboration; 2) early experience and longitudinal integration by early exposure to patient-oriented integration and longitudinal integrated clerkships; 3) going beyond hospitals toward society by responding to changing community needs and showing respect for diversity; and 4) student-driven learning with advanced technology through active learning with individualization, social interaction, and resource accessibility. Conclusions: This review integrated the trends in undergraduate medical education in readiness for the anticipated changes in medical environments. The detailed programs introduced in this study could be useful for medical educators in the development of curricula. Further research is required to integrate the educational trends into graduate and continuing medical education, and to investigate the status or effects of innovative educational programs in each medical school or environment.
294	Beyond semantic distance: Automated scoring of divergent thinking greatly improves with large language models Divergent thinking; Alternate uses test; Large -language models; Automated scoring Automated scoring for divergent thinking (DT) seeks to overcome a key obstacle to creativity measurement: the effort, cost, and reliability of scoring open-ended tests. For a common test of DT, the Alternate Uses Task (AUT), the primary automated approach casts the problem as a semantic distance between a prompt and the resulting idea in a text model. This work presents an alternative approach that greatly surpasses the performance of the best existing semantic distance approaches. Our system, Ocsai, fine-tunes deep neural network-based large-language models (LLMs) on human-judged responses. Trained and evaluated against one of the largest collections of human-judged AUT responses, with 27 thousand responses collected from nine past studies, our fine-tuned large-language-models achieved up to r = 0.81 correlation with human raters, greatly surpassing current systems (r = 0.12-0.26). Further, learning transfers well to new test items and the approach is still robust with small numbers of training labels. We also compare prompt-based zero-shot and few-shot approaches, using GPT-3, ChatGPT, and GPT-4. This work also suggests a limit to the underlying assumptions of the semantic distance model, showing that a purely semantic approach that uses the stronger language representation of LLMs, while still improving on existing systems, does not achieve comparable improvements to our fine-tuned system. The increase in performance can support stronger applications and interventions in DT and opens the space of automated DT scoring to new areas for improving and understanding this branch of methods.
295	Reviewing the current state of virtual reality integration in medical education - a scoping review Digitalisation; Medical Education; Medical School; Medical training; Virtual reality BackgroundIn medical education, new technologies like Virtual Reality (VR) are increasingly integrated to enhance digital learning. Originally used to train surgical procedures, now use cases also cover emergency scenarios and non-technical skills like clinical decision-making. This scoping review aims to provide an overview of VR in medical education, including requirements, advantages, disadvantages, as well as evaluation methods and respective study results to establish a foundation for future VR integration into medical curricula.MethodsThis review follows the updated JBI methodology for scoping reviews and adheres to the respective PRISMA extension. We included reviews in English or German language from 2012 to March 2022 that examine the use of VR in education for medical and nursing students, registered nurses, and qualified physicians. Data extraction focused on medical specialties, subjects, curricula, technical/didactic requirements, evaluation methods and study outcomes as well as advantages and disadvantages of VR.ResultsA total of 763 records were identified. After eligibility assessment, 69 studies were included. Nearly half of them were published between 2021 and 2022, predominantly from high-income countries. Most reviews focused on surgical training in laparoscopic and minimally invasive procedures (43.5%) and included studies with qualified physicians as participants (43.5%). Technical, didactic and organisational requirements were highlighted and evaluations covering performance time and quality, skills acquisition and validity, often showed positive outcomes. Accessibility, repeatability, cost-effectiveness, and improved skill development were reported as advantages, while financial challenges, technical limitations, lack of scientific evidence, and potential user discomfort were cited as disadvantages.DiscussionDespite a high potential of VR in medical education, there are mandatory requirements for its integration into medical curricula addressing challenges related to finances, technical limitations, and didactic aspects. The reported lack of standardised and validated guidelines for evaluating VR training must be overcome to enable high-quality evidence for VR usage in medical education. Interdisciplinary teams of software developers, AI experts, designers, medical didactics experts and end users are required to design useful VR courses. Technical issues and compromised realism can be mitigated by further technological advancements.
